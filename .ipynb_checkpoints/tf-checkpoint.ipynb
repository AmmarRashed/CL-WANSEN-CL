{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "      <th>tokenized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>i love science fiction and i hate superheroes ...</td>\n",
       "      <td>9</td>\n",
       "      <td>['love', 'science', 'fiction', 'hate', 'superh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>the movie is absolutely incredible all the per...</td>\n",
       "      <td>10</td>\n",
       "      <td>['the', 'movie', 'absolutely', 'incredible', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>in a cinematic era dominated by reboots and mi...</td>\n",
       "      <td>8</td>\n",
       "      <td>['cinematic', 'era', 'dominated', 'reboots', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>movie review on rise of the planet of the apes...</td>\n",
       "      <td>4</td>\n",
       "      <td>['movie', 'review', 'rise', 'the', 'planet', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>during experiments to find a cure for alzheime...</td>\n",
       "      <td>7</td>\n",
       "      <td>['during', 'experiments', 'find', 'cure', 'for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language    Movie_ID                                             Review  \\\n",
       "0       en  -800777728  i love science fiction and i hate superheroes ...   \n",
       "1       en  -800777728  the movie is absolutely incredible all the per...   \n",
       "2       en -1018312192  in a cinematic era dominated by reboots and mi...   \n",
       "3       en -1018312192  movie review on rise of the planet of the apes...   \n",
       "4       en -1018312192  during experiments to find a cure for alzheime...   \n",
       "\n",
       "   Score                                  tokenized_reviews  \n",
       "0      9  ['love', 'science', 'fiction', 'hate', 'superh...  \n",
       "1     10  ['the', 'movie', 'absolutely', 'incredible', '...  \n",
       "2      8  ['cinematic', 'era', 'dominated', 'reboots', '...  \n",
       "3      4  ['movie', 'review', 'rise', 'the', 'planet', '...  \n",
       "4      7  ['during', 'experiments', 'find', 'cure', 'for...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/tokenized_reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "      <th>tokenized_reviews</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>-1018312192</td>\n",
       "      <td>filme giderken bu kadar iyisini beklemiyordum ...</td>\n",
       "      <td>9</td>\n",
       "      <td>['film', 'gider', 'kadar', 'iyi', 'cok', 'seyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>-1112579067</td>\n",
       "      <td>sevgilime tavsiye etmi tim abisinden izlemi ab...</td>\n",
       "      <td>8</td>\n",
       "      <td>['tim', 'izle', 'denen', 'bir', 'ger', 'yin', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>-1112579067</td>\n",
       "      <td>kesinlikle izlenmesi gereken filmlerden hala e...</td>\n",
       "      <td>8</td>\n",
       "      <td>['kesinlik', 'izlenme', 'film', 'hal', 'ifade'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>-1112579067</td>\n",
       "      <td>ok duyguland m duygusuz bir insan m fakat bu ...</td>\n",
       "      <td>9</td>\n",
       "      <td>['bir', 'insan', 'fakat', 'film', 'ben', 'ger'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>-1112579067</td>\n",
       "      <td>will smith in en iyi filmi bana g re</td>\n",
       "      <td>9</td>\n",
       "      <td>['will', 'smith', 'iyi', 'film', 'ban']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Movie_ID                                             Review  \\\n",
       "Language                                                                  \n",
       "tr       -1018312192  filme giderken bu kadar iyisini beklemiyordum ...   \n",
       "tr       -1112579067  sevgilime tavsiye etmi tim abisinden izlemi ab...   \n",
       "tr       -1112579067  kesinlikle izlenmesi gereken filmlerden hala e...   \n",
       "tr       -1112579067   ok duyguland m duygusuz bir insan m fakat bu ...   \n",
       "tr       -1112579067              will smith in en iyi filmi bana g re    \n",
       "\n",
       "          Score                                  tokenized_reviews  \n",
       "Language                                                            \n",
       "tr            9  ['film', 'gider', 'kadar', 'iyi', 'cok', 'seyi...  \n",
       "tr            8  ['tim', 'izle', 'denen', 'bir', 'ger', 'yin', ...  \n",
       "tr            8  ['kesinlik', 'izlenme', 'film', 'hal', 'ifade'...  \n",
       "tr            9  ['bir', 'insan', 'fakat', 'film', 'ben', 'ger'...  \n",
       "tr            9            ['will', 'smith', 'iyi', 'film', 'ban']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"Language\").loc[\"tr\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(df[\"Review\"]), np.array(df[\"Score\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class TextUtil:\n",
    "    def __init__(self, sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters):\n",
    "        \"\"\"\n",
    "        :param sequence_length: the length of each sentence\n",
    "        :param num_classes: number of classes in the output layer (in our case 11 [0-10])\n",
    "        :param vocab_size: for the embedding layer which will be shaped vocab_size x embedding size\n",
    "        :param embedding_size: word2vec dimensions\n",
    "        :param filter_sizes: convolution filter windows sizes > number of words it covers  example [4, 5, 6]\n",
    "        :param num_filters: number of filters per filter size\n",
    "        \"\"\"\n",
    "        # self.sequence_length = sequence_length\n",
    "        # self.num_classes = num_classes\n",
    "        # self.vocab_size = vocab_size\n",
    "        # self.embedding_size = embedding_size\n",
    "        # self.filter_sizes = filter_sizes\n",
    "        # self.num_filters = num_filters\n",
    "\n",
    "        # None: batch size len could be anything\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.int32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keeping_prob = tf.placeholder(tf.float32, name=\"dropout_keeping_prob\")\n",
    "\n",
    "        with tf.device(\"/cpu:0\"), tf.name_scope(\"embedding\"):\n",
    "            W = tf.Variable(\n",
    "                tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n",
    "                name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                # Convolution Layer\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(\n",
    "                    self.embedded_chars_expanded,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "                # Apply nonlinearity\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                # Max-pooling over the outputs\n",
    "                pooled = tf.nn.max_pool(\n",
    "                    h,\n",
    "                    ksize=[1, sequence_length - filter_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.h_pool = tf.concat(3, pooled_outputs)\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "\n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keeping_prob)\n",
    "\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.Variable(tf.truncated_normal([num_filters_total, num_classes], stddev=0.1), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "\n",
    "        # Calculate mean cross-entropy loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(self.scores, self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses)\n",
    "\n",
    "        # Calculate Accuracy\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = TextCNN(\n",
    "    sequence_length=X_train.shape[1],\n",
    "    num_classes=2,\n",
    "    vocab_size=len(vocabulary),\n",
    "    embedding_size=FLAGS.embedding_dim,\n",
    "    filter_sizes=map(int, FLAGS.filter_sizes.split(\",\")),\n",
    "    num_filters=FLAGS.num_filters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
