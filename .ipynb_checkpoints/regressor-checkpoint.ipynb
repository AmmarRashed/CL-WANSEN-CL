{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, pandas as pd, re, numpy as np, ast\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>rev_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>9</td>\n",
       "      <td>[  5.10346368e-02   3.13695297e-02   3.0434969...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>10</td>\n",
       "      <td>[  5.85338362e-02   3.14969495e-02   9.2768417...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>8</td>\n",
       "      <td>[  5.58815002e-02   3.47756743e-02  -4.6352325...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>4</td>\n",
       "      <td>[ 0.05872388  0.03473265 -0.01488676  0.101489...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>7</td>\n",
       "      <td>[  3.05793583e-02   3.45815420e-02  -6.1754882...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language    Movie_ID  Score  \\\n",
       "0       en  -800777728      9   \n",
       "1       en  -800777728     10   \n",
       "2       en -1018312192      8   \n",
       "3       en -1018312192      4   \n",
       "4       en -1018312192      7   \n",
       "\n",
       "                                             rev_vec  \n",
       "0  [  5.10346368e-02   3.13695297e-02   3.0434969...  \n",
       "1  [  5.85338362e-02   3.14969495e-02   9.2768417...  \n",
       "2  [  5.58815002e-02   3.47756743e-02  -4.6352325...  \n",
       "3  [ 0.05872388  0.03473265 -0.01488676  0.101489...  \n",
       "4  [  3.05793583e-02   3.45815420e-02  -6.1754882...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_vect_dicts = pickle.load(open(\"score_vectors_dict\", \"rb\"))\n",
    "df = pd.read_csv(\"datasets/LMSR_rev2vec.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>rev_vec</th>\n",
       "      <th>score_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>9</td>\n",
       "      <td>[  5.10346368e-02   3.13695297e-02   3.0434969...</td>\n",
       "      <td>[-0.279659865294, -0.0989524373099, 0.03580531...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>10</td>\n",
       "      <td>[  5.85338362e-02   3.14969495e-02   9.2768417...</td>\n",
       "      <td>[-0.337921482265, -0.0845029055412, 0.01985886...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>8</td>\n",
       "      <td>[  5.58815002e-02   3.47756743e-02  -4.6352325...</td>\n",
       "      <td>[-0.392837140579, -0.13993286079, 0.0117605265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>4</td>\n",
       "      <td>[ 0.05872388  0.03473265 -0.01488676  0.101489...</td>\n",
       "      <td>[-0.619363193141, -0.294599547156, 0.014450649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>7</td>\n",
       "      <td>[  3.05793583e-02   3.45815420e-02  -6.1754882...</td>\n",
       "      <td>[-0.418672884105, -0.170094622466, 0.089099188...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language    Movie_ID  Score  \\\n",
       "0       en  -800777728      9   \n",
       "1       en  -800777728     10   \n",
       "2       en -1018312192      8   \n",
       "3       en -1018312192      4   \n",
       "4       en -1018312192      7   \n",
       "\n",
       "                                             rev_vec  \\\n",
       "0  [  5.10346368e-02   3.13695297e-02   3.0434969...   \n",
       "1  [  5.85338362e-02   3.14969495e-02   9.2768417...   \n",
       "2  [  5.58815002e-02   3.47756743e-02  -4.6352325...   \n",
       "3  [ 0.05872388  0.03473265 -0.01488676  0.101489...   \n",
       "4  [  3.05793583e-02   3.45815420e-02  -6.1754882...   \n",
       "\n",
       "                                           score_vec  \n",
       "0  [-0.279659865294, -0.0989524373099, 0.03580531...  \n",
       "1  [-0.337921482265, -0.0845029055412, 0.01985886...  \n",
       "2  [-0.392837140579, -0.13993286079, 0.0117605265...  \n",
       "3  [-0.619363193141, -0.294599547156, 0.014450649...  \n",
       "4  [-0.418672884105, -0.170094622466, 0.089099188...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"score_vec\"] = df[\"Score\"].apply(lambda x: score_vect_dicts[x] if x in score_vect_dicts else np.NaN)\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_np_array(array_string, as_nparray=True):\n",
    "    pattern = r'''# Match (mandatory) whitespace between...\n",
    "              (?<=\\]) # ] and\n",
    "              \\s+\n",
    "              (?= \\[) # [, or\n",
    "              |\n",
    "              (?<=[^\\[\\]\\s]) \n",
    "              \\s+\n",
    "              (?= [^\\[\\]\\s]) # two non-bracket non-whitespace characters\n",
    "           '''\n",
    "    fixed_string = re.sub(pattern, ',', array_string, flags=re.VERBOSE)\n",
    "    if as_nparray:\n",
    "        return np.array(ast.literal_eval(fixed_string))\n",
    "    return ast.literal_eval(fixed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import chain, starmap\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(df), 300))\n",
    "Y = np.zeros((len(df), 300))\n",
    "y = np.zeros((len(df)))\n",
    "i = 0\n",
    "for rev in df.iterrows():\n",
    "    score = rev[1][2]\n",
    "    rev_vec = parse_np_array(rev[1][3])\n",
    "    score_vec = rev[1][4]\n",
    "    \n",
    "    X[i] = rev_vec\n",
    "    Y[i] = score_vec\n",
    "    y[i] = score\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(p):\n",
    "    pipeline, pipeline_params = [], OrderedDict()\n",
    "    \n",
    "    for model, model_params in p:\n",
    "        try:\n",
    "            name = model.__name__\n",
    "            pipeline.append((name, model()))\n",
    "        except:\n",
    "            name = model.estimator.__name__\n",
    "            pipeline.append((name, model))\n",
    "       \n",
    "        pipeline_params.update({'{}__{}'.format(name, param_name) : values \n",
    "                                for param_name, values in model_params.items()})\n",
    "    \n",
    "    return Pipeline(pipeline), pipeline_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "\n",
    "    (MLPRegressor, {\n",
    "        \"hidden_layer_sizes\":range(50, 300+1,50),\n",
    "        \"max_iter\":range(100, 200+1, 25)\n",
    "    }),\n",
    "    (RandomForestRegressor, {\n",
    "        \"n_estimators\": range(3, 10),\n",
    "        \"n_jobs\":[-1],\n",
    "    }),\n",
    "    (LinearRegression, {\n",
    "        \"n_jobs\":[-1]\n",
    "    })\n",
    "]\n",
    "feature_selection = [\n",
    "    (PCA, {\n",
    "    'n_components': range(50, 150+1, 25)\n",
    "  })\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf = MLPClassifier(random_state=42)\n",
    "mlp_clf.fit(Y, y)\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_TRIALS = 10\n",
    "# metrics = ['f1', 'recall', 'precision', 'accuracy']\n",
    "# trials = []\n",
    "\n",
    "# # for i in range(NUM_TRIALS):\n",
    "# cv_pipelines = []\n",
    "# inner_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# outer_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# for pipeline, params in map(build_pipeline, product(feature_selection, regressors)):\n",
    "#     cv_pipeline = GridSearchCV(pipeline, params, cv=inner_cv, n_jobs=-1, verbose=1).fit(X, Y)\n",
    "#     cv_pipelines.append(cv_pipeline)\n",
    "\n",
    "# best_pipeline = cv_pipelines[np.argmax([i.best_score_ for i in cv_pipelines])]\n",
    "# cv = cross_validate(best_pipeline.best_estimator_, \n",
    "#                     X=X, y=Y, cv=outer_cv, \n",
    "#                     scoring=metrics, \n",
    "#                     return_train_score=False)\n",
    "\n",
    "# trials.append((best_pipeline, cv))\n",
    "# print(\"{} trial done\".format(i+1))\n",
    "# print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_accuracy(y_true, y_predict):\n",
    "    res = 0\n",
    "    for i in range(len(y_true)):\n",
    "        res += abs(y_true[i]-y_predict[i])\n",
    "    return 1-res/(len(y_true)*len(set(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {\"distance_accuracy\":0}\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    l_train, l_test = y[train_index], y[test_index]\n",
    "    pca = PCA()\n",
    "    pca.fit(X_train)\n",
    "    pca.transform(X_train)\n",
    "    mlp = MLPRegressor(random_state=42)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    preds_score_vecs = lr.predict(X_test)\n",
    "    pred_scores = knn.predict(preds_score_vecs)\n",
    "    for metric in score_dict:\n",
    "        score_dict[metric] += globals()[metric](l_test, pred_scores)\n",
    "for metric in score_dict:\n",
    "    score_dict[metric] /= 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distance_accuracy': 0.88336335496199436}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.]\n",
      "[ 8.]\n"
     ]
    }
   ],
   "source": [
    "print(knn.predict(mlp.predict(np.atleast_2d(vp))))\n",
    "print(knn.predict(mlp.predict(np.atleast_2d(vn))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn = np.array([ 0.024575  ,  0.0780872 ,  0.0218456 , -0.416978  ,  0.0418342 ,\n",
    "       -0.26509828, -0.15126799, -0.1380056 ,  0.1373278 ,  0.213032  ,\n",
    "       -0.021196  , -0.286086  , -0.062111  ,  0.158969  ,  0.1046596 ,\n",
    "        0.0441594 , -0.1745858 ,  0.06308679, -0.0271644 ,  0.225724  ,\n",
    "        0.07405599,  0.0317332 , -0.2219522 , -0.149866  ,  0.142036  ,\n",
    "        0.00603   ,  0.2340944 ,  0.1475164 , -0.1298866 ,  0.10311399,\n",
    "        0.27726799, -0.2231768 ,  0.1363482 , -0.0377694 ,  0.0211782 ,\n",
    "       -0.0374892 ,  0.1913826 ,  0.55832402, -0.0291594 , -0.1916008 ,\n",
    "       -0.137254  ,  0.2495355 , -0.159432  ,  0.0383394 ,  0.06307359,\n",
    "       -0.06488302, -0.010813  ,  0.06447   , -0.43357179,  0.2884226 ,\n",
    "       -0.006242  ,  0.31172919,  0.006465  , -0.202956  ,  0.13317999,\n",
    "        0.234002  , -0.1704622 , -0.142286  ,  0.1297116 , -0.30379   ,\n",
    "       -0.18723999, -0.0586302 ,  0.13263419,  0.15410801, -0.0545603 ,\n",
    "        0.1699034 , -0.18423   , -0.082516  , -0.079438  ,  0.34552881,\n",
    "       -0.2079218 ,  0.443968  ,  0.14478679, -0.1228022 ,  0.0741026 ,\n",
    "        0.2452676 ,  0.2687516 , -0.4057148 , -0.0954918 ,  0.171634  ,\n",
    "        0.2247296 , -0.116044  ,  0.59757199, -0.0844328 , -0.0348282 ,\n",
    "        0.2154974 , -0.015546  , -0.2104446 ,  0.10083159,  0.0759356 ,\n",
    "        0.29458   , -0.133753  ,  0.1162    ,  0.1378152 , -0.1707856 ,\n",
    "       -0.085724  , -0.0289014 ,  0.338166  , -0.37039001, -0.0547254 ,\n",
    "        0.0465862 , -0.0389332 , -0.1511948 , -0.2348892 ,  0.10468   ,\n",
    "        0.1546    ,  0.0071447 , -0.36236481, -0.1022528 ,  0.22919001,\n",
    "       -0.17852647,  0.1351988 , -0.27181799,  0.0673532 , -0.2173312 ,\n",
    "       -0.3075472 ,  0.06701642,  0.267372  , -0.26892019,  0.101166  ,\n",
    "        0.050804  ,  0.2443642 , -0.03797   ,  0.11411714,  0.0200308 ,\n",
    "       -0.673707  ,  0.240564  , -0.032244  , -0.084962  ,  0.1343066 ,\n",
    "        0.147628  , -0.1281278 , -0.03501   , -0.13466614, -0.091464  ,\n",
    "       -0.2160354 , -0.34959999, -0.18217901, -0.02749   ,  0.147264  ,\n",
    "       -0.1084934 , -0.00213201,  0.11428801,  0.1227576 , -0.02473298,\n",
    "        0.113816  , -0.0390326 ,  0.54454201,  0.0396268 , -0.04223801,\n",
    "        0.274098  ,  0.1014148 , -0.0485458 ,  0.1502744 , -0.048396  ,\n",
    "        0.0828894 , -0.0649078 , -0.00495232, -0.0129226 ,  0.1339572 ,\n",
    "       -0.1326338 , -0.0339584 ,  0.0275506 ,  0.085596  ,  0.394556  ,\n",
    "       -0.00980564, -0.60479599, -0.075632  ,  0.1147774 , -0.3782834 ,\n",
    "        0.028796  , -0.407134  , -0.045582  ,  0.226008  , -0.0245888 ,\n",
    "        0.4154308 , -0.124188  ,  0.0456686 ,  0.272304  ,  0.06235399,\n",
    "       -0.23105499,  0.2285066 , -0.1360454 , -0.193236  , -0.42464201,\n",
    "       -0.1383896 , -0.20321819,  0.504094  ,  0.0874442 , -0.0654232 ,\n",
    "        0.084188  ,  0.2607762 ,  0.06747678, -0.11143244,  0.13610542,\n",
    "        0.0172552 , -0.0733664 , -0.040266  ,  0.082984  , -0.307465  ,\n",
    "        0.08035204, -0.13782518,  0.263822  , -0.130928  , -0.265558  ,\n",
    "        0.041311  , -0.249024  , -0.1387842 , -0.2848    , -0.2122302 ,\n",
    "        0.0458996 , -0.22237   , -0.0132874 , -0.1249018 ,  0.39228599,\n",
    "       -0.21706681, -0.21440177,  0.3210316 , -0.47030999, -0.33631383,\n",
    "       -0.2332706 , -0.0390812 ,  0.08309986, -0.107676  ,  0.0093338 ,\n",
    "       -0.0226178 ,  0.165766  ,  0.057472  , -0.0851216 ,  0.0241008 ,\n",
    "        0.09513   ,  0.126258  , -0.139444  ,  0.211626  , -0.391036  ,\n",
    "        0.1594172 , -0.0602718 , -0.24749739,  0.0504366 , -0.2312028 ,\n",
    "        0.53387199, -0.19293864, -0.1390358 ,  0.2534996 , -0.2511718 ,\n",
    "       -0.0130448 , -0.1585984 ,  0.12275732, -0.30499041,  0.03531948,\n",
    "        0.11372   ,  0.09131801, -0.358166  ,  0.156076  , -0.1561332 ,\n",
    "        0.0183022 ,  0.16250619,  0.045286  , -0.48574999,  0.1268312 ,\n",
    "        0.064976  ,  0.1773104 ,  0.1984662 ,  0.1406944 , -0.2192226 ,\n",
    "        0.103485  , -0.06491428, -0.0990716 ,  0.005734  ,  0.414386  ,\n",
    "        0.1544144 , -0.191814  , -0.2675194 ,  0.0653194 ,  0.1829872 ,\n",
    "        0.290616  , -0.008922  ,  0.2243556 ,  0.0697846 ,  0.07361981,\n",
    "       -0.1629504 ,  0.17001   , -0.52244201, -0.0185994 ,  0.2284724 ,\n",
    "       -0.0518902 ,  0.1932424 , -0.3130024 ,  0.0506188 ,  0.050459  ,\n",
    "        0.29641   , -0.2854852 ,  0.000702  ,  0.0064622 , -0.36655999,\n",
    "       -0.1739664 ,  0.01311908, -0.25799618,  0.129018  , -0.53156001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = np.array([ -3.02941972e-02,  -8.59100111e-03,   4.35969993e-02,\n",
    "        -2.22849201e-01,   1.22254001e-01,  -1.06640801e-01,\n",
    "         1.34760812e-03,  -8.14858001e-02,   1.72767997e-02,\n",
    "         1.15293998e-01,   1.73920065e-02,  -1.63480705e-01,\n",
    "        -1.13961402e-01,   1.15037603e-01,   1.21960401e-01,\n",
    "         4.15838003e-02,  -7.77953982e-02,  -6.54366042e-02,\n",
    "         3.76957987e-02,   1.21770003e-01,   1.58715390e-02,\n",
    "         4.89195943e-02,   1.99452013e-02,  -3.36503997e-01,\n",
    "         1.16934001e-02,   1.76313998e-01,   1.55097196e-01,\n",
    "         1.58909991e-02,   9.59161982e-02,  -5.03308028e-02,\n",
    "         1.49623793e-01,  -6.66974042e-02,   1.59631262e-01,\n",
    "        -9.77100046e-02,   9.48232024e-02,  -1.90816000e-02,\n",
    "         4.18719370e-04,   2.33268005e-01,  -4.23953988e-02,\n",
    "        -1.95430758e-01,  -2.04257934e-01,   1.84860102e-01,\n",
    "         7.73687966e-02,  -9.36580002e-02,  -6.54597998e-02,\n",
    "        -2.12840001e-01,   7.58451991e-02,   4.73899983e-02,\n",
    "        -3.64982972e-01,   3.92242002e-01,  -1.26253341e-01,\n",
    "         1.44718400e-01,  -9.11842000e-02,  -6.15880042e-02,\n",
    "         3.53219971e-02,   5.27192026e-02,  -1.51871882e-01,\n",
    "        -7.40377992e-02,   1.33347379e-01,  -1.81688800e-01,\n",
    "        -1.49678596e-01,  -9.12774041e-02,  -9.50460583e-03,\n",
    "         1.70257202e-01,  -1.44753997e-01,   6.11200184e-03,\n",
    "        -1.82210001e-01,  -1.01643399e-01,   7.34320007e-02,\n",
    "         2.55164408e-01,  -1.25014382e-01,   8.76006022e-02,\n",
    "         1.27669797e-01,   2.66392007e-02,   1.05578603e-01,\n",
    "         8.91500056e-02,   1.82932400e-01,  -3.71673995e-01,\n",
    "        -4.30997986e-02,   1.18699200e-01,   5.81125978e-02,\n",
    "         6.59593992e-02,   3.25065194e-01,   5.47260195e-03,\n",
    "         1.22292000e-01,   7.01103985e-02,   7.75454196e-02,\n",
    "        -2.03751989e-02,   1.58489595e-01,   5.15808001e-02,\n",
    "        -2.43540019e-02,  -6.97748013e-02,   1.03765604e-01,\n",
    "        -1.25674799e-01,  -1.28850801e-01,  -1.58620209e-01,\n",
    "         1.05441963e-01,   2.85204399e-01,  -3.20115405e-01,\n",
    "        -5.80465978e-02,   3.01855996e-02,   7.44797960e-02,\n",
    "        -1.39411971e-02,  -2.11659598e-01,  -2.55691964e-02,\n",
    "         1.01462799e-01,  -4.62768468e-02,  -1.12397605e-01,\n",
    "         1.36114001e-02,  -3.62025987e-02,  -2.38461399e-01,\n",
    "         2.83709988e-02,  -9.81211968e-02,   7.13587988e-02,\n",
    "        -8.15757971e-02,  -2.86987804e-01,   1.97773999e-01,\n",
    "         9.33279991e-02,  -2.29008194e-01,   8.62035990e-02,\n",
    "         6.84594207e-02,   4.00867991e-02,   5.03083967e-02,\n",
    "         1.81129947e-02,   8.12834021e-02,  -4.10608606e-01,\n",
    "         2.68722002e-01,   2.48331999e-02,  -2.65882002e-01,\n",
    "         1.68868003e-01,   2.62938000e-01,  -1.06025399e-01,\n",
    "        -6.48609944e-02,  -1.61037799e-01,   6.46590026e-02,\n",
    "        -1.34562597e-01,  -2.21677999e-01,   1.00724497e-01,\n",
    "         7.02159740e-03,   9.17319804e-03,  -2.07966000e-02,\n",
    "        -3.59799616e-02,   2.35068206e-01,  -3.89145970e-02,\n",
    "         1.07817200e-01,   1.11474000e-01,  -1.32101204e-01,\n",
    "         2.03666609e-01,  -1.09156597e-01,  -1.37965605e-01,\n",
    "         1.67948003e-01,  -1.12996027e-02,  -1.15617201e-01,\n",
    "         1.21682998e-01,   8.07360008e-02,   1.20547399e-01,\n",
    "        -5.82441993e-02,  -1.04260057e-02,   1.32436007e-02,\n",
    "         1.96243999e-01,  -1.50959599e-01,   2.09732004e-02,\n",
    "         8.09341988e-02,   5.01667976e-02,   9.24072243e-02,\n",
    "         5.53332814e-02,  -4.11905191e-01,  -1.33904599e-01,\n",
    "         1.27767199e-01,  -2.31411402e-01,   1.49089199e-01,\n",
    "        -1.67326797e-01,   5.85971985e-02,   1.79354400e-01,\n",
    "        -1.90839995e-02,   2.89904399e-01,   8.04782014e-02,\n",
    "         3.73840891e-04,   4.26323988e-02,   3.71357985e-02,\n",
    "        -1.68309002e-01,   1.42635800e-01,  -7.14156006e-02,\n",
    "        -1.43311399e-01,  -2.24270808e-01,  -2.32027989e-02,\n",
    "        -1.69024394e-01,   3.70714599e-01,  -6.60784006e-02,\n",
    "        -1.17824599e-01,   2.42806603e-01,   1.63728006e-02,\n",
    "         7.11437999e-03,  -2.40348026e-02,  -1.19598024e-02,\n",
    "         3.91033992e-02,  -8.98745969e-02,  -1.01110402e-01,\n",
    "        -4.57934779e-02,  -2.45543065e-01,   1.43499441e-01,\n",
    "         1.87253090e-02,   1.33474001e-01,  -2.54519612e-02,\n",
    "        -3.14360075e-03,   7.02473976e-02,  -1.26675203e-01,\n",
    "        -1.02920400e-01,  -1.69724999e-01,  -1.46552026e-02,\n",
    "        -8.26387942e-02,  -4.73771989e-02,  -9.38656025e-02,\n",
    "        -8.79024003e-02,   2.53689995e-01,  -6.36480026e-02,\n",
    "        -2.64442006e-01,   3.38723802e-01,  -1.93343993e-01,\n",
    "        -2.48374401e-01,   8.98940042e-03,   9.22016054e-02,\n",
    "         6.99038606e-02,  -9.31808025e-02,  -4.87245996e-02,\n",
    "        -8.00629981e-02,   1.11128004e-01,  -2.38869973e-02,\n",
    "         3.58299864e-03,   1.48677940e-01,   4.77210049e-02,\n",
    "         1.24727000e-01,  -1.38971798e-01,   1.13520003e-01,\n",
    "        -3.22983998e-01,   8.33641980e-02,  -1.03348602e-01,\n",
    "        -1.58010796e-01,  -9.92539994e-02,  -2.71680202e-01,\n",
    "         1.16012198e-01,  -2.00044398e-01,  -9.03685991e-02,\n",
    "         1.12554805e-01,   6.23582035e-02,   4.44129992e-02,\n",
    "        -1.70414004e-01,   1.58297000e-01,  -1.89169202e-01,\n",
    "         4.01613386e-02,  -2.52391998e-02,  -3.58281970e-02,\n",
    "        -3.01191998e-01,   2.49625406e-01,  -3.36730003e-01,\n",
    "         1.44854401e-01,   2.25159992e-01,   1.51213999e-01,\n",
    "        -4.21675998e-01,   1.14360196e-01,   2.76694000e-02,\n",
    "         1.71860757e-01,   7.67917994e-02,   1.59523421e-01,\n",
    "        -2.57122804e-01,   2.66726004e-02,   1.58339021e-02,\n",
    "        -7.17266008e-02,  -5.74267991e-02,   1.63990400e-01,\n",
    "         1.01509798e-01,  -1.53264996e-01,  -1.47058201e-01,\n",
    "         1.55562998e-01,   2.11387996e-01,   4.08735994e-01,\n",
    "         6.40900105e-02,   1.42989001e-01,   2.06137206e-01,\n",
    "         2.38131724e-01,  -2.16013598e-01,   1.74998404e-01,\n",
    "        -2.16620004e-01,  -7.58000314e-03,   1.96230003e-01,\n",
    "        -3.66898011e-02,   1.10754202e-01,  -1.73872402e-01,\n",
    "        -1.70517981e-02,  -8.94763991e-02,   3.04676002e-01,\n",
    "        -1.01115800e-01,  -6.57439902e-03,   4.66485992e-02,\n",
    "        -3.00552399e-01,  -1.47147403e-01,   3.56325399e-02,\n",
    "        -1.14748199e-01,   3.33572075e-02,  -3.25230007e-01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_score_vecs = lr.predict(X_test)\n",
    "pred_scors = knn.predict(preds_score_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = list()\n",
    "Y_ = list()\n",
    "y = list()\n",
    "for rev in df.iterrows():\n",
    "    try:\n",
    "        score = rev[1][2]\n",
    "        vec = parse_np_array(rev[1][-1])\n",
    "        Y_.append(score_vect_dicts[score])\n",
    "        y.append(score)\n",
    "    except:\n",
    "        continue\n",
    "    X_.append(vec)\n",
    "X = np.array(X_)\n",
    "Y = np.array(Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "X_train = pad_sequences(X_train, maxlen=300, value=0.)\n",
    "X_test = pad_sequences(X_test, maxlen=300, value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train2 = pad_sequences(X_train2, maxlen=300, value=0.)\n",
    "X_test2 = pad_sequences(X_test2, maxlen=300, value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((688, 300), (296, 300))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, X_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Node 'init_19/NoOp': Unknown input node '^is_training/Assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1292\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1353\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1354\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Node 'init_19/NoOp': Unknown input node '^is_training/Assign'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a3b118af10a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_verbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, network, clip_gradients, tensorboard_verbose, tensorboard_dir, checkpoint_path, best_checkpoint_path, max_checkpoints, session, best_val_accuracy)\u001b[0m\n\u001b[1;32m     63\u001b[0m                                \u001b[0mmax_checkpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_checkpoints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                                \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                                best_val_accuracy=best_val_accuracy)\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train_ops, graph, clip_gradients, tensorboard_dir, tensorboard_verbose, checkpoint_path, best_checkpoint_path, max_checkpoints, keep_checkpoint_every_n_hours, random_seed, session, best_val_accuracy)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;31m# Fix for re-using sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m#initialize_uninit_variables(self.session)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Node 'init_19/NoOp': Unknown input node '^is_training/Assign'"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    net = tflearn.input_data([None, 300])\n",
    "    net = tflearn.embedding(net, input_dim=1000, output_dim=300)\n",
    "    net = tflearn.lstm(net, 300, dropout=0.8)\n",
    "    net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "    net = tflearn.regression(net, optimizer='adam', learning_rate=0.001)\n",
    "    \n",
    "    model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "    model.fit(X_train, Y_train, validation_set(X_test, Y_test), show_metric=True, patch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tflearn.input_data([None, 300])\n",
    "net = tflearn.embedding(net, input_dim=1000, output_dim=300)\n",
    "net = tflearn.lstm(net, 300, dropout=0.8)\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(X_train2, y_train, validation_set(X_test, y_test), show_metric=True, patch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
