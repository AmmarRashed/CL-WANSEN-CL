{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, pandas as pd, re, numpy as np, ast, warnings\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import chain, starmap\n",
    "from itertools import product\n",
    "import unicodedata\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import gensim\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>i love science fiction and i hate superheroes ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>the movie is absolutely incredible all the per...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>in a cinematic era dominated by reboots and mi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>movie review on rise of the planet of the apes...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>during experiments to find a cure for alzheime...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language    Movie_ID                                             Review  \\\n",
       "0       en  -800777728  i love science fiction and i hate superheroes ...   \n",
       "1       en  -800777728  the movie is absolutely incredible all the per...   \n",
       "2       en -1018312192  in a cinematic era dominated by reboots and mi...   \n",
       "3       en -1018312192  movie review on rise of the planet of the apes...   \n",
       "4       en -1018312192  during experiments to find a cure for alzheime...   \n",
       "\n",
       "   Score  \n",
       "0      9  \n",
       "1     10  \n",
       "2      8  \n",
       "3      4  \n",
       "4      7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/movie_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vects = gensim.models.KeyedVectors.load_word2vec_format(r\"../NLP_data/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_vects = gensim.models.KeyedVectors.load_word2vec_format(r\"../NLP_data/wiki.tr/wiki.tr.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "turkish_stemmer = TurkishStemmer()\n",
    "def clean(text, language=\"en\", stem=True):\n",
    "    global turkish_stemmer\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').lower().decode(\"ascii\")\n",
    "    \n",
    "    if language == \"tr\":\n",
    "        if stem:\n",
    "            text= ' '.join([turkish_stemmer.stem(w) for w in text.split()])\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r'[0-9]', '#', text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" \", text)\n",
    "    text = re.sub(r\"\\=\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\":\", \" \", text)\n",
    "    text = re.sub(r\"e(\\s)?-(\\s)?mail\", \"email\", text)\n",
    "\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    return TextBlob(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_SIZE = 300\n",
    "def vectorize(text, language):\n",
    "    global VECTOR_SIZE            \n",
    "    blob = clean(text, language)\n",
    "    vector = np.zeros(VECTOR_SIZE)\n",
    "    if len(blob.words) < 1:\n",
    "        return None\n",
    "\n",
    "    for word in blob.words:\n",
    "        try:\n",
    "            if language == \"en\":\n",
    "                vector += globals()[\"en_vects\"][word]\n",
    "            else:\n",
    "                vector += globals()[\"tr_vects\"][word]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    vector /= len(blob.words)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvec(x):\n",
    "    lang, rev = x.split(\":::::\")\n",
    "    return vectorize(rev, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_function(frame):\n",
    "    return np.mean(frame[\"rev_vec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LMSR\n",
    "def preprocess_data(df, language_column=\"Language\", review_column=\"Review\"):\n",
    "    LMSR_df = df.copy()\n",
    "    LMSR_df[\"lang_rev\"] = LMSR_df[[language_column, review_column]].apply(lambda x: x[0]+\":::::\"+x[1], axis=1)\n",
    "    LMSR_df[\"rev_vec\"] = LMSR_df[\"lang_rev\"].apply(lambda x:getvec(x))\n",
    "    LMSR_df.drop([\"lang_rev\", \"Review\"], axis=1, inplace=True)\n",
    "    return LMSR_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_vects(LMSR_df, movie_id_column=\"Movie_ID\", language_column=\"Language\", score_column=\"Score\"):\n",
    "    LMS_r = LMSR_df.groupby([movie_id_column,language_column,score_column], as_index=False).apply(merging_function)\n",
    "    LMS_r_df = LMS_r.reset_index().rename({0:\"rev_vec\"}, axis=1)\n",
    "    \n",
    "    merged_by_lang_and_movies = LMS_r_df.groupby(\n",
    "        [language_column,\n",
    "         score_column],\n",
    "        as_index=False).apply(merging_function).to_frame()\n",
    "    merged_by_lang_and_movies.reset_index(inplace=True)\n",
    "    \n",
    "    en_revs = dict()\n",
    "    tr_revs = dict()\n",
    "    for movie in LMS_r_df.set_index(movie_id_column).iterrows():\n",
    "        vec = movie[1][\"rev_vec\"]\n",
    "        lang = movie[1][language_column]\n",
    "        score = movie[1][score_column]\n",
    "        if lang == \"en\":\n",
    "            en_revs[score] = vec\n",
    "        else:\n",
    "            tr_revs[score] = vec\n",
    "    scores = sorted([i for i in tr_revs.keys() if i in en_revs.keys()])\n",
    "    \n",
    "    En_score_vecs = np.array([en_revs[sv] for sv in scores])  # English score vectors\n",
    "    Tr_score_vecs = np.array([tr_revs[sv] for sv in scores])  # Turkish score vectors\n",
    "    \n",
    "    # Minimizing the distance between Score vectors in different languages\n",
    "    W = MLPRegressor()\n",
    "    W.fit(En_score_vecs, Tr_score_vecs)\n",
    "    \n",
    "    # Merging score vectors across languages\n",
    "    scores_vects = dict()\n",
    "    for score in range(len(scores)random_satate):\n",
    "        scores_vects[scores[score]] = np.mean(\\\n",
    "            W.predict(np.atleast_2d(En_score_vecs[score])\\\n",
    "                    ), axis=0)\n",
    "    return scores_vects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_accuracy(y_true, y_predict):\n",
    "    res = 0\n",
    "    for i in range(len(y_true)):\n",
    "        res += abs(y_true[i]-y_predict[i])\n",
    "    return 1-res/(len(y_true)*len(set(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XYy(LMSR):\n",
    "    X = np.zeros((len(LMSR), 300))\n",
    "    Y = np.zeros((len(LMSR), 300))\n",
    "    y = np.zeros((len(LMSR)))\n",
    "    i = 0\n",
    "    for rev in LMSR.iterrows():\n",
    "        score = rev[1][2]\n",
    "        rev_vec = rev[1][3]\n",
    "        score_vec = rev[1][4]\n",
    "\n",
    "        X[i] = rev_vec\n",
    "        Y[i] = score_vec\n",
    "        y[i] = score\n",
    "\n",
    "        i += 1\n",
    "    return X, Y, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(df, train_index, regressor=MLPRegressor(), classifier=MLPClassifier(), dim_reduct=PCA(), random_state=42):\n",
    "    LMSR = preprocess_data(df.loc[train_index])\n",
    "    score_vect_dicts = get_score_vects(LMSR)\n",
    "    LMSR[\"score_vec\"] = LMSR[\"Score\"].apply(lambda x: score_vect_dicts[x] if x in score_vect_dicts else np.NaN)\n",
    "    LMSR.dropna(inplace=True)\n",
    "    \n",
    "    X, Y, y = get_XYy(LMSR)\n",
    "    \n",
    "    regressor. random_state = random_state\n",
    "    classifier.random_state = random_state\n",
    "    dim_reduct.random_state = random_state\n",
    "    \n",
    "    if dim_reduct is not None:\n",
    "        dim_reduct.fit(X)\n",
    "        dim_reduct.transform(X)\n",
    "    regressor.fit(X, Y)\n",
    "    classifier.fit(Y, y)\n",
    "    return regressor, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, test_index, regressor, classifier):\n",
    "    LMSR = preprocess_data(df.loc[test_index])\n",
    "    score_vect_dicts = get_score_vects(LMSR)\n",
    "    LMSR[\"score_vec\"] = LMSR[\"Score\"].apply(lambda x: score_vect_dicts[x] if x in score_vect_dicts else np.NaN)\n",
    "    LMSR.dropna(inplace=True)\n",
    "    \n",
    "    X, Y, y = get_XYy(LMSR)\n",
    "    \n",
    "    preds_score_vecs = regressor.predict(X)\n",
    "    pred_scores = classifier.predict(preds_score_vecs)\n",
    "    \n",
    "    return pred_scores, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial:\t1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:\t1\n",
      "Score:\t0.7774436090225564\n",
      "K:\t2\n",
      "Score:\t0.7447916666666667\n",
      "K:\t3\n",
      "Score:\t0.7601010101010102\n",
      "K:\t4\n",
      "Score:\t0.7868480725623583\n",
      "K:\t5\n",
      "Score:\t0.7563775510204082\n",
      "K:\t6\n",
      "Score:\t0.6390168970814132\n",
      "K:\t7\n",
      "Score:\t0.7430555555555556\n",
      "K:\t8\n",
      "Score:\t0.781786941580756\n",
      "K:\t9\n",
      "Score:\t0.7453416149068324\n",
      "K:\t10\n",
      "Score:\t0.7195121951219512\n",
      "**********\n",
      "Trial0 avg score:\t 0.7454275113619508\n",
      "------------------------------\n",
      "Trial:\t2\n",
      "K:\t1\n",
      "Score:\t0.7443609022556391\n",
      "K:\t2\n",
      "Score:\t0.72265625\n",
      "K:\t3\n",
      "Score:\t0.7550505050505051\n",
      "K:\t4\n",
      "Score:\t0.7868480725623583\n",
      "K:\t5\n",
      "Score:\t0.5051020408163265\n",
      "K:\t6\n",
      "Score:\t0.7572964669738863\n",
      "K:\t7\n",
      "Score:\t0.7135416666666667\n",
      "K:\t8\n",
      "Score:\t0.7474226804123711\n",
      "K:\t9\n",
      "Score:\t0.7888198757763976\n",
      "K:\t10\n",
      "Score:\t0.7286585365853658\n",
      "**********\n",
      "Trial1 avg score:\t 0.7249756997099517\n",
      "------------------------------\n",
      "Trial:\t3\n",
      "K:\t1\n",
      "Score:\t0.7669172932330828\n",
      "K:\t2\n",
      "Score:\t0.7135416666666667\n",
      "K:\t3\n",
      "Score:\t0.7815656565656566\n",
      "K:\t4\n",
      "Score:\t0.8106575963718821\n",
      "K:\t5\n",
      "Score:\t0.7206632653061225\n",
      "K:\t6\n",
      "Score:\t0.7511520737327189\n",
      "K:\t7\n",
      "Score:\t0.6736111111111112\n",
      "K:\t8\n",
      "Score:\t0.7766323024054983\n",
      "K:\t9\n",
      "Score:\t0.7406832298136645\n",
      "K:\t10\n",
      "Score:\t0.7042682926829269\n",
      "**********\n",
      "Trial2 avg score:\t 0.7439692487889331\n",
      "------------------------------\n",
      "Trial:\t4\n",
      "K:\t1\n",
      "Score:\t0.7729323308270677\n",
      "K:\t2\n",
      "Score:\t0.7239583333333333\n",
      "K:\t3\n",
      "Score:\t0.7411616161616161\n",
      "K:\t4\n",
      "Score:\t0.7811791383219955\n",
      "K:\t5\n",
      "Score:\t0.6938775510204082\n",
      "K:\t6\n",
      "Score:\t0.728110599078341\n",
      "K:\t7\n",
      "Score:\t0.7465277777777778\n",
      "K:\t8\n",
      "Score:\t0.7869415807560137\n",
      "K:\t9\n",
      "Score:\t0.7717391304347826\n",
      "K:\t10\n",
      "Score:\t0.7439024390243902\n",
      "**********\n",
      "Trial3 avg score:\t 0.7490330496735725\n",
      "------------------------------\n",
      "Trial:\t5\n",
      "K:\t1\n",
      "Score:\t0.7548872180451127\n",
      "K:\t2\n",
      "Score:\t0.6640625\n",
      "K:\t3\n",
      "Score:\t0.7853535353535354\n",
      "K:\t4\n",
      "Score:\t0.7845804988662132\n",
      "K:\t5\n",
      "Score:\t0.7346938775510203\n",
      "K:\t6\n",
      "Score:\t0.7419354838709677\n",
      "K:\t7\n",
      "Score:\t0.734375\n",
      "K:\t8\n",
      "Score:\t0.7542955326460481\n",
      "K:\t9\n",
      "Score:\t0.7531055900621118\n",
      "K:\t10\n",
      "Score:\t0.7286585365853658\n",
      "**********\n",
      "Trial4 avg score:\t 0.7435947772980376\n",
      "------------------------------\n",
      "Trial:\t6\n",
      "K:\t1\n",
      "Score:\t0.7744360902255639\n",
      "K:\t2\n",
      "Score:\t0.73046875\n",
      "K:\t3\n",
      "Score:\t0.7626262626262627\n",
      "K:\t4\n",
      "Score:\t0.780045351473923\n",
      "K:\t5\n",
      "Score:\t0.7729591836734694\n",
      "K:\t6\n",
      "Score:\t0.7542242703533026\n",
      "K:\t7\n",
      "Score:\t0.7013888888888888\n",
      "K:\t8\n",
      "Score:\t0.7989690721649485\n",
      "K:\t9\n",
      "Score:\t0.7484472049689441\n",
      "K:\t10\n",
      "Score:\t0.7317073170731707\n",
      "**********\n",
      "Trial5 avg score:\t 0.7555272391448475\n",
      "------------------------------\n",
      "Trial:\t7\n",
      "K:\t1\n",
      "Score:\t0.7443609022556391\n",
      "K:\t2\n",
      "Score:\t0.734375\n",
      "K:\t3\n",
      "Score:\t0.7487373737373737\n",
      "K:\t4\n",
      "Score:\t0.7607709750566893\n",
      "K:\t5\n",
      "Score:\t0.6938775510204082\n",
      "K:\t6\n",
      "Score:\t0.7235023041474654\n",
      "K:\t7\n",
      "Score:\t0.7013888888888888\n",
      "K:\t8\n",
      "Score:\t0.7439862542955327\n",
      "K:\t9\n",
      "Score:\t0.7422360248447205\n",
      "K:\t10\n",
      "Score:\t0.6676829268292683\n",
      "**********\n",
      "Trial6 avg score:\t 0.7260918201075985\n",
      "------------------------------\n",
      "Trial:\t8\n",
      "K:\t1\n",
      "Score:\t0.6090225563909775\n",
      "K:\t2\n",
      "Score:\t0.7630208333333334\n",
      "K:\t3\n",
      "Score:\t0.726010101010101\n",
      "K:\t4\n",
      "Score:\t0.7959183673469388\n",
      "K:\t5\n",
      "Score:\t0.7168367346938775\n",
      "K:\t6\n",
      "Score:\t0.7434715821812596\n",
      "K:\t7\n",
      "Score:\t0.6927083333333333\n",
      "K:\t8\n",
      "Score:\t0.738831615120275\n",
      "K:\t9\n",
      "Score:\t0.7298136645962733\n",
      "K:\t10\n",
      "Score:\t0.7195121951219512\n",
      "**********\n",
      "Trial7 avg score:\t 0.723514598312832\n",
      "------------------------------\n",
      "Trial:\t9\n",
      "K:\t1\n",
      "Score:\t0.7804511278195488\n",
      "K:\t2\n",
      "Score:\t0.7356770833333333\n",
      "K:\t3\n",
      "Score:\t0.7588383838383839\n",
      "K:\t4\n",
      "Score:\t0.8027210884353742\n",
      "K:\t5\n",
      "Score:\t0.7653061224489796\n",
      "K:\t6\n",
      "Score:\t0.749615975422427\n",
      "K:\t7\n",
      "Score:\t0.6979166666666667\n",
      "K:\t8\n",
      "Score:\t0.7697594501718213\n",
      "K:\t9\n",
      "Score:\t0.7515527950310559\n",
      "K:\t10\n",
      "Score:\t0.7195121951219512\n",
      "**********\n",
      "Trial8 avg score:\t 0.7531350888289542\n",
      "------------------------------\n",
      "Trial:\t10\n",
      "K:\t1\n",
      "Score:\t0.7684210526315789\n",
      "K:\t2\n",
      "Score:\t0.6770833333333333\n",
      "K:\t3\n",
      "Score:\t0.7348484848484849\n",
      "K:\t4\n",
      "Score:\t0.7970521541950113\n",
      "K:\t5\n",
      "Score:\t0.7704081632653061\n",
      "K:\t6\n",
      "Score:\t0.7619047619047619\n",
      "K:\t7\n",
      "Score:\t0.7482638888888888\n",
      "K:\t8\n",
      "Score:\t0.7508591065292096\n",
      "K:\t9\n",
      "Score:\t0.7329192546583851\n",
      "K:\t10\n",
      "Score:\t0.7652439024390244\n",
      "**********\n",
      "Trial9 avg score:\t 0.7507004102693985\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = 10\n",
    "scores = list(np.zeros(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    print(\"Trial:\\t{}\".format(i+1))\n",
    "    score_dict = {\"distance_accuracy\":0}\n",
    "    k = 0\n",
    "    for train_index, test_index in skf.split(df[\"Review\"], df[\"Language\"]):\n",
    "        regressor, classifier = fit(df, train_index, random_state=i)\n",
    "        preds, true = predict(df, test_index, regressor, classifier)\n",
    "        s = distance_accuracy(true, preds)\n",
    "        score_dict[\"distance_accuracy\"] += s\n",
    "        k += 1\n",
    "        print(\"K:\\t{}\\nScore:\\t{}\".format(k, s))\n",
    "    score_dict[\"distance_accuracy\"] /= 10.0\n",
    "    scores[i] = score_dict[\"distance_accuracy\"]\n",
    "    print(\"*\"*10)\n",
    "    print(\"Trial{} avg score:\\t {}\".format(i, score_dict[\"distance_accuracy\"]))\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.741597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.723515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.730468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.744698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.750284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.755527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "count  10.000000\n",
       "mean    0.741597\n",
       "std     0.012171\n",
       "min     0.723515\n",
       "25%     0.730468\n",
       "50%     0.744698\n",
       "75%     0.750284\n",
       "max     0.755527"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.DataFrame(list(scores))\n",
    "stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
