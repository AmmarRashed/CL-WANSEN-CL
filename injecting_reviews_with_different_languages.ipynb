{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, pickle, ast, unicodedata, re\n",
    "from googletrans import Translator\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "      <th>tokenized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>i love science fiction and i hate superheroes ...</td>\n",
       "      <td>9</td>\n",
       "      <td>['love', 'science', 'fiction', 'hate', 'superh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>the movie is absolutely incredible all the per...</td>\n",
       "      <td>10</td>\n",
       "      <td>['the', 'movie', 'absolutely', 'incredible', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>in a cinematic era dominated by reboots and mi...</td>\n",
       "      <td>8</td>\n",
       "      <td>['cinematic', 'era', 'dominated', 'reboots', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>movie review on rise of the planet of the apes...</td>\n",
       "      <td>4</td>\n",
       "      <td>['movie', 'review', 'rise', 'the', 'planet', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>during experiments to find a cure for alzheime...</td>\n",
       "      <td>7</td>\n",
       "      <td>['during', 'experiments', 'find', 'cure', 'for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language    Movie_ID                                             Review  \\\n",
       "0       en  -800777728  i love science fiction and i hate superheroes ...   \n",
       "1       en  -800777728  the movie is absolutely incredible all the per...   \n",
       "2       en -1018312192  in a cinematic era dominated by reboots and mi...   \n",
       "3       en -1018312192  movie review on rise of the planet of the apes...   \n",
       "4       en -1018312192  during experiments to find a cure for alzheime...   \n",
       "\n",
       "   Score                                  tokenized_reviews  \n",
       "0      9  ['love', 'science', 'fiction', 'hate', 'superh...  \n",
       "1     10  ['the', 'movie', 'absolutely', 'incredible', '...  \n",
       "2      8  ['cinematic', 'era', 'dominated', 'reboots', '...  \n",
       "3      4  ['movie', 'review', 'rise', 'the', 'planet', '...  \n",
       "4      7  ['during', 'experiments', 'find', 'cure', 'for...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/tokenized_reviews.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(tweet):\n",
    "    text = unicodedata.normalize('NFKD', tweet).encode('ascii', 'ignore').lower().decode(\"ascii\")\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r'[0-9]', '#', text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vects = gensim.models.KeyedVectors.load_word2vec_format(r\"GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_vects = gensim.models.KeyedVectors.load_word2vec_format(r\"wiki.tr/wiki.tr.vec\", binary=False)\n",
    "# tr_vects = gensim.models.Word2Vec.load(\"wiki.tr/wiki.tr.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_word2cluster = pickle.load(open(\"datasets/en_word2cluster.pickle\", \"rb\"))\n",
    "tr_word2cluster = pickle.load(open(\"datasets/tr_word2cluster.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "stemmer = TurkishStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df, translate_freq=0.75):\n",
    "    inv_langs = {\"en\":\"tr\", \"tr\":\"en\"}\n",
    "    new_df = dict()\n",
    "    for row in df.iterrows():\n",
    "        src = row[1][\"Language\"]\n",
    "        score = row[1][\"Score\"]\n",
    "        trgt = inv_langs[src]\n",
    "        tokens = clean(row[1][\"Review\"]).split()\n",
    "        \n",
    "        vector = np.zeros(300)\n",
    "        clust_vector = np.zeros(300)\n",
    "        \n",
    "        for word in tokens:\n",
    "            try:\n",
    "                if np.random.random() >= translate_freq:\n",
    "                    translated_word = clean(translator.translate(stemmer.stem(word), src=src, dest=trgt).text)\n",
    "                    if trgt == 'tr':  ## English > Turkish\n",
    "                        vector += globals()[\"tr_vects\"][translated_word]\n",
    "                        clust_vector += globals()[\"tr_word2cluster\"][translated_word]\n",
    "                    else:  ## Turkish > English\n",
    "                        vector += globals()[\"en_vects\"][translated_word]\n",
    "                        clust_vector += globals()[\"en_word2cluster\"][translated_word]\n",
    "                elif src == 'tr':\n",
    "                    vector += globals()[\"tr_vects\"][stemmer.stem(word)]\n",
    "                    clust_vector += globals()[\"tr_word2cluster\"][stemmer.stem(word)]\n",
    "                else:\n",
    "                    vector += globals()[\"en_vects\"][word]\n",
    "                    clust_vector += globals()[\"en_word2cluster\"][stemmer.stem(word)]\n",
    "            except:  # Keyerror or JSONDecodeError\n",
    "                continue\n",
    "    new_df[row[0]] = [score, vector/len(tokens), clust_vector/len(tokens)]\n",
    "    return pd.DataFrame.from_dict(new_df, 'index').rename({0:\"Score\", 1:\"bow_word2vec\", 2:\"bow_clust2vec\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_df = vectorize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_csv(\"labeled_bow.csv\", index_label=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vectorize_clust(review, src, trgt):\n",
    "#     global en_word2cluster, tr_word2cluster\n",
    "#     tokens = clean(review).split()\n",
    "#     vectors = np.zeros(300)\n",
    "#     for word in tokens:\n",
    "#         try:\n",
    "#             if np.random.random() >= 0.5:\n",
    "#                 if trgt == 'tr':  ## English > Turkish\n",
    "#                     vectors += tr_word2cluster[clean(translator.translate(stemmer.stem(word), src=src, dest=trgt).text)]\n",
    "#                 else:  ## Turkish > English\n",
    "#                     vectors += en_word2cluster[clean(translator.translate(word, src=src, dest=trgt).text)]\n",
    "#             elif src == 'tr':\n",
    "#                 vectors += tr_word2cluster[stemmer.stem(word)]\n",
    "#             else:\n",
    "#                 vectors += en_word2cluster[word]\n",
    "#         except:  # Keyerror or JSONDecodeError\n",
    "#             continue\n",
    "#     return vectors/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
