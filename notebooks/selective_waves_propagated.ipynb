{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle, pandas as pd, re, numpy as np, ast, warnings\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import time\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import chain, starmap\n",
    "from itertools import product\n",
    "import unicodedata\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import gensim\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>i love science fiction and i hate superheroes ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>the movie is absolutely incredible all the per...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>in a cinematic era dominated by reboots and mi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>movie review on rise of the planet of the apes...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>during experiments to find a cure for alzheime...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language    Movie_ID                                             Review  \\\n",
       "0       en  -800777728  i love science fiction and i hate superheroes ...   \n",
       "1       en  -800777728  the movie is absolutely incredible all the per...   \n",
       "2       en -1018312192  in a cinematic era dominated by reboots and mi...   \n",
       "3       en -1018312192  movie review on rise of the planet of the apes...   \n",
       "4       en -1018312192  during experiments to find a cure for alzheime...   \n",
       "\n",
       "   Score  \n",
       "0      9  \n",
       "1     10  \n",
       "2      8  \n",
       "3      4  \n",
       "4      7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv(\"../datasets/movie_data.csv\")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Language  Movie_ID  Review\n",
       "Score                            \n",
       "1            29        29      29\n",
       "2            21        21      21\n",
       "3            14        14      14\n",
       "4            23        23      23\n",
       "5            83        83      83\n",
       "6            43        43      43\n",
       "7            71        71      71\n",
       "8           207       207     207\n",
       "9           175       175     175\n",
       "10          334       334     334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.groupby(\"Score\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vects = gensim.models.KeyedVectors.load_word2vec_format(r\"../../NLP_data/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_vects = gensim.models.KeyedVectors.load_word2vec_format(r\"../../NLP_data/wiki.tr/wiki.tr.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "turkish_stemmer = TurkishStemmer()\n",
    "def clean(text, language=\"en\", stem=True):\n",
    "    global turkish_stemmer\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').lower().decode(\"ascii\")\n",
    "    \n",
    "    if language == \"tr\":\n",
    "        if stem:\n",
    "            text= ' '.join([turkish_stemmer.stem(w) for w in text.split()])\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r'[0-9]', '#', text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" \", text)\n",
    "    text = re.sub(r\"\\=\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\":\", \" \", text)\n",
    "    text = re.sub(r\"e(\\s)?-(\\s)?mail\", \"email\", text)\n",
    "\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    return TextBlob(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_SIZE = 300\n",
    "def vectorize(text, language):\n",
    "    global VECTOR_SIZE            \n",
    "    blob = clean(text, language)\n",
    "    vector = np.zeros(VECTOR_SIZE)\n",
    "    if len(blob.words) < 1:\n",
    "        return None\n",
    "\n",
    "    for word in blob.words:\n",
    "        try:\n",
    "            if language == \"en\":\n",
    "                vector += globals()[\"en_vects\"][word]\n",
    "            else:\n",
    "                vector += globals()[\"tr_vects\"][word]\n",
    "        except KeyError as e:\n",
    "#             warnings.warn(str(e))\n",
    "            continue\n",
    "    vector /= max(len(blob.words),1)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvec(x):\n",
    "    lang, rev = x.split(\":::::\")\n",
    "    return vectorize(rev, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LMSR\n",
    "def preprocess_data(df, language_column=\"Language\", review_column=\"Review\"):\n",
    "    LMSR_df = df.copy()\n",
    "    LMSR_df[\"lang_rev\"] = LMSR_df[[language_column, review_column]].apply(lambda x: x[0]+\":::::\"+x[1], axis=1)\n",
    "    LMSR_df[\"rev_vec\"] = LMSR_df[\"lang_rev\"].apply(lambda x:getvec(x))\n",
    "    LMSR_df.drop([\"lang_rev\", \"Review\"], axis=1, inplace=True)\n",
    "    return LMSR_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_accuracy(y_true, y_predict):\n",
    "    res = 0\n",
    "    for i in range(len(y_true)):\n",
    "        res += abs(y_true[i]-y_predict[i])\n",
    "    return 1-res/(len(y_true)*len(set(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XYy(LMSR):\n",
    "    X = np.zeros((len(LMSR), VECTOR_SIZE))\n",
    "    Y = np.zeros((len(LMSR), VECTOR_SIZE))\n",
    "    y = np.zeros((len(LMSR)))\n",
    "    i = 0\n",
    "    for rev in LMSR.iterrows():\n",
    "        score = rev[1][2]\n",
    "        rev_vec = rev[1][3]\n",
    "        score_vec = rev[1][4]\n",
    "\n",
    "        X[i] = rev_vec\n",
    "        Y[i] = score_vec\n",
    "        y[i] = score\n",
    "\n",
    "        i += 1\n",
    "    return X, Y, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derive=False):\n",
    "    if derive:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dict(df, get_L2and3=False):\n",
    "    data_dict = dict() #{language:{score: {movie_id: [rev1, rev2, ..., revn]}}}\n",
    "    L1 = dict()  # {(languge, score, movie_id): list of reviews with the same score with the same language}\n",
    "    L2 = dict()  # {(language, score): None}\n",
    "    L3 = dict()  # {score: None}\n",
    "    for _, row in df.iterrows():\n",
    "        lang = row[\"Language\"]\n",
    "        movie_id = row[\"Movie_ID\"]\n",
    "        score = row[\"Score\"]\n",
    "        review = row[\"rev_vec\"]\n",
    "\n",
    "        data_dict.setdefault(lang, {})\n",
    "        data_dict[lang].setdefault(score, {})\n",
    "        data_dict[lang][score].setdefault(movie_id, [])\n",
    "        data_dict[lang][score][movie_id].append(review)\n",
    "        \n",
    "        L1.setdefault((lang, score, movie_id), list())\n",
    "        L1[(lang, score, movie_id)].append(review)\n",
    "        if get_L2and3:    \n",
    "            L2[(lang, score)] = None\n",
    "            L3[score] = None\n",
    "    if get_L2and3:\n",
    "        return data_dict, L1, L2, L3\n",
    "    return data_dict, L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_L2(LSM_R, data_dict):\n",
    "    L2 = dict()  # {(language, score): list of movies vectors}\n",
    "    for language in data_dict:\n",
    "        for score in data_dict[language]:\n",
    "            for movie_id in data_dict[language][score]:\n",
    "                L2.setdefault((language, score), list())\n",
    "                L2[(language, score)].append(LSM_R[(language, score, movie_id)])\n",
    "    return L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_L3(LS_MR, data_dict):\n",
    "    L3 = dict()  # {score: vector of merged languages for that score}\n",
    "    for language in data_dict:\n",
    "        for score in data_dict[language]:\n",
    "            L3.setdefault(score, list())\n",
    "            L3[score].append(LS_MR[(language, score)])\n",
    "    return L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(L, W):\n",
    "    merged = dict()  # {item: vector of merged subitems}\n",
    "    for i, item in enumerate(sorted(L)):\n",
    "        for subitem in L[item]:\n",
    "            merged.setdefault(item, [np.zeros(VECTOR_SIZE),0])\n",
    "            merged[item][0] += sigmoid(subitem.dot(W[i]))\n",
    "            merged[item][1] += 1\n",
    "    for item in merged:\n",
    "        merged[item] = merged[item][0]/ merged[item][1]\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(L, delta, W, alpha=0.1):\n",
    "    for i, k in enumerate(sorted(L)):\n",
    "        for l in L[k]:\n",
    "            W[i] += l.T.dot(delta[i]) *alpha\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_error(delta, W):\n",
    "    error = 0\n",
    "    for i in range(len(delta)):\n",
    "        error += delta[i].dot(W[i].T)\n",
    "    return error/len(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_delta(error, layer, size):\n",
    "    delta = np.zeros((size, VECTOR_SIZE))\n",
    "    j = 0\n",
    "    for i,k in enumerate(sorted(layer)):\n",
    "        for l in layer[k]:\n",
    "            delta[j] = error[i]*sigmoid(l, True)\n",
    "            j += 1\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_vects(df, iterations=100, alpha=0.1, random_state=42, W1=None, W2=None, W3=None, W4=None):\n",
    "    LSMR = preprocess_data(df)\n",
    "    data_dict, L1 = get_data_dict(LSMR)\n",
    "    y = softmax(list(LSMR.Score))\n",
    "#     np.random.seed(random_state)\n",
    "    learning_curve = dict()\n",
    "    for i in range(iterations+1):\n",
    "        # forward propagation\n",
    "        if W1 is None:\n",
    "            W1 = 2*np.random.random((len(L1), 300, 300))-1\n",
    "\n",
    "        LSM_R = merge(L1, W1)\n",
    "        L2 = get_L2(LSM_R, data_dict)\n",
    "        if W2 is None:\n",
    "            W2 = 2*np.random.random((len(L2), 300, 300))-1\n",
    "\n",
    "        LS_MR = merge(L2, W2)\n",
    "        L3 = get_L3(LS_MR, data_dict)\n",
    "        if W3 is None:\n",
    "            W3 = 2*np.random.random((len(L3), 300, 300))-1\n",
    "\n",
    "        score_vectors_dict = merge(L3, W3)\n",
    "        l4 = sigmoid(np.array([v for k, v in sorted(score_vectors_dict.items())]))\n",
    "        if W4 is None:\n",
    "            W4 = 2*np.random.random((300, len(LSMR)))-1\n",
    "        \n",
    "        l5 = softmax(l4.dot(W4))  # predicted scores\n",
    "        \n",
    "        # Calculate the error\n",
    "        l5_error = np.mean(np.dot(np.log(l5), y))\n",
    "        \n",
    "        # Back propagation\n",
    "        l5_delta = l5_error * sigmoid(l5, True)\n",
    "        W4 += l4.T.dot(l5_delta)*alpha\n",
    "        \n",
    "        l4_error = l5_delta.dot(W4.T)\n",
    "        l4_delta = l4_error * sigmoid(l4, True)\n",
    "        \n",
    "        W3 = update_weights(L3, l4_delta, W3, alpha)\n",
    "        \n",
    "        l3_error = get_layer_error(l4_delta, W3)\n",
    "        l3_delta = get_layer_delta(l3_error, L3, len(L2))\n",
    "        \n",
    "        W2 = update_weights(L2, l3_delta, W2, alpha)\n",
    "        \n",
    "        l2_error = get_layer_error(l3_delta, W2)\n",
    "        l2_delta = get_layer_delta(l2_error, L2, len(LSMR))\n",
    "        \n",
    "        W1 = update_weights(L1, l2_delta, W1, alpha)\n",
    "        learning_curve[i] = l5_error\n",
    "        if i%10 == 0:\n",
    "            print(\"epoch {}:\\t{}\".format(i, np.abs(l5_error)))\n",
    "        if i%100 == 0:\n",
    "            alpha *= 0.9\n",
    "    return LSMR, score_vectors_dict, learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(LSMR, score_vect_dicts,random_state=42, regressor=MLPRegressor(), classifier=MLPClassifier()):\n",
    "    LSMR[\"score_vec\"] = LSMR[\"Score\"].apply(lambda x: score_vect_dicts[x] if x in score_vect_dicts else np.NaN)\n",
    "    LSMR.dropna(inplace=True)\n",
    "    \n",
    "    X, Y, y = get_XYy(LSMR)\n",
    "    \n",
    "    regressor.random_state = random_state\n",
    "    classifier.random_state = random_state\n",
    "        \n",
    "    regressor.fit(X, Y)\n",
    "    classifier.fit(Y, y)\n",
    "    return regressor, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(LSMR, score_vect_dicts, regressor, classifier):\n",
    "    LSMR[\"score_vec\"] = LSMR[\"Score\"].apply(lambda x: score_vect_dicts[x] if x in score_vect_dicts else np.NaN)\n",
    "    LSMR.dropna(inplace=True)\n",
    "    \n",
    "    X, Y, y = get_XYy(LSMR)\n",
    "    \n",
    "    preds_score_vecs = regressor.predict(X)\n",
    "    pred_scores = classifier.predict(preds_score_vecs)\n",
    "    \n",
    "    return pred_scores, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language    0\n",
       "Movie_ID    0\n",
       "Score       0\n",
       "rev_vec     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tronly_test_raw = df_full[-100:]\n",
    "tronly_test = preprocess_data(tronly_test_raw)\n",
    "df = df_full[:-100]\n",
    "tronly_test[tronly_test.Language==\"en\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models(model, train, test, tronly, ytrain, ytest, ytronly):\n",
    "    _ = time.time()\n",
    "    model.fit(train, ytrain)\n",
    "    predtra = time.time()-_\n",
    "    \n",
    "    _ = time.time()\n",
    "    predtrain = model.predict(train)\n",
    "    trat = time.time()-_\n",
    "    s_train = distance_accuracy(ytrain, predtrain)\n",
    "    f1_train = f1_score(ytrain, predtrain, average='weighted')\n",
    "    \n",
    "    _ = time.time()\n",
    "    predtest= model.predict(test)\n",
    "    tet = time.time()-_\n",
    "    s_test = distance_accuracy(ytest, predtest)\n",
    "    f1_test = f1_score(ytest, predtest, average='weighted')\n",
    "    \n",
    "    _ = time.time()\n",
    "    predtronly = model.predict(tronly)\n",
    "    trt = time.time()-_\n",
    "    s_tr = distance_accuracy(ytronly, predtronly)\n",
    "    f1_tronly = f1_score(ytronly, predtronly, average='weighted')\n",
    "    \n",
    "    evals = OrderedDict()\n",
    "    evals[\"Train\"] = s_train\n",
    "    evals[\"Test\"] = s_test\n",
    "    evals[\"Tr. Only\"] = s_tr\n",
    "    evals[\"Training Time\"] = trat\n",
    "    evals[\"Pred.Tra. Time\"] = predtra\n",
    "    evals[\"Testing Time\"] = tet\n",
    "    evals[\"Tr.Test Time\"] = trt\n",
    "    evals[\"F1 Test\"] = f1_test\n",
    "    evals[\"F1 Train\"] = f1_train\n",
    "    evals[\"F1 Tr. only\"] = f1_tronly\n",
    "    return evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_average(scores_tables):\n",
    "#     scores_tables: {i_th trial:\n",
    "#                     {k_th fold:\n",
    "#                         {'Model': {'Test': 0.8090301003344482,\n",
    "#                                    'Train': 0.783361064891847,\n",
    "#                                    'Turkish only': 0.7414285714285714}}}\n",
    "    avgs = dict()\n",
    "    for trial in scores_tables:\n",
    "        for table in scores_tables[trial]:\n",
    "            for model in scores_tables[trial][table]:\n",
    "                avgs.setdefault(model, dict())\n",
    "                for metric, score in scores_tables[trial][table][model].items():\n",
    "                    avgs[model].setdefault(metric, list())\n",
    "                    avgs[model][metric].append(score)\n",
    "    for model in avgs:\n",
    "        for metric in avgs[model]:\n",
    "            avgs[model][metric] = np.mean(avgs[model][metric])\n",
    "    return pd.DataFrame(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_score(trial_scores_tables):\n",
    "#  trial_scores_tables: {k_th fold:\n",
    "#                             {'Model': {'Test': 0.8090301003344482,\n",
    "#                                        'Train': 0.783361064891847,\n",
    "#                                        'Turkish only': 0.7414285714285714}}}\n",
    "    avgs = dict()\n",
    "    for table in trial_scores_tables:\n",
    "        for model in trial_scores_tables[table]:\n",
    "            avgs.setdefault(model, dict())\n",
    "            for metric, score in trial_scores_tables[table][model].items():\n",
    "                avgs[model].setdefault(metric, list())\n",
    "                avgs[model][metric].append(score)\n",
    "    for model in avgs:\n",
    "        for metric in avgs[model]:\n",
    "            avgs[model][metric] = np.mean(avgs[model][metric])\n",
    "    return pd.DataFrame(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_selectivewaves_regclass(df, tronly_test_raw, NUM_TRIALS=1, splits=10):  \n",
    "    learning_curves = dict()\n",
    "    scores_tables = OrderedDict()\n",
    "    for i in range(NUM_TRIALS):\n",
    "        print(\"Trial:\\t{}\".format(i+1))\n",
    "        scores_tables[i] = OrderedDict()\n",
    "        learning_curves[i] = OrderedDict()\n",
    "        k = 0\n",
    "        skf = StratifiedKFold(n_splits=splits, random_state=i)\n",
    "        for train_index, test_index in skf.split(df[\"Review\"], df[\"Language\"]):\n",
    "            print(\"K:\\t{}\".format(k+1))\n",
    "            scores_tables[i][k] = OrderedDict()\n",
    "            start = time.time()\n",
    "            LSMR, score_vect_dicts, training_curve = get_score_vects(\n",
    "                df.loc[train_index], random_state=i, alpha=1e-5, iterations=50)\n",
    "            regressor, classifier = fit(LSMR, score_vect_dicts, random_state=i)\n",
    "            trat = time.time()- start\n",
    "\n",
    "            test_data = preprocess_data(df.loc[test_index])\n",
    "            _ = time.time()\n",
    "            preds, true = predict(test_data, score_vect_dicts, regressor, classifier)\n",
    "            tet = time.time()-_\n",
    "\n",
    "            _ = time.time()\n",
    "            preds_train, true_train = predict(preprocess_data(df.loc[train_index]),\n",
    "                                              score_vect_dicts,\n",
    "                                              regressor, classifier)\n",
    "            predtra = time.time()-_\n",
    "\n",
    "            _ = time.time()\n",
    "            preds_tr, true_tr = predict(tronly_test, score_vect_dicts, regressor, classifier)\n",
    "            trt = time.time()-_\n",
    "\n",
    "            elapsed = time.time()-start\n",
    "\n",
    "            s = distance_accuracy(true, preds)\n",
    "            f1_test = f1_score(true, preds, average='weighted')\n",
    "\n",
    "            s_train = distance_accuracy(true_train, preds_train)\n",
    "            f1_train = f1_score(true_train, preds_train, average='weighted')\n",
    "\n",
    "            s_tr = distance_accuracy(true_tr, preds_tr)\n",
    "            f1_tronly = f1_test = f1_score(true_tr, preds_tr, average='weighted')        \n",
    "\n",
    "\n",
    "            lr = LogisticRegression(random_state=i)\n",
    "            mlp = MLPClassifier(random_state=i)\n",
    "            rf = RandomForestClassifier(random_state=i,n_jobs=-1)\n",
    "            train_mat = np.array(list(LSMR[\"rev_vec\"]))\n",
    "            test_mat = np.array(list(test_data[\"rev_vec\"]))\n",
    "            tronly_mat = np.array(list(tronly_test[\"rev_vec\"]))\n",
    "\n",
    "            evals = OrderedDict()\n",
    "            evals[\"Train\"] = s_train\n",
    "            evals[\"Test\"] = s\n",
    "            evals[\"Tr. Only\"] = s_tr\n",
    "            evals[\"Training Time\"] = trat\n",
    "            evals[\"Pred.Tra. Time\"] = predtra\n",
    "            evals[\"Testing Time\"] = tet\n",
    "            evals[\"Tr.Test Time\"] = trt\n",
    "            evals[\"F1 Test\"] = f1_test\n",
    "            evals[\"F1 Train\"] = f1_train\n",
    "            evals[\"F1 Tr. only\"] = f1_tronly\n",
    "            scores_tables[i][k][\"DeepSelect\"] = evals\n",
    "            scores_tables[i][k][\"MLP\"] = eval_models(\n",
    "                mlp, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "            scores_tables[i][k][\"Logistic Regression\"] = eval_models(\n",
    "                lr, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "            scores_tables[i][k][\"RandomForest\"] = eval_models(\n",
    "                rf, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "\n",
    "            print()\n",
    "            print(\"K:\\t{}\".format(k+1))\n",
    "            print(pd.DataFrame(scores_tables[i][k]))\n",
    "            print(\"\\nThis fold took:\", elapsed, \"seconds\\n\")\n",
    "            learning_curves[i][k] = training_curve\n",
    "            k += 1\n",
    "            print(\"*\"*10+\"\\n\")\n",
    "        print(\"Average scores for trial {}\".format(i))\n",
    "        print(get_trial_score(scores_tables[i]))\n",
    "        print(\"-\"*30)\n",
    "    print(\"%%\"*20)\n",
    "    print(\"Average of {} trials\".format(NUM_TRIALS))\n",
    "    print(get_total_average(scores_tables))\n",
    "    return scores_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial:\t1\n",
      "K:\t1\n",
      "epoch 0:\t24.76686600092429\n",
      "epoch 10:\t24.450570421325914\n",
      "epoch 20:\t24.044721181809056\n",
      "epoch 30:\t23.659809859445378\n",
      "epoch 40:\t23.372617877461806\n",
      "epoch 50:\t23.145493307660868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t1\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.202264  0.205265             0.196250      0.242046\n",
      "F1 Tr. only       0.202264  0.240859             0.303204      0.287112\n",
      "F1 Train          0.236986  0.331770             0.336056      0.995061\n",
      "Pred.Tra. Time    1.799902  0.455240             0.177022      0.108307\n",
      "Test              0.803704  0.811111             0.802469      0.798765\n",
      "Testing Time      0.009492  0.000347             0.000145      0.105107\n",
      "Tr. Only          0.804286  0.798571             0.781429      0.714286\n",
      "Tr.Test Time      0.013290  0.000324             0.000156      0.106326\n",
      "Train             0.812840  0.823333             0.823086      0.999259\n",
      "Training Time    15.069148  0.004432             0.000827      0.105972\n",
      "\n",
      "This fold took: 17.099502563476562 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t2\n",
      "epoch 0:\t24.92346767130208\n",
      "epoch 10:\t24.564709301632753\n",
      "epoch 20:\t24.2073859671301\n",
      "epoch 30:\t23.935115071168564\n",
      "epoch 40:\t23.6987205718208\n",
      "epoch 50:\t23.486057918315307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t2\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.181481  0.208627             0.217063      0.270889\n",
      "F1 Tr. only       0.181481  0.321167             0.297630      0.267191\n",
      "F1 Train          0.066203  0.334973             0.329319      0.992585\n",
      "Pred.Tra. Time    1.777080  0.431015             0.162320      0.108316\n",
      "Test              0.791111  0.772222             0.773333      0.793333\n",
      "Testing Time      0.009697  0.000659             0.000160      0.105429\n",
      "Tr. Only          0.801429  0.817143             0.782857      0.748571\n",
      "Tr.Test Time      0.013545  0.000781             0.000156      0.105695\n",
      "Train             0.825802  0.829877             0.829506      0.998889\n",
      "Training Time    14.483696  0.001688             0.000736      0.106070\n",
      "\n",
      "This fold took: 16.476651191711426 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t3\n",
      "epoch 0:\t24.38693266071134\n",
      "epoch 10:\t24.36671859100121\n",
      "epoch 20:\t24.141229575106586\n",
      "epoch 30:\t23.950204384628034\n",
      "epoch 40:\t23.76446889932159\n",
      "epoch 50:\t23.54198691144533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t3\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.180303  0.199350             0.178009      0.211884\n",
      "F1 Tr. only       0.180303  0.298937             0.302416      0.282611\n",
      "F1 Train          0.239626  0.318162             0.325155      0.993821\n",
      "Pred.Tra. Time    1.703255  0.476871             0.174251      0.108089\n",
      "Test              0.783951  0.771605             0.756790      0.770370\n",
      "Testing Time      0.008917  0.000309             0.000123      0.103327\n",
      "Tr. Only          0.798571  0.797143             0.780000      0.754286\n",
      "Tr.Test Time      0.014533  0.000587             0.000115      0.103675\n",
      "Train             0.816420  0.826420             0.827531      0.998395\n",
      "Training Time    15.074522  0.002025             0.000899      0.103266\n",
      "\n",
      "This fold took: 17.02352285385132 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t4\n",
      "epoch 0:\t22.97082298668301\n",
      "epoch 10:\t22.82736282802089\n",
      "epoch 20:\t22.696021554263883\n",
      "epoch 30:\t22.547027378871025\n",
      "epoch 40:\t22.4013970031759\n",
      "epoch 50:\t22.240539348597185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t4\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.171136  0.254857             0.255074      0.293663\n",
      "F1 Tr. only       0.171136  0.323662             0.341750      0.307138\n",
      "F1 Train          0.178423  0.299336             0.310901      0.996292\n",
      "Pred.Tra. Time    1.826833  0.604097             0.166308      0.109244\n",
      "Test              0.813333  0.807778             0.805556      0.785556\n",
      "Testing Time      0.008838  0.000611             0.000100      0.104795\n",
      "Tr. Only          0.730000  0.787143             0.801429      0.790000\n",
      "Tr.Test Time      0.014428  0.000319             0.000102      0.104845\n",
      "Train             0.792222  0.821111             0.823457      0.999259\n",
      "Training Time    13.542790  0.001891             0.000707      0.103283\n",
      "\n",
      "This fold took: 15.608597040176392 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t5\n",
      "epoch 0:\t21.27403529190793\n",
      "epoch 10:\t21.150054938585143\n",
      "epoch 20:\t20.966579648248388\n",
      "epoch 30:\t20.77070906470299\n",
      "epoch 40:\t20.615861525301906\n",
      "epoch 50:\t20.444709706088176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t5\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.202264  0.289502             0.241477      0.261729\n",
      "F1 Tr. only       0.202264  0.313378             0.287556      0.279572\n",
      "F1 Train          0.222821  0.288964             0.306291      0.996295\n",
      "Pred.Tra. Time    1.790706  0.687872             0.167190      0.108454\n",
      "Test              0.813580  0.809877             0.792593      0.746914\n",
      "Testing Time      0.008772  0.000309             0.000109      0.101528\n",
      "Tr. Only          0.804286  0.804286             0.775714      0.742857\n",
      "Tr.Test Time      0.014600  0.000322             0.000135      0.101608\n",
      "Train             0.812099  0.823827             0.820617      0.999259\n",
      "Training Time    15.534183  0.001626             0.000750      0.102017\n",
      "\n",
      "This fold took: 17.551403522491455 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t6\n",
      "epoch 0:\t23.328142026006237\n",
      "epoch 10:\t22.943384216296288\n",
      "epoch 20:\t22.669671286466247\n",
      "epoch 30:\t22.547168520151004\n",
      "epoch 40:\t22.340511062595017\n",
      "epoch 50:\t22.13583784828388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t6\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.202264  0.228530             0.243285      0.258241\n",
      "F1 Tr. only       0.202264  0.370055             0.292236      0.308313\n",
      "F1 Train          0.228288  0.321539             0.334170      0.991355\n",
      "Pred.Tra. Time    1.811466  0.558301             0.192604      0.108248\n",
      "Test              0.801111  0.790000             0.793333      0.805556\n",
      "Testing Time      0.010818  0.014003             0.000101      0.105598\n",
      "Tr. Only          0.804286  0.810000             0.767143      0.747143\n",
      "Tr.Test Time      0.013106  0.000635             0.000111      0.105049\n",
      "Train             0.814938  0.829630             0.827901      0.998025\n",
      "Training Time    16.667842  0.021832             0.000720      0.103447\n",
      "\n",
      "This fold took: 18.714858531951904 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t7\n",
      "epoch 0:\t22.822449440498122\n",
      "epoch 10:\t22.487452789556254\n",
      "epoch 20:\t22.203279160148504\n",
      "epoch 30:\t21.99624966967625\n",
      "epoch 40:\t21.829642595852597\n",
      "epoch 50:\t21.738356185460745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t7\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.197836  0.261481             0.224081      0.265556\n",
      "F1 Tr. only       0.197836  0.383894             0.332195      0.335966\n",
      "F1 Train          0.228624  0.350501             0.325914      0.991345\n",
      "Pred.Tra. Time    1.867791  1.079048             0.158678      0.107991\n",
      "Test              0.800000  0.787778             0.783333      0.777778\n",
      "Testing Time      0.009044  0.000311             0.000105      0.105295\n",
      "Tr. Only          0.801429  0.814286             0.788571      0.771429\n",
      "Tr.Test Time      0.013583  0.000318             0.000100      0.104778\n",
      "Train             0.815926  0.834198             0.827160      0.998148\n",
      "Training Time    14.991585  0.001625             0.000746      0.103639\n",
      "\n",
      "This fold took: 17.10541844367981 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t8\n",
      "epoch 0:\t23.57382025575771\n",
      "epoch 10:\t23.405012021192853\n",
      "epoch 20:\t23.026254836512017\n",
      "epoch 30:\t22.713405503505832\n",
      "epoch 40:\t22.441812420193592\n",
      "epoch 50:\t22.279979468534044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t8\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.281460  0.219282             0.240992      0.236479\n",
      "F1 Tr. only       0.281460  0.321095             0.348020      0.231954\n",
      "F1 Train          0.205937  0.282132             0.313870      0.993809\n",
      "Pred.Tra. Time    1.858663  0.651061             0.187132      0.107837\n",
      "Test              0.841667  0.816667             0.825000      0.775000\n",
      "Testing Time      0.009346  0.000345             0.000113      0.104412\n",
      "Tr. Only          0.750000  0.821429             0.800000      0.688571\n",
      "Tr.Test Time      0.010101  0.000335             0.000146      0.105883\n",
      "Train             0.792716  0.819383             0.821235      0.998025\n",
      "Training Time    17.200065  0.001734             0.000848      0.102837\n",
      "\n",
      "This fold took: 19.294219493865967 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t9\n",
      "epoch 0:\t19.9516426349678\n",
      "epoch 10:\t19.848213856978084\n",
      "epoch 20:\t19.74263647426656\n",
      "epoch 30:\t19.618040343969476\n",
      "epoch 40:\t19.512793585691988\n",
      "epoch 50:\t19.41919679289311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t9\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.206488  0.185791             0.133072      0.230364\n",
      "F1 Tr. only       0.206488  0.341620             0.308476      0.303576\n",
      "F1 Train          0.275839  0.438538             0.336940      0.995064\n",
      "Pred.Tra. Time    1.765091  1.229238             0.167646      0.108062\n",
      "Test              0.776667  0.768889             0.757778      0.754444\n",
      "Testing Time      0.009656  0.000679             0.000111      0.104964\n",
      "Tr. Only          0.797143  0.800000             0.781429      0.737143\n",
      "Tr.Test Time      0.014234  0.000328             0.000101      0.104991\n",
      "Train             0.819259  0.845679             0.828148      0.998642\n",
      "Training Time    14.691512  0.001661             0.000756      0.103207\n",
      "\n",
      "This fold took: 16.728501319885254 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t10\n",
      "epoch 0:\t24.667802115791478\n",
      "epoch 10:\t24.143970182603308\n",
      "epoch 20:\t23.83940182489085\n",
      "epoch 30:\t23.550858148647933\n",
      "epoch 40:\t23.32982883919447\n",
      "epoch 50:\t23.124156661682825\n",
      "\n",
      "K:\t10\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.202264  0.338667             0.306383      0.287274\n",
      "F1 Tr. only       0.202264  0.286406             0.266340      0.296579\n",
      "F1 Train          0.221775  0.438964             0.303478      0.995059\n",
      "Pred.Tra. Time    1.820277  1.275109             0.160689      0.108840\n",
      "Test              0.819444  0.793056             0.806944      0.773611\n",
      "Testing Time      0.009311  0.000600             0.000132      0.105698\n",
      "Tr. Only          0.804286  0.735714             0.771429      0.760000\n",
      "Tr.Test Time      0.014679  0.000322             0.000144      0.105209\n",
      "Train             0.810000  0.837284             0.816173      0.998889\n",
      "Training Time    14.899025  0.001693             0.000764      0.106309\n",
      "\n",
      "This fold took: 16.956726789474487 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "Average scores for trial 0\n",
      "                DeepSelect  Logistic Regression       MLP  RandomForest\n",
      "F1 Test           0.202776             0.223569  0.239135      0.255812\n",
      "F1 Tr. only       0.202776             0.307982  0.320107      0.290001\n",
      "F1 Train          0.210452             0.322209  0.340488      0.994069\n",
      "Pred.Tra. Time    1.802106             0.171384  0.744785      0.108339\n",
      "Test              0.804457             0.789713  0.792898      0.778133\n",
      "Testing Time      0.009389             0.000120  0.001817      0.104615\n",
      "Tr. Only          0.789571             0.783000  0.798571      0.745429\n",
      "Tr.Test Time      0.013610             0.000126  0.000427      0.104806\n",
      "Train             0.811222             0.824481  0.829074      0.998679\n",
      "Training Time    15.215437             0.000775  0.004021      0.104005\n",
      "------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Average of 1 trials\n",
      "                DeepSelect  Logistic Regression       MLP  RandomForest\n",
      "F1 Test           0.202776             0.223569  0.239135      0.255812\n",
      "F1 Tr. only       0.202776             0.307982  0.320107      0.290001\n",
      "F1 Train          0.210452             0.322209  0.340488      0.994069\n",
      "Pred.Tra. Time    1.802106             0.171384  0.744785      0.108339\n",
      "Test              0.804457             0.789713  0.792898      0.778133\n",
      "Testing Time      0.009389             0.000120  0.001817      0.104615\n",
      "Tr. Only          0.789571             0.783000  0.798571      0.745429\n",
      "Tr.Test Time      0.013610             0.000126  0.000427      0.104806\n",
      "Train             0.811222             0.824481  0.829074      0.998679\n",
      "Training Time    15.215437             0.000775  0.004021      0.104005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores_tables = eval_selectivewaves_regclass(df, tronly_test_raw)\n",
    "pickle.dump(scores_tables, open(\"batch_no_tf_tables.results\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the full network for prediction\n",
    "### P.S. this variation supports online (incremental) training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(LSMR):\n",
    "    X = dict()\n",
    "    y = dict()\n",
    "    for _, row in LSMR.iterrows():\n",
    "        score = row[\"Score\"]\n",
    "        y_ = np.zeros(10)\n",
    "        y_[score-1] = 1\n",
    "        y[len(y)] = y_\n",
    "        X[len(X)] = row[\"rev_vec\"]\n",
    "    return np.array(list(X.values())), np.array(list(y.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_selective(df_train,epochs=100, learning_rate = 0.1, random_state=42, p_every=10):\n",
    "    LSMR_train = preprocess_data(df_train)\n",
    "    np.random.seed(random_state)\n",
    "    data_dict, L1, L2, L3 = get_data_dict(LSMR_train, get_L2and3=True)\n",
    "    init_weights = lambda layer, i, o: {k:2*np.random.random((i, o))-1 for k in layer}\n",
    "    W1 = init_weights(L1, 300, 300)  # (languge, score, movie_id)\n",
    "    W2 = init_weights(L2, 300, 300)  # (languge, score):\n",
    "    W3 = init_weights(L3, 300, 10)  # score:\n",
    "    \n",
    "    \n",
    "    reset_graph()\n",
    "    x = tf.placeholder(tf.float32, [None, 300])\n",
    "    y = tf.placeholder(tf.float32, [None, 10]) # 1-10 => 10 classes\n",
    "\n",
    "    w1 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w2 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w3 = tf.placeholder(tf.float32, [300, 10])\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([300]))\n",
    "    b2 = tf.Variable(tf.zeros([300]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    l2 = tf.nn.sigmoid(tf.matmul(x, w1) + b1)\n",
    "    l3 = tf.nn.sigmoid(tf.matmul(l2, w2) + b2)\n",
    "    pred = tf.nn.softmax(tf.matmul(l3, w3) + b3)\n",
    "\n",
    "\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    training_curve = dict()\n",
    "    with tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):\n",
    "        with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for e in range(epochs+1):\n",
    "                avg_cost = 0.\n",
    "                for _, row in LSMR_train.iterrows():\n",
    "                    lang = row[\"Language\"]\n",
    "                    movie_id = row[\"Movie_ID\"]\n",
    "                    score = row[\"Score\"]\n",
    "                    y_ = np.zeros(10)\n",
    "                    y_[score-1] = 1\n",
    "                    y_ = np.atleast_2d(y_)\n",
    "                    x_ = np.atleast_2d(row[\"rev_vec\"])\n",
    "                    w1_,w2_,w3_,_, c = sess.run([w1, w2, w3, optimizer, cost],\n",
    "                                             feed_dict={x: x_,\n",
    "                                                        y: y_,\n",
    "                                                        w1:W1[(lang, score, movie_id)],\n",
    "                                                        w2:W2[(lang, score)],\n",
    "                                                        w3:W3[score]})\n",
    "                    W1[(lang, score, movie_id)] = w1_\n",
    "                    W2[(lang, score)] = w2_\n",
    "                    W3[score] = w3_\n",
    "\n",
    "                    avg_cost += c\n",
    "                training_curve[e] = avg_cost\n",
    "                if e%p_every==0:\n",
    "                    print(\"Epoch {}: {}\".format(e, avg_cost/len(LSMR_train)))\n",
    "\n",
    "            return W1, W2, W3, training_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_index(array):\n",
    "    indx = None\n",
    "    max_ = float(\"-inf\")\n",
    "    for i, e in enumerate(array):\n",
    "        if e > max_:\n",
    "            max_ = e\n",
    "            indx = i\n",
    "    return indx, max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_selective(df, W1, W2, W3):\n",
    "    LSMR = preprocess_data(df)\n",
    "    reset_graph()\n",
    "    x = tf.placeholder(tf.float32, [None, 300])\n",
    "\n",
    "    w1 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w2 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w3 = tf.placeholder(tf.float32, [300, 10])\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([300]))\n",
    "    b2 = tf.Variable(tf.zeros([300]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    l2 = tf.nn.sigmoid(tf.matmul(x, w1) + b1)\n",
    "    l3 = tf.nn.sigmoid(tf.matmul(l2, w2) + b2)\n",
    "    pred = tf.nn.softmax(tf.matmul(l3, w3) + b3)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    prediction = tf.argmax(pred, 1)\n",
    "    preds = np.zeros(len(LSMR))\n",
    "    with tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):\n",
    "        with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            j = 0\n",
    "            for _, row in LSMR.iterrows():\n",
    "                v = row[\"rev_vec\"]\n",
    "                predicted_scores = np.zeros(len(W1))\n",
    "                for i, info in enumerate(W1):\n",
    "                    language, score, movie_id = info\n",
    "                    w_1 = W1[(language, score, movie_id)]\n",
    "                    w_2 = W2[(language, score)]\n",
    "                    w_3 = W3[score]\n",
    "\n",
    "                    predicted_scores[i] = prediction.eval({x: np.atleast_2d(v),\n",
    "                                                           w1:w_1,w2:w_2,w3:w_3})\n",
    "\n",
    "                max_index, probability = get_max_index(softmax(predicted_scores))\n",
    "                predicted_score = predicted_scores[max_index]\n",
    "\n",
    "                preds[j] = predicted_score\n",
    "                j+=1\n",
    "\n",
    "\n",
    "    return preds, np.array(list(LSMR.Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_selectivewaves_nn(df, tronly_test_raw, NUM_TRIALS=1, splits=10):  \n",
    "    learning_curves = OrderedDict()\n",
    "    scores_tables_nn = OrderedDict()\n",
    "    for i in range(NUM_TRIALS):\n",
    "        print(\"Trial:\\t{}\".format(i+1))\n",
    "        learning_curves[i] = OrderedDict()\n",
    "        k = 0\n",
    "        skf = StratifiedKFold(n_splits=splits, random_state=i)\n",
    "        scores_tables_nn[i] = dict()\n",
    "        for train_index, test_index in skf.split(df[\"Review\"], df[\"Language\"]):\n",
    "            print(\"K: \\t{}\".format(k+1))\n",
    "            scores_tables_nn[i][k] = OrderedDict()\n",
    "            start = time.time()\n",
    "            # approx 3 epochs per second\n",
    "            LSMR = preprocess_data(df.loc[train_index])\n",
    "            W1, W2, W3, training_curve = train_selective(df.loc[train_index], epochs=150, p_every=25)\n",
    "            _ = time.time()\n",
    "            trat = _-start\n",
    "            print(\"Took: {} for training\".format(trat))\n",
    "\n",
    "            _ = time.time()\n",
    "            preds_train, true_train = predict_selective(df.loc[train_index], W1, W2, W3)\n",
    "            predtra = time.time()-_\n",
    "            print(\"Took: {} for predicting {} training instances\".format(predtra, len(train_index)))\n",
    "\n",
    "            test_data = preprocess_data(df.loc[test_index])\n",
    "            _ = time.time()\n",
    "            preds, true = predict_selective(df.loc[test_index], W1, W2, W3)\n",
    "            tet = time.time()-_\n",
    "            print(\"Took: {} for predicting {} test instances\".format(tet, len(test_index)))\n",
    "\n",
    "            _ = time.time()\n",
    "            preds_tr, true_tr = predict_selective(tronly_test_raw, W1, W2, W3)\n",
    "            trt = time.time()-_\n",
    "            print(\"Took: {} for predicting {} Turkish test instances\".format(trt, len(tronly_test)))\n",
    "\n",
    "            elapsed = time.time()-start\n",
    "\n",
    "            s = distance_accuracy(true, preds)\n",
    "            s_train = distance_accuracy(true_train, preds_train)\n",
    "            s_tr = distance_accuracy(true_tr, preds_tr)\n",
    "\n",
    "            f1_test = f1_score(true, preds, average='weighted')\n",
    "            f1_train = f1_score(true_train, preds_train, average='weighted')\n",
    "            f1_tronly = f1_score(true_tr, preds_tr, average='weighted')\n",
    "\n",
    "            mlp = MLPClassifier(random_state=i)\n",
    "            lr = LogisticRegression(random_state=i)\n",
    "            rf = RandomForestClassifier(random_state=i,n_jobs=-1)\n",
    "            train_mat = np.array(list(LSMR[\"rev_vec\"]))\n",
    "            test_mat = np.array(list(test_data[\"rev_vec\"]))\n",
    "            tronly_mat = np.array(list(tronly_test[\"rev_vec\"]))\n",
    "\n",
    "            evals = OrderedDict()\n",
    "            evals[\"Train\"] = s_train\n",
    "            evals[\"Test\"] = s\n",
    "            evals[\"Tr. Only\"] = s_tr\n",
    "            evals[\"Training Time\"] = trat\n",
    "            evals[\"Pred.Tra. Time\"] = predtra\n",
    "            evals[\"Testing Time\"] = tet\n",
    "            evals[\"Tr.Test Time\"] = trt\n",
    "            evals[\"F1 Test\"] = f1_test\n",
    "            evals[\"F1 Train\"] = f1_train\n",
    "            evals[\"F1 Tr. only\"] = f1_tronly\n",
    "            scores_tables_nn[i][k][\"DeepSelect\"] = evals\n",
    "\n",
    "            scores_tables_nn[i][k][\"LogisticRegression\"] = eval_models(lr, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "            scores_tables_nn[i][k][\"MLP\"] = eval_models(mlp, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "            scores_tables_nn[i][k][\"RandomForest\"] = eval_models(rf, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "\n",
    "            print()\n",
    "            print(pd.DataFrame(scores_tables_nn[i][k]))\n",
    "            print(\"took:\", elapsed, \"seconds\\n\")\n",
    "            learning_curves[i][k] = training_curve\n",
    "            k += 1\n",
    "            print(\"*\"*10+\"\\n\")\n",
    "        print(\"Average scores for trial {}\".format(i))\n",
    "        print(get_trial_score(scores_tables_nn[i]))\n",
    "        print(\"-\"*30)\n",
    "    print(\"%%\"*20)\n",
    "    print(\"Average of {} trials\".format(NUM_TRIALS))\n",
    "    print(get_total_average(scores_tables_nn))\n",
    "    return scores_tables_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial:\t1\n",
      "K: \t1\n",
      "Epoch 0: 1.9773333567116693\n",
      "Epoch 25: 0.003818575064216644\n",
      "Epoch 50: 0.0019198051157985323\n",
      "Epoch 75: 0.0012996401052061156\n",
      "Epoch 100: 0.000988080382333894\n",
      "Epoch 125: 0.0007996864090740125\n",
      "Epoch 150: 0.0006731128424478581\n",
      "Took: 183.70366883277893 for training\n",
      "Took: 615.1565337181091 for predicting 810 training instances\n",
      "Took: 65.2965362071991 for predicting 90 test instances\n",
      "Took: 73.59039640426636 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.120773            0.196250  0.205265      0.242046\n",
      "F1 Tr. only       0.021802            0.303204  0.240859      0.287112\n",
      "F1 Train          0.050270            0.336056  0.331770      0.995061\n",
      "Pred.Tra. Time  615.156534            0.175007  0.563957      0.111384\n",
      "Test              0.833333            0.802469  0.811111      0.798765\n",
      "Testing Time     65.296536            0.000103  0.000311      0.105492\n",
      "Tr. Only          0.787143            0.781429  0.798571      0.714286\n",
      "Tr.Test Time     73.590396            0.000098  0.000322      0.105752\n",
      "Train             0.822469            0.823086  0.823333      0.999259\n",
      "Training Time   183.703669            0.000723  0.001884      0.102581\n",
      "took: 937.9249000549316 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t2\n",
      "Epoch 0: 2.3775782500775855\n",
      "Epoch 25: 0.004348101737080323\n",
      "Epoch 50: 0.0020806660097174457\n",
      "Epoch 75: 0.0013976375215784987\n",
      "Epoch 100: 0.0010624149531730678\n",
      "Epoch 125: 0.0008616164289622017\n",
      "Epoch 150: 0.0007272326177424357\n",
      "Took: 180.36139559745789 for training\n",
      "Took: 513.9241342544556 for predicting 810 training instances\n",
      "Took: 59.309340715408325 for predicting 90 test instances\n",
      "Took: 63.074501514434814 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.050294            0.217063  0.208627      0.270889\n",
      "F1 Tr. only       0.150864            0.297630  0.321167      0.267191\n",
      "F1 Train          0.087336            0.329319  0.334973      0.992585\n",
      "Pred.Tra. Time  513.924134            0.169826  0.434763      0.127065\n",
      "Test              0.783333            0.773333  0.772222      0.793333\n",
      "Testing Time     59.309341            0.000108  0.000311      0.104064\n",
      "Tr. Only          0.795714            0.782857  0.817143      0.748571\n",
      "Tr.Test Time     63.074502            0.000108  0.000331      0.105528\n",
      "Train             0.823457            0.829506  0.829877      0.998889\n",
      "Training Time   180.361396            0.000723  0.001676      0.102903\n",
      "took: 816.843035697937 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t3\n",
      "Epoch 0: 2.1105157300578643\n",
      "Epoch 25: 0.004087267299817969\n",
      "Epoch 50: 0.0019113149940726908\n",
      "Epoch 75: 0.0012732374629505147\n",
      "Epoch 100: 0.0009633172474697583\n",
      "Epoch 125: 0.000778884561837312\n",
      "Epoch 150: 0.0006560410923149108\n",
      "Took: 192.57593369483948 for training\n",
      "Took: 520.1284375190735 for predicting 810 training instances\n",
      "Took: 55.579052448272705 for predicting 90 test instances\n",
      "Took: 62.73327016830444 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.066667            0.178009  0.199350      0.211884\n",
      "F1 Tr. only       0.021802            0.302416  0.298937      0.282611\n",
      "F1 Train          0.055054            0.325155  0.318162      0.993821\n",
      "Pred.Tra. Time  520.128438            0.176462  0.427962      0.129727\n",
      "Test              0.796296            0.756790  0.771605      0.770370\n",
      "Testing Time     55.579052            0.000159  0.000334      0.105165\n",
      "Tr. Only          0.787143            0.780000  0.797143      0.754286\n",
      "Tr.Test Time     62.733270            0.000147  0.000330      0.104523\n",
      "Train             0.826173            0.827531  0.826420      0.998395\n",
      "Training Time   192.575934            0.000753  0.001710      0.106050\n",
      "took: 831.2531008720398 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t4\n",
      "Epoch 0: 2.47723830999529\n",
      "Epoch 25: 0.006543009063156722\n",
      "Epoch 50: 0.002836956465667322\n",
      "Epoch 75: 0.001875388481338503\n",
      "Epoch 100: 0.0014193576503870459\n",
      "Epoch 125: 0.0011497064898872587\n",
      "Epoch 150: 0.0009702312833957124\n",
      "Took: 214.42865920066833 for training\n",
      "Took: 533.9337005615234 for predicting 810 training instances\n",
      "Took: 56.72276759147644 for predicting 90 test instances\n",
      "Took: 62.730045318603516 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.041880            0.255074  0.254857      0.293663\n",
      "F1 Tr. only       0.021802            0.341750  0.323662      0.307138\n",
      "F1 Train          0.057870            0.310901  0.299336      0.996292\n",
      "Pred.Tra. Time  533.933701            0.148086  0.375179      0.110834\n",
      "Test              0.824444            0.805556  0.807778      0.785556\n",
      "Testing Time     56.722768            0.000132  0.000314      0.104963\n",
      "Tr. Only          0.787143            0.801429  0.787143      0.790000\n",
      "Tr.Test Time     62.730045            0.000101  0.000318      0.104890\n",
      "Train             0.825309            0.823457  0.821111      0.999259\n",
      "Training Time   214.428659            0.000704  0.001636      0.102548\n",
      "took: 868.0068027973175 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t5\n",
      "Epoch 0: 2.4254132675827416\n",
      "Epoch 25: 0.007124853473765367\n",
      "Epoch 50: 0.0029632288716947815\n",
      "Epoch 75: 0.001946002681710592\n",
      "Epoch 100: 0.0014707003281763337\n",
      "Epoch 125: 0.001191508610895653\n",
      "Epoch 150: 0.0010063985808415055\n",
      "Took: 193.84930992126465 for training\n",
      "Took: 523.990800857544 for predicting 810 training instances\n",
      "Took: 58.46610379219055 for predicting 90 test instances\n",
      "Took: 65.26005339622498 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.031373            0.241477  0.289502      0.261729\n",
      "F1 Tr. only       0.021802            0.287556  0.313378      0.279572\n",
      "F1 Train          0.059300            0.306291  0.288964      0.996295\n",
      "Pred.Tra. Time  523.990801            0.144853  0.490867      0.110879\n",
      "Test              0.806173            0.792593  0.809877      0.746914\n",
      "Testing Time     58.466104            0.000131  0.000310      0.104856\n",
      "Tr. Only          0.787143            0.775714  0.804286      0.742857\n",
      "Tr.Test Time     65.260053            0.000136  0.000318      0.104731\n",
      "Train             0.825185            0.820617  0.823827      0.999259\n",
      "Training Time   193.849310            0.000654  0.001686      0.102402\n",
      "took: 841.7475633621216 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t6\n",
      "Epoch 0: 2.5140747782521813\n",
      "Epoch 25: 0.004502532258827418\n",
      "Epoch 50: 0.002211785128756912\n",
      "Epoch 75: 0.0014994027829871998\n",
      "Epoch 100: 0.001145901822772649\n",
      "Epoch 125: 0.0009330131943834358\n",
      "Epoch 150: 0.0007901334228653956\n",
      "Took: 193.82340168952942 for training\n",
      "Took: 521.019739151001 for predicting 810 training instances\n",
      "Took: 57.46411204338074 for predicting 90 test instances\n",
      "Took: 64.15533757209778 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.026623            0.243285  0.228530      0.258241\n",
      "F1 Tr. only       0.021802            0.292236  0.370055      0.308313\n",
      "F1 Train          0.060083            0.334170  0.321539      0.991355\n",
      "Pred.Tra. Time  521.019739            0.149468  0.518251      0.135072\n",
      "Test              0.803333            0.793333  0.790000      0.805556\n",
      "Testing Time     57.464112            0.000103  0.000301      0.104838\n",
      "Tr. Only          0.787143            0.767143  0.810000      0.747143\n",
      "Tr.Test Time     64.155338            0.000103  0.000323      0.104754\n",
      "Train             0.827778            0.827901  0.829630      0.998025\n",
      "Training Time   193.823402            0.000649  0.001684      0.103200\n",
      "took: 836.6289052963257 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t7\n",
      "Epoch 0: 2.0252993080216304\n",
      "Epoch 25: 0.004158288826428316\n",
      "Epoch 50: 0.0019495924537374248\n",
      "Epoch 75: 0.0013167823257401639\n",
      "Epoch 100: 0.001006455283062156\n",
      "Epoch 125: 0.000819903696613179\n",
      "Epoch 150: 0.0006945743623698125\n",
      "Took: 194.56617617607117 for training\n",
      "Took: 536.1434712409973 for predicting 810 training instances\n",
      "Took: 58.2746045589447 for predicting 90 test instances\n",
      "Took: 64.16651034355164 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.026623            0.224081  0.261481      0.265556\n",
      "F1 Tr. only       0.021802            0.332195  0.383894      0.335966\n",
      "F1 Train          0.060021            0.325914  0.350501      0.991345\n",
      "Pred.Tra. Time  536.143471            0.154256  0.783379      0.111752\n",
      "Test              0.795556            0.783333  0.787778      0.777778\n",
      "Testing Time     58.274605            0.000102  0.000305      0.104939\n",
      "Tr. Only          0.787143            0.788571  0.814286      0.771429\n",
      "Tr.Test Time     64.166510            0.000101  0.000321      0.105597\n",
      "Train             0.828519            0.827160  0.834198      0.998148\n",
      "Training Time   194.566176            0.000626  0.001614      0.102175\n",
      "took: 853.3530278205872 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t8\n",
      "Epoch 0: 2.386953772464716\n",
      "Epoch 25: 0.005820904014874234\n",
      "Epoch 50: 0.0026788789231635534\n",
      "Epoch 75: 0.0017896633637661456\n",
      "Epoch 100: 0.001360831037431109\n",
      "Epoch 125: 0.0011058854826850155\n",
      "Epoch 150: 0.0009358523425970097\n",
      "Took: 197.08762121200562 for training\n",
      "Took: 519.3965420722961 for predicting 810 training instances\n",
      "Took: 57.6979603767395 for predicting 90 test instances\n",
      "Took: 61.745113134384155 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.112281            0.240992  0.219282      0.236479\n",
      "F1 Tr. only       0.021802            0.348020  0.321095      0.231954\n",
      "F1 Train          0.050942            0.313870  0.282132      0.993809\n",
      "Pred.Tra. Time  519.396542            0.150652  0.478358      0.110773\n",
      "Test              0.863889            0.825000  0.816667      0.775000\n",
      "Testing Time     57.697960            0.000103  0.000320      0.104861\n",
      "Tr. Only          0.787143            0.800000  0.821429      0.688571\n",
      "Tr.Test Time     61.745113            0.000103  0.000319      0.105430\n",
      "Train             0.817901            0.821235  0.819383      0.998025\n",
      "Training Time   197.087621            0.000610  0.001600      0.103175\n",
      "took: 836.1293518543243 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t9\n",
      "Epoch 0: 2.9021928498045635\n",
      "Epoch 25: 0.005129504039105984\n",
      "Epoch 50: 0.002507706557218379\n",
      "Epoch 75: 0.0016960249718019924\n",
      "Epoch 100: 0.0012941287556573733\n",
      "Epoch 125: 0.001052249841851801\n",
      "Epoch 150: 0.0008898748942328894\n",
      "Took: 191.99448561668396 for training\n",
      "Took: 528.0968854427338 for predicting 810 training instances\n",
      "Took: 55.99299335479736 for predicting 90 test instances\n",
      "Took: 61.0268759727478 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.060021            0.133072  0.185791      0.230364\n",
      "F1 Tr. only       0.021802            0.308476  0.341620      0.303576\n",
      "F1 Train          0.055753            0.336940  0.438538      0.995064\n",
      "Pred.Tra. Time  528.096885            0.151687  1.024017      0.110780\n",
      "Test              0.798889            0.757778  0.768889      0.754444\n",
      "Testing Time     55.992993            0.000116  0.000320      0.104057\n",
      "Tr. Only          0.787143            0.781429  0.800000      0.737143\n",
      "Tr.Test Time     61.026876            0.000130  0.000322      0.105283\n",
      "Train             0.828148            0.828148  0.845679      0.998642\n",
      "Training Time   191.994486            0.000657  0.001659      0.102299\n",
      "took: 837.3354005813599 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t10\n",
      "Epoch 0: 2.313656463823308\n",
      "Epoch 25: 0.004104317455820494\n",
      "Epoch 50: 0.002030699017542741\n",
      "Epoch 75: 0.0013742376939195242\n",
      "Epoch 100: 0.0010469946722385733\n",
      "Epoch 125: 0.0008495575762263618\n",
      "Epoch 150: 0.000716896278712469\n",
      "Took: 191.57597875595093 for training\n",
      "Took: 533.8623700141907 for predicting 810 training instances\n",
      "Took: 63.952608823776245 for predicting 90 test instances\n",
      "Took: 59.9774386882782 for predicting 100 Turkish test instances\n",
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.082961            0.306383  0.338667      0.287274\n",
      "F1 Tr. only       0.020183            0.266340  0.286406      0.296579\n",
      "F1 Train          0.072491            0.303478  0.438964      0.995059\n",
      "Pred.Tra. Time  533.862370            0.147035  1.028941      0.111132\n",
      "Test              0.783333            0.806944  0.793056      0.773611\n",
      "Testing Time     63.952609            0.000118  0.000307      0.104713\n",
      "Tr. Only          0.787143            0.771429  0.735714      0.760000\n",
      "Tr.Test Time     59.977439            0.000104  0.000317      0.104804\n",
      "Train             0.800247            0.816173  0.837284      0.998889\n",
      "Training Time   191.575979            0.000640  0.001690      0.106039\n",
      "took: 849.5751967430115 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "Average scores for trial 0\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.061949            0.223569  0.239135      0.255812\n",
      "F1 Tr. only       0.034546            0.307982  0.320107      0.290001\n",
      "F1 Train          0.060912            0.322209  0.340488      0.994069\n",
      "Pred.Tra. Time  534.565261            0.156733  0.612567      0.116940\n",
      "Test              0.808858            0.789713  0.792898      0.778133\n",
      "Testing Time     58.875608            0.000117  0.000313      0.104795\n",
      "Tr. Only          0.788000            0.783000  0.798571      0.745429\n",
      "Tr.Test Time     63.845954            0.000113  0.000322      0.105129\n",
      "Train             0.822519            0.824481  0.829074      0.998679\n",
      "Training Time   193.396663            0.000674  0.001684      0.103337\n",
      "------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Average of 1 trials\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.061949            0.223569  0.239135      0.255812\n",
      "F1 Tr. only       0.034546            0.307982  0.320107      0.290001\n",
      "F1 Train          0.060912            0.322209  0.340488      0.994069\n",
      "Pred.Tra. Time  534.565261            0.156733  0.612567      0.116940\n",
      "Test              0.808858            0.789713  0.792898      0.778133\n",
      "Testing Time     58.875608            0.000117  0.000313      0.104795\n",
      "Tr. Only          0.788000            0.783000  0.798571      0.745429\n",
      "Tr.Test Time     63.845954            0.000113  0.000322      0.105129\n",
      "Train             0.822519            0.824481  0.829074      0.998679\n",
      "Training Time   193.396663            0.000674  0.001684      0.103337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores_tables_nn = eval_selectivewaves_nn(df, tronly_test_raw)\n",
    "pickle.dump(scores_tables_nn, open(\"incremental_tf_tables.results\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En: 50\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t16.52820921224812\n",
      "epoch 10:\t16.39311794442145\n",
      "epoch 20:\t16.28053593823387\n",
      "epoch 30:\t16.17463017163827\n",
      "epoch 40:\t16.067564309247263\n",
      "epoch 50:\t15.964494623225281\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 7.339794548606778\n",
      "Epoch 25: 0.08729174313691143\n",
      "Epoch 50: 0.015980279772296057\n",
      "Epoch 75: 0.008813390556133843\n",
      "Epoch 100: 0.006229110769650169\n",
      "Epoch 125: 0.004865745641478409\n",
      "Epoch 150: 0.00401580884632106\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 67.90573191642761\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.17242087221081\n",
      "epoch 10:\t19.943121625922586\n",
      "epoch 20:\t19.747438776393345\n",
      "epoch 30:\t19.562883062061417\n",
      "epoch 40:\t19.343043317450203\n",
      "epoch 50:\t19.134988594722827\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.537748518779587\n",
      "Epoch 25: 0.02896918413554466\n",
      "Epoch 50: 0.011732149529388362\n",
      "Epoch 75: 0.00750067419797303\n",
      "Epoch 100: 0.00556290933663359\n",
      "Epoch 125: 0.0044437062310127935\n",
      "Epoch 150: 0.0037117885535350907\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 97.6483633518219\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.558661043428863\n",
      "epoch 10:\t18.275162920900748\n",
      "epoch 20:\t18.0690512800357\n",
      "epoch 30:\t18.011163026017886\n",
      "epoch 40:\t17.979688741120565\n",
      "epoch 50:\t17.893496160064807\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 5.529079747339197\n",
      "Epoch 25: 0.020512997728527646\n",
      "Epoch 50: 0.009145965525856488\n",
      "Epoch 75: 0.006014972501543525\n",
      "Epoch 100: 0.004513847238152213\n",
      "Epoch 125: 0.003624595370665167\n",
      "Epoch 150: 0.003033832769629311\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 115.3185076713562\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.650004065424067\n",
      "epoch 10:\t20.501010042838722\n",
      "epoch 20:\t20.39800701220522\n",
      "epoch 30:\t20.278491025736592\n",
      "epoch 40:\t20.11572724965626\n",
      "epoch 50:\t19.923114970322096\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 5.586502467327262\n",
      "Epoch 25: 0.012770103482683311\n",
      "Epoch 50: 0.00597685394368238\n",
      "Epoch 75: 0.00401376832193299\n",
      "Epoch 100: 0.0030581356741225005\n",
      "Epoch 125: 0.0024870354660931427\n",
      "Epoch 150: 0.0021050228487172803\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 147.89269638061523\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.207572227998376\n",
      "epoch 10:\t19.083247898189956\n",
      "epoch 20:\t19.03569606932404\n",
      "epoch 30:\t18.94439668950445\n",
      "epoch 40:\t18.87147352515329\n",
      "epoch 50:\t18.787741274334515\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.921140831965866\n",
      "Epoch 25: 0.008907715815676056\n",
      "Epoch 50: 0.004296590380481575\n",
      "Epoch 75: 0.002905163657736011\n",
      "Epoch 100: 0.00222057767339993\n",
      "Epoch 125: 0.0018094544650148236\n",
      "Epoch 150: 0.0015336333086393096\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 165.94341206550598\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.207796265508662\n",
      "epoch 10:\t21.99923903785189\n",
      "epoch 20:\t21.8343851582949\n",
      "epoch 30:\t21.63882946082881\n",
      "epoch 40:\t21.4389646683601\n",
      "epoch 50:\t21.222813907040518\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.8077726276764787\n",
      "Epoch 25: 0.008134934987037924\n",
      "Epoch 50: 0.003975011260735661\n",
      "Epoch 75: 0.0026854954341419654\n",
      "Epoch 100: 0.002047992654231699\n",
      "Epoch 125: 0.0016648195952402131\n",
      "Epoch 150: 0.0014078559791512596\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 194.4621250629425\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.233458047309444\n",
      "epoch 10:\t20.041739636448913\n",
      "epoch 20:\t19.891385162254203\n",
      "epoch 30:\t19.71715369944107\n",
      "epoch 40:\t19.561088087049676\n",
      "epoch 50:\t19.43148609784066\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.821938721553482\n",
      "Epoch 25: 0.01253030508266668\n",
      "Epoch 50: 0.005854549981108214\n",
      "Epoch 75: 0.0039043113349882994\n",
      "Epoch 100: 0.002959969207274822\n",
      "Epoch 125: 0.0023984562801987607\n",
      "Epoch 150: 0.0020243045445926273\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 215.1549551486969\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.430905383380168\n",
      "epoch 10:\t23.18144371995767\n",
      "epoch 20:\t22.94502573587449\n",
      "epoch 30:\t22.70553442408163\n",
      "epoch 40:\t22.466395823016427\n",
      "epoch 50:\t22.25169961727304\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.5469703360552067\n",
      "Epoch 25: 0.008192623501099353\n",
      "Epoch 50: 0.003823824644709131\n",
      "Epoch 75: 0.002550301385817598\n",
      "Epoch 100: 0.001932100512973451\n",
      "Epoch 125: 0.0015639287674667451\n",
      "Epoch 150: 0.0013184374155939223\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 228.99712491035461\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.13661317279356\n",
      "epoch 10:\t21.035086856216374\n",
      "epoch 20:\t20.90981561251643\n",
      "epoch 30:\t20.738727637396543\n",
      "epoch 40:\t20.59078150136115\n",
      "epoch 50:\t20.456599832109802\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.27495084668355\n",
      "Epoch 25: 0.008682058947574772\n",
      "Epoch 50: 0.003922100654622726\n",
      "Epoch 75: 0.002587961226206156\n",
      "Epoch 100: 0.0019491792230337246\n",
      "Epoch 125: 0.001571730005687824\n",
      "Epoch 150: 0.0013214073862277556\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 257.6350030899048\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.7418612024327\n",
      "epoch 10:\t20.61126471828218\n",
      "epoch 20:\t20.427651514925522\n",
      "epoch 30:\t20.224610123807626\n",
      "epoch 40:\t20.038430630643447\n",
      "epoch 50:\t19.87129637088691\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.0611462647272694\n",
      "Epoch 25: 0.013180303992127544\n",
      "Epoch 50: 0.004980258201166584\n",
      "Epoch 75: 0.0031414944836789496\n",
      "Epoch 100: 0.0023115928415877026\n",
      "Epoch 125: 0.001836346504895927\n",
      "Epoch 150: 0.0015275294163778754\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 271.9390392303467\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.86882168245634\n",
      "epoch 10:\t19.9092612408944\n",
      "epoch 20:\t19.805491090237812\n",
      "epoch 30:\t19.614890601752453\n",
      "epoch 40:\t19.394302070273426\n",
      "epoch 50:\t19.202363324633318\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 5.129584824559944\n",
      "Epoch 25: 0.07302809065203064\n",
      "Epoch 50: 0.018936178862778822\n",
      "Epoch 75: 0.008098027134043865\n",
      "Epoch 100: 0.005344458754093954\n",
      "Epoch 125: 0.004043634303583791\n",
      "Epoch 150: 0.003275666567844837\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 106.9969220161438\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.8334635842836\n",
      "epoch 10:\t19.596365687491907\n",
      "epoch 20:\t19.42477436447093\n",
      "epoch 30:\t19.18635338742181\n",
      "epoch 40:\t18.98612432579517\n",
      "epoch 50:\t18.824622419099178\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.073025793182993\n",
      "Epoch 25: 0.024851973619600662\n",
      "Epoch 50: 0.009547373446093844\n",
      "Epoch 75: 0.006075273871617052\n",
      "Epoch 100: 0.004498353506844271\n",
      "Epoch 125: 0.0035907408257824297\n",
      "Epoch 150: 0.00299853506651036\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 131.9662082195282\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.16143237968937\n",
      "epoch 10:\t22.895519960223215\n",
      "epoch 20:\t22.630408198515518\n",
      "epoch 30:\t22.393349482121188\n",
      "epoch 40:\t22.15018465776216\n",
      "epoch 50:\t21.9228406337818\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.097704803931992\n",
      "Epoch 25: 0.01171999797953421\n",
      "Epoch 50: 0.005583083305720555\n",
      "Epoch 75: 0.0037276106836987887\n",
      "Epoch 100: 0.002820443417107816\n",
      "Epoch 125: 0.0022790729098708406\n",
      "Epoch 150: 0.0019179223946500976\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 157.23956084251404\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.030692492409532\n",
      "epoch 10:\t17.966970356394008\n",
      "epoch 20:\t17.902395139477072\n",
      "epoch 30:\t17.842417408589657\n",
      "epoch 40:\t17.792289593120998\n",
      "epoch 50:\t17.742208190843115\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.6150671737271365\n",
      "Epoch 25: 0.02688962801029832\n",
      "Epoch 50: 0.008102054117510376\n",
      "Epoch 75: 0.004946322766180454\n",
      "Epoch 100: 0.0035976783454416887\n",
      "Epoch 125: 0.0028439896536409694\n",
      "Epoch 150: 0.0023607819092273546\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 177.96316170692444\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.79707911365647\n",
      "epoch 10:\t21.579340775055037\n",
      "epoch 20:\t21.319263888025546\n",
      "epoch 30:\t21.083574187988813\n",
      "epoch 40:\t20.877853598556165\n",
      "epoch 50:\t20.678224027628165\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.022157329743908\n",
      "Epoch 25: 0.013149791939492653\n",
      "Epoch 50: 0.005074322252737223\n",
      "Epoch 75: 0.003283855563414401\n",
      "Epoch 100: 0.0024660120824588224\n",
      "Epoch 125: 0.0019900957459336155\n",
      "Epoch 150: 0.0016760999038595513\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 200.16781044006348\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.48452854974004\n",
      "epoch 10:\t20.36027199581928\n",
      "epoch 20:\t20.1939450112428\n",
      "epoch 30:\t20.05790142204325\n",
      "epoch 40:\t19.93724989704214\n",
      "epoch 50:\t19.82781621670487\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.5623621198098268\n",
      "Epoch 25: 0.008550410627038475\n",
      "Epoch 50: 0.003926103010309678\n",
      "Epoch 75: 0.002606454517836872\n",
      "Epoch 100: 0.001970258335651293\n",
      "Epoch 125: 0.0015927595037199434\n",
      "Epoch 150: 0.0013416406704134895\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 229.26985144615173\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.10494286979153\n",
      "epoch 10:\t20.89894679956469\n",
      "epoch 20:\t20.685748409781187\n",
      "epoch 30:\t20.5010005360481\n",
      "epoch 40:\t20.354514089265002\n",
      "epoch 50:\t20.182619935342764\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.8759061492468296\n",
      "Epoch 25: 0.011034273873407361\n",
      "Epoch 50: 0.004876591607318771\n",
      "Epoch 75: 0.003214784715911073\n",
      "Epoch 100: 0.0024239204727803695\n",
      "Epoch 125: 0.0019574643842038076\n",
      "Epoch 150: 0.0016482350777347451\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 249.13368248939514\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.020764458651293\n",
      "epoch 10:\t20.891886241392378\n",
      "epoch 20:\t20.68192359233935\n",
      "epoch 30:\t20.49713849051033\n",
      "epoch 40:\t20.373689276336414\n",
      "epoch 50:\t20.265332904851938\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.676640738699782\n",
      "Epoch 25: 0.029177015036527466\n",
      "Epoch 50: 0.006549534974939369\n",
      "Epoch 75: 0.0038066155166732295\n",
      "Epoch 100: 0.0027189252839662005\n",
      "Epoch 125: 0.0021315732859940387\n",
      "Epoch 150: 0.0017631736603724287\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 271.3981873989105\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.611996609227326\n",
      "epoch 10:\t19.550913302986253\n",
      "epoch 20:\t19.484419036839885\n",
      "epoch 30:\t19.43057801214237\n",
      "epoch 40:\t19.370563558298308\n",
      "epoch 50:\t19.308662664746727\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.5847677716950102\n",
      "Epoch 25: 0.004585617790633147\n",
      "Epoch 50: 0.0023508130706804556\n",
      "Epoch 75: 0.0016081602297063568\n",
      "Epoch 100: 0.0012323498404728885\n",
      "Epoch 125: 0.0010039285088413964\n",
      "Epoch 150: 0.0008497835313989153\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 289.33306646347046\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.4479804995722\n",
      "epoch 10:\t22.235946698893777\n",
      "epoch 20:\t22.00800224306249\n",
      "epoch 30:\t21.790577228389363\n",
      "epoch 40:\t21.61653206921743\n",
      "epoch 50:\t21.48750014526655\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.1582032730954523\n",
      "Epoch 25: 0.004965149507272372\n",
      "Epoch 50: 0.002417920444570882\n",
      "Epoch 75: 0.0016318884558484115\n",
      "Epoch 100: 0.0012430625843048802\n",
      "Epoch 125: 0.0010091691360825052\n",
      "Epoch 150: 0.0008522512376118243\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 316.6615414619446\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.15616335692374\n",
      "epoch 10:\t21.857546057276803\n",
      "epoch 20:\t21.3647330114568\n",
      "epoch 30:\t20.99977583926535\n",
      "epoch 40:\t20.714517377219174\n",
      "epoch 50:\t20.453905815546484\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.791492950846441\n",
      "Epoch 25: 0.022575320332503236\n",
      "Epoch 50: 0.0074050309615406726\n",
      "Epoch 75: 0.004584078676560622\n",
      "Epoch 100: 0.0033654293342543066\n",
      "Epoch 125: 0.0026786330240826683\n",
      "Epoch 150: 0.00223509240462303\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 142.16614723205566\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.8172021139943\n",
      "epoch 10:\t21.598703792211186\n",
      "epoch 20:\t21.425414424510098\n",
      "epoch 30:\t21.246898187583902\n",
      "epoch 40:\t21.076554412868582\n",
      "epoch 50:\t20.922790006585526\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.6764972273495875\n",
      "Epoch 25: 0.008017707224739158\n",
      "Epoch 50: 0.004025442810036664\n",
      "Epoch 75: 0.0027544117511554404\n",
      "Epoch 100: 0.0021162931054356667\n",
      "Epoch 125: 0.0017289250559770152\n",
      "Epoch 150: 0.0014673169815701524\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 167.22138571739197\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.48992700144672\n",
      "epoch 10:\t19.316554728702908\n",
      "epoch 20:\t19.1712271567448\n",
      "epoch 30:\t18.991007348601958\n",
      "epoch 40:\t18.83458985944437\n",
      "epoch 50:\t18.71095832879485\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.7186488738201056\n",
      "Epoch 25: 0.015392832230211886\n",
      "Epoch 50: 0.005814481665725503\n",
      "Epoch 75: 0.0037161891812222286\n",
      "Epoch 100: 0.0027641083468274196\n",
      "Epoch 125: 0.0022143103348145976\n",
      "Epoch 150: 0.0018540579293586377\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 187.22345805168152\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.585262591379355\n",
      "epoch 10:\t18.527532554101132\n",
      "epoch 20:\t18.44668109394878\n",
      "epoch 30:\t18.379011969405234\n",
      "epoch 40:\t18.31026156791402\n",
      "epoch 50:\t18.235632920667165\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 6.386730050672181\n",
      "Epoch 25: 0.03168226513110224\n",
      "Epoch 50: 0.008378137390590998\n",
      "Epoch 75: 0.00513829306515955\n",
      "Epoch 100: 0.003777836485899629\n",
      "Epoch 125: 0.0030132118734275447\n",
      "Epoch 150: 0.0025192542548068326\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 210.33798003196716\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.573434935504174\n",
      "epoch 10:\t23.351050803686526\n",
      "epoch 20:\t23.149934728436136\n",
      "epoch 30:\t22.98582652364161\n",
      "epoch 40:\t22.85166469344882\n",
      "epoch 50:\t22.726070760664655\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.103576277324547\n",
      "Epoch 25: 0.007391933911624327\n",
      "Epoch 50: 0.003524582524425617\n",
      "Epoch 75: 0.002367519000686156\n",
      "Epoch 100: 0.0018002176498481098\n",
      "Epoch 125: 0.0014604808573380572\n",
      "Epoch 150: 0.0012331005110168495\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 233.06008338928223\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.00986803254752\n",
      "epoch 10:\t21.822853833190955\n",
      "epoch 20:\t21.689463576386274\n",
      "epoch 30:\t21.537908730465613\n",
      "epoch 40:\t21.382265836372866\n",
      "epoch 50:\t21.254283402042567\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.8044332785358748\n",
      "Epoch 25: 0.010539666725563644\n",
      "Epoch 50: 0.004936709455316117\n",
      "Epoch 75: 0.003311756141178753\n",
      "Epoch 100: 0.002522434524942769\n",
      "Epoch 125: 0.0020510104281689003\n",
      "Epoch 150: 0.0017355997590129846\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 264.267028093338\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.989097355594925\n",
      "epoch 10:\t19.91210693328592\n",
      "epoch 20:\t19.850295174191455\n",
      "epoch 30:\t19.788516176000545\n",
      "epoch 40:\t19.729596618388232\n",
      "epoch 50:\t19.67257795478231\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.9771409824188848\n",
      "Epoch 25: 0.005876495422645285\n",
      "Epoch 50: 0.0027761702840356796\n",
      "Epoch 75: 0.0018485769343563989\n",
      "Epoch 100: 0.00139673410024094\n",
      "Epoch 125: 0.0011277702119314675\n",
      "Epoch 150: 0.0009487010400361278\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 283.77928614616394\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.15872654945169\n",
      "epoch 10:\t20.994643254515445\n",
      "epoch 20:\t20.889219108199434\n",
      "epoch 30:\t20.77700338469528\n",
      "epoch 40:\t20.685846463670977\n",
      "epoch 50:\t20.5934540559441\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.9829293372635877\n",
      "Epoch 25: 0.00890653217077941\n",
      "Epoch 50: 0.0036769324435628266\n",
      "Epoch 75: 0.0023857103837788096\n",
      "Epoch 100: 0.0017877976719415877\n",
      "Epoch 125: 0.0014393954148816076\n",
      "Epoch 150: 0.0012098678454590492\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 307.3232114315033\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t26.114602819401682\n",
      "epoch 10:\t25.760612354606614\n",
      "epoch 20:\t25.27181005061845\n",
      "epoch 30:\t24.814327419460774\n",
      "epoch 40:\t24.364151873191403\n",
      "epoch 50:\t23.952279100798513\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.2453539410875405\n",
      "Epoch 25: 0.007221409808606522\n",
      "Epoch 50: 0.003292698211774169\n",
      "Epoch 75: 0.002175347149274303\n",
      "Epoch 100: 0.0016407766716837408\n",
      "Epoch 125: 0.0013255510151176238\n",
      "Epoch 150: 0.0011168204209540962\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 331.32477378845215\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.851142158405626\n",
      "epoch 10:\t22.801282839150993\n",
      "epoch 20:\t22.576772341395934\n",
      "epoch 30:\t22.336404643846812\n",
      "epoch 40:\t22.13157604571347\n",
      "epoch 50:\t21.936151582047092\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.835650669848189\n",
      "Epoch 25: 0.008615990609600265\n",
      "Epoch 50: 0.0037791118000726244\n",
      "Epoch 75: 0.0024965943380578894\n",
      "Epoch 100: 0.0018896010808659143\n",
      "Epoch 125: 0.001531597887463983\n",
      "Epoch 150: 0.0012937564252620021\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 344.8439230918884\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.87951329775793\n",
      "epoch 10:\t21.609583785677806\n",
      "epoch 20:\t21.374985183572463\n",
      "epoch 30:\t21.146925251475402\n",
      "epoch 40:\t20.908895052425535\n",
      "epoch 50:\t20.683415301318153\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.0130757942501516\n",
      "Epoch 25: 0.018946271147936265\n",
      "Epoch 50: 0.004527614615739613\n",
      "Epoch 75: 0.002793914477332393\n",
      "Epoch 100: 0.0020625949514161118\n",
      "Epoch 125: 0.0016485953188882499\n",
      "Epoch 150: 0.0013795942953673665\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 169.36197710037231\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.141952502430648\n",
      "epoch 10:\t20.986465825104034\n",
      "epoch 20:\t20.73812942822706\n",
      "epoch 30:\t20.522807447303148\n",
      "epoch 40:\t20.32276133698312\n",
      "epoch 50:\t20.147302365526336\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 5.931420692024758\n",
      "Epoch 25: 0.0274967080895619\n",
      "Epoch 50: 0.007544038837314864\n",
      "Epoch 75: 0.004652672860395666\n",
      "Epoch 100: 0.0034209811425203692\n",
      "Epoch 125: 0.0027264560565738193\n",
      "Epoch 150: 0.0022766816292249\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 193.20699405670166\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.8286005941117\n",
      "epoch 10:\t18.73982597343862\n",
      "epoch 20:\t18.63870677704113\n",
      "epoch 30:\t18.557730064488265\n",
      "epoch 40:\t18.490939181058966\n",
      "epoch 50:\t18.41826496452496\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 5.717472193680078\n",
      "Epoch 25: 0.027288279246897675\n",
      "Epoch 50: 0.00819466482400628\n",
      "Epoch 75: 0.00500264523851115\n",
      "Epoch 100: 0.0036470251293508225\n",
      "Epoch 125: 0.0028877940763777587\n",
      "Epoch 150: 0.0023996049808403088\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 218.02778792381287\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.833737199558858\n",
      "epoch 10:\t22.53110330653086\n",
      "epoch 20:\t22.30699458248825\n",
      "epoch 30:\t22.11693086532055\n",
      "epoch 40:\t21.960229457232266\n",
      "epoch 50:\t21.824923931630057\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.33508396314053\n",
      "Epoch 25: 0.01592504507264165\n",
      "Epoch 50: 0.005995053685411891\n",
      "Epoch 75: 0.0038420682688142605\n",
      "Epoch 100: 0.0028688629922456244\n",
      "Epoch 125: 0.00230762209648216\n",
      "Epoch 150: 0.0019401352673391948\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 262.4925711154938\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t25.313367207873036\n",
      "epoch 10:\t25.199084836044797\n",
      "epoch 20:\t24.978783905433346\n",
      "epoch 30:\t24.71380693032838\n",
      "epoch 40:\t24.44487538676406\n",
      "epoch 50:\t24.182971413031176\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.084877554877587\n",
      "Epoch 25: 0.006880885046975323\n",
      "Epoch 50: 0.0034188256505302663\n",
      "Epoch 75: 0.0023227515433063674\n",
      "Epoch 100: 0.001776408325976604\n",
      "Epoch 125: 0.0014465876076837957\n",
      "Epoch 150: 0.0012247978951802452\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 272.2025966644287\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.50827004943057\n",
      "epoch 10:\t18.40771581824874\n",
      "epoch 20:\t18.278970912527704\n",
      "epoch 30:\t18.170394785411673\n",
      "epoch 40:\t18.08557541778162\n",
      "epoch 50:\t18.02176877612144\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.258408594256848\n",
      "Epoch 25: 0.03581006818670341\n",
      "Epoch 50: 0.007744724390673499\n",
      "Epoch 75: 0.004443860824132819\n",
      "Epoch 100: 0.0031487209098165956\n",
      "Epoch 125: 0.0024498513996005305\n",
      "Epoch 150: 0.0020104004706405993\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 300.81946086883545\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t30.120137697344433\n",
      "epoch 10:\t29.69258176729101\n",
      "epoch 20:\t29.2924536832179\n",
      "epoch 30:\t29.092448989197653\n",
      "epoch 40:\t29.197482055681814\n",
      "epoch 50:\t28.996832828671863\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.712213295086008\n",
      "Epoch 25: 0.006052407208360933\n",
      "Epoch 50: 0.002970356582228343\n",
      "Epoch 75: 0.0019962239565464537\n",
      "Epoch 100: 0.0015132678838424064\n",
      "Epoch 125: 0.0012232408024338485\n",
      "Epoch 150: 0.0010291367877735583\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 322.5249376296997\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.488690836008942\n",
      "epoch 10:\t18.44451361650892\n",
      "epoch 20:\t18.401417866662825\n",
      "epoch 30:\t18.35061118800551\n",
      "epoch 40:\t18.289243706219736\n",
      "epoch 50:\t18.227061270656314\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.1896447209087393\n",
      "Epoch 25: 0.010615806706615362\n",
      "Epoch 50: 0.003953996544274219\n",
      "Epoch 75: 0.002516640535156748\n",
      "Epoch 100: 0.0018705631424802724\n",
      "Epoch 125: 0.001499050186277683\n",
      "Epoch 150: 0.0012561569093688918\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 337.04653096199036\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.7590645417584\n",
      "epoch 10:\t21.577269451447524\n",
      "epoch 20:\t21.45013678703915\n",
      "epoch 30:\t21.364717144900236\n",
      "epoch 40:\t21.290260857748514\n",
      "epoch 50:\t21.216369578558403\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.47821453957151\n",
      "Epoch 25: 0.006764135695345073\n",
      "Epoch 50: 0.0031654199016721966\n",
      "Epoch 75: 0.002120024489424769\n",
      "Epoch 100: 0.0016114300280725452\n",
      "Epoch 125: 0.0013077016186826996\n",
      "Epoch 150: 0.0011046192404086648\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 356.83785462379456\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t25.60914285300418\n",
      "epoch 10:\t25.22745892870912\n",
      "epoch 20:\t24.866948447984914\n",
      "epoch 30:\t24.58809774502688\n",
      "epoch 40:\t24.292140936662708\n",
      "epoch 50:\t23.97734841748848\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.646724799795411\n",
      "Epoch 25: 0.008839020231458411\n",
      "Epoch 50: 0.00433057249042785\n",
      "Epoch 75: 0.002948463788459132\n",
      "Epoch 100: 0.002262426031124297\n",
      "Epoch 125: 0.00184795593677336\n",
      "Epoch 150: 0.001568709950307247\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 381.79757475852966\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.952726617239424\n",
      "epoch 10:\t20.817256859920686\n",
      "epoch 20:\t20.707687955423584\n",
      "epoch 30:\t20.601828493966888\n",
      "epoch 40:\t20.502902709480832\n",
      "epoch 50:\t20.406839692033632\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.6536252902080566\n",
      "Epoch 25: 0.011118674516534345\n",
      "Epoch 50: 0.0045866840274701925\n",
      "Epoch 75: 0.003002458423781781\n",
      "Epoch 100: 0.0022629215808655286\n",
      "Epoch 125: 0.001829097366257413\n",
      "Epoch 150: 0.0015418871873313538\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 204.3739891052246\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.8784085718491\n",
      "epoch 10:\t19.702857991683402\n",
      "epoch 20:\t19.501702421596452\n",
      "epoch 30:\t19.33651598095254\n",
      "epoch 40:\t19.206772382684413\n",
      "epoch 50:\t19.080008138963034\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.958588392660904\n",
      "Epoch 25: 0.01252805821377754\n",
      "Epoch 50: 0.005421447953675383\n",
      "Epoch 75: 0.00352707057868291\n",
      "Epoch 100: 0.002636141976610375\n",
      "Epoch 125: 0.002114606324275056\n",
      "Epoch 150: 0.0017707202359898391\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 241.1300253868103\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.50984084546834\n",
      "epoch 10:\t19.41343576482552\n",
      "epoch 20:\t19.33363715062497\n",
      "epoch 30:\t19.245676341982495\n",
      "epoch 40:\t19.15225546774284\n",
      "epoch 50:\t19.064223896230608\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.4761431308412876\n",
      "Epoch 25: 0.010081440418464907\n",
      "Epoch 50: 0.004786870506798034\n",
      "Epoch 75: 0.0031992668994594415\n",
      "Epoch 100: 0.00242245679423432\n",
      "Epoch 125: 0.001958343715649347\n",
      "Epoch 150: 0.0016485054008571014\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 264.4336893558502\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.216309278630806\n",
      "epoch 10:\t19.194461330104858\n",
      "epoch 20:\t19.12608715508994\n",
      "epoch 30:\t19.03428923330069\n",
      "epoch 40:\t18.929643425467948\n",
      "epoch 50:\t18.840975112275867\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.7402938980374927\n",
      "Epoch 25: 0.00514508184037035\n",
      "Epoch 50: 0.002627125040819409\n",
      "Epoch 75: 0.0018052588430137115\n",
      "Epoch 100: 0.001389780850608875\n",
      "Epoch 125: 0.0011366604193848084\n",
      "Epoch 150: 0.0009653131772466157\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 285.7581968307495\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.070488543865814\n",
      "epoch 10:\t20.943190681980205\n",
      "epoch 20:\t20.765631263675466\n",
      "epoch 30:\t20.619234313766523\n",
      "epoch 40:\t20.499348097753654\n",
      "epoch 50:\t20.393535740504692\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.284200203139723\n",
      "Epoch 25: 0.012114724326319345\n",
      "Epoch 50: 0.005178028020056647\n",
      "Epoch 75: 0.003403758857051192\n",
      "Epoch 100: 0.002569238529373858\n",
      "Epoch 125: 0.002078996623845847\n",
      "Epoch 150: 0.0017544423478324865\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 308.22048258781433\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.13082299579924\n",
      "epoch 10:\t20.93985571266741\n",
      "epoch 20:\t20.79405430130888\n",
      "epoch 30:\t20.52842073454652\n",
      "epoch 40:\t20.313880828448106\n",
      "epoch 50:\t20.115741299331088\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.1386772949409374\n",
      "Epoch 25: 0.012147004881993854\n",
      "Epoch 50: 0.0038992278246273693\n",
      "Epoch 75: 0.002499413326609101\n",
      "Epoch 100: 0.0018749466613380904\n",
      "Epoch 125: 0.0015148897302090202\n",
      "Epoch 150: 0.0012784832698455328\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 328.01486110687256\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.28392720614052\n",
      "epoch 10:\t20.16524281941698\n",
      "epoch 20:\t20.05266255221482\n",
      "epoch 30:\t19.937405853721472\n",
      "epoch 40:\t19.85109249759553\n",
      "epoch 50:\t19.76797902459815\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.749173306745193\n",
      "Epoch 25: 0.005152725766729171\n",
      "Epoch 50: 0.002573071666336815\n",
      "Epoch 75: 0.0017550996828565005\n",
      "Epoch 100: 0.0013450042285652573\n",
      "Epoch 125: 0.0010961843947604997\n",
      "Epoch 150: 0.0009282196819177317\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 348.3618206977844\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.214948044520476\n",
      "epoch 10:\t22.749101182281315\n",
      "epoch 20:\t22.52291352422376\n",
      "epoch 30:\t22.2283484491143\n",
      "epoch 40:\t21.99950670311144\n",
      "epoch 50:\t21.799729907863714\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.7062756595164932\n",
      "Epoch 25: 0.004697346904462295\n",
      "Epoch 50: 0.0023597265071381864\n",
      "Epoch 75: 0.0016125991305116578\n",
      "Epoch 100: 0.0012376489428418294\n",
      "Epoch 125: 0.0010100535591528856\n",
      "Epoch 150: 0.0008563226516329543\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 375.36515069007874\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.9796712891421\n",
      "epoch 10:\t22.74682510757704\n",
      "epoch 20:\t22.461683607206236\n",
      "epoch 30:\t22.166642274140553\n",
      "epoch 40:\t21.934790859440838\n",
      "epoch 50:\t21.730711688571624\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.955847713540484\n",
      "Epoch 25: 0.011883186281515098\n",
      "Epoch 50: 0.0051278996162420565\n",
      "Epoch 75: 0.0033815795689898535\n",
      "Epoch 100: 0.0025604518606393016\n",
      "Epoch 125: 0.0020775237672341225\n",
      "Epoch 150: 0.0017572520026235116\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 393.17196106910706\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.145035685847127\n",
      "epoch 10:\t22.961444867638857\n",
      "epoch 20:\t22.800300878752246\n",
      "epoch 30:\t22.649455385917292\n",
      "epoch 40:\t22.514695851232112\n",
      "epoch 50:\t22.377291874631887\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.160434352555984\n",
      "Epoch 25: 0.005160337744698434\n",
      "Epoch 50: 0.002580344217461306\n",
      "Epoch 75: 0.0017586434629277812\n",
      "Epoch 100: 0.0013470655700029092\n",
      "Epoch 125: 0.0010975944098074182\n",
      "Epoch 150: 0.0009292922926643035\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 407.61310338974\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.00293898528469\n",
      "epoch 10:\t21.80178594233744\n",
      "epoch 20:\t21.620557175868647\n",
      "epoch 30:\t21.38161168538247\n",
      "epoch 40:\t21.13645009528317\n",
      "epoch 50:\t20.915321559398684\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.6980728767266984\n",
      "Epoch 25: 0.008137032215544798\n",
      "Epoch 50: 0.0032344357458281166\n",
      "Epoch 75: 0.0020930516317214237\n",
      "Epoch 100: 0.0015684026222756715\n",
      "Epoch 125: 0.0012636639357899238\n",
      "Epoch 150: 0.0010632610615703818\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 238.04393458366394\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.526886122801898\n",
      "epoch 10:\t24.065891438433823\n",
      "epoch 20:\t23.700930914062432\n",
      "epoch 30:\t23.428588806547776\n",
      "epoch 40:\t23.20742315846807\n",
      "epoch 50:\t22.963659580181464\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.8929623735854157\n",
      "Epoch 25: 0.011117439200126299\n",
      "Epoch 50: 0.004842279212243739\n",
      "Epoch 75: 0.0032271784414277995\n",
      "Epoch 100: 0.002458861794002587\n",
      "Epoch 125: 0.0020031184658268774\n",
      "Epoch 150: 0.001698961645405162\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 266.552695274353\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.67502496924017\n",
      "epoch 10:\t21.383501030426277\n",
      "epoch 20:\t21.19323519433857\n",
      "epoch 30:\t21.035232985458055\n",
      "epoch 40:\t20.891465500634453\n",
      "epoch 50:\t20.760009787720982\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.7341412948312827\n",
      "Epoch 25: 0.008669030578916395\n",
      "Epoch 50: 0.003921413069413878\n",
      "Epoch 75: 0.0025925106799344834\n",
      "Epoch 100: 0.001954601717245298\n",
      "Epoch 125: 0.001576843445554048\n",
      "Epoch 150: 0.0013258921469579425\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 286.59071946144104\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.041746420127573\n",
      "epoch 10:\t23.779847022675277\n",
      "epoch 20:\t23.49091149963166\n",
      "epoch 30:\t23.300782376701022\n",
      "epoch 40:\t23.15711748149478\n",
      "epoch 50:\t23.023955710410497\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.9281752178022091\n",
      "Epoch 25: 0.008197828841674021\n",
      "Epoch 50: 0.0036887857709604326\n",
      "Epoch 75: 0.002434244551146677\n",
      "Epoch 100: 0.001834922189502826\n",
      "Epoch 125: 0.0014809828738638385\n",
      "Epoch 150: 0.0012462341748594643\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 315.76285672187805\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.70394025915572\n",
      "epoch 10:\t21.610268296580728\n",
      "epoch 20:\t21.587209888569767\n",
      "epoch 30:\t21.522669543179568\n",
      "epoch 40:\t21.432579596532612\n",
      "epoch 50:\t21.3178972458377\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.17281551660852\n",
      "Epoch 25: 0.013922408836180693\n",
      "Epoch 50: 0.005509425762244064\n",
      "Epoch 75: 0.0035312491943113853\n",
      "Epoch 100: 0.0026259100250244955\n",
      "Epoch 125: 0.0021015814355432668\n",
      "Epoch 150: 0.0017577115177391533\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 334.5150303840637\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.806555730606654\n",
      "epoch 10:\t22.478975681761572\n",
      "epoch 20:\t22.32324112611806\n",
      "epoch 30:\t22.184692875291386\n",
      "epoch 40:\t22.021589944065738\n",
      "epoch 50:\t21.85981746801544\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.5704141190396816\n",
      "Epoch 25: 0.00581188155946919\n",
      "Epoch 50: 0.002750116382206034\n",
      "Epoch 75: 0.0018484664724330404\n",
      "Epoch 100: 0.001407294011144068\n",
      "Epoch 125: 0.001142923501280456\n",
      "Epoch 150: 0.0009657868739594206\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 357.9664890766144\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t27.7877659579056\n",
      "epoch 10:\t27.28060726695208\n",
      "epoch 20:\t26.861793717591194\n",
      "epoch 30:\t26.5156232289071\n",
      "epoch 40:\t26.151737369553736\n",
      "epoch 50:\t25.792026847774974\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.5845950818573202\n",
      "Epoch 25: 0.0067961114938161074\n",
      "Epoch 50: 0.0032799630812640882\n",
      "Epoch 75: 0.0022104156976422867\n",
      "Epoch 100: 0.0016827501860412777\n",
      "Epoch 125: 0.0013659554146617492\n",
      "Epoch 150: 0.001153763605490722\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 393.20270228385925\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.620714075008696\n",
      "epoch 10:\t21.564670666911866\n",
      "epoch 20:\t21.461081662918136\n",
      "epoch 30:\t21.350367148281826\n",
      "epoch 40:\t21.23047550451202\n",
      "epoch 50:\t21.109757343529292\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.4620138788820922\n",
      "Epoch 25: 0.003627448999766568\n",
      "Epoch 50: 0.0018960977684239957\n",
      "Epoch 75: 0.0013088087846062119\n",
      "Epoch 100: 0.0010082517931969902\n",
      "Epoch 125: 0.000824230684981311\n",
      "Epoch 150: 0.0006994362657218243\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 390.75848746299744\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.586691053320486\n",
      "epoch 10:\t23.283824528945345\n",
      "epoch 20:\t23.181527020408776\n",
      "epoch 30:\t22.92851255474014\n",
      "epoch 40:\t22.63724653412549\n",
      "epoch 50:\t22.37500433865825\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.970863287982867\n",
      "Epoch 25: 0.006628275355538363\n",
      "Epoch 50: 0.0032079747681834623\n",
      "Epoch 75: 0.0021760516404550814\n",
      "Epoch 100: 0.0016661011466729207\n",
      "Epoch 125: 0.0013585199725833325\n",
      "Epoch 150: 0.00115136702317207\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 426.1990637779236\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.370965675660774\n",
      "epoch 10:\t23.041347087166763\n",
      "epoch 20:\t22.815533198437226\n",
      "epoch 30:\t22.603692476160468\n",
      "epoch 40:\t22.374366857126894\n",
      "epoch 50:\t22.140637718632778\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.71432944500629\n",
      "Epoch 25: 0.005269735050367542\n",
      "Epoch 50: 0.0025028521668108233\n",
      "Epoch 75: 0.0016617323160962119\n",
      "Epoch 100: 0.0012518985148484976\n",
      "Epoch 125: 0.0010082903701803454\n",
      "Epoch 150: 0.0008463903871268031\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 439.8830053806305\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.840406400134363\n",
      "epoch 10:\t22.72766914257078\n",
      "epoch 20:\t22.658416132407698\n",
      "epoch 30:\t22.54305212473543\n",
      "epoch 40:\t22.42056184173374\n",
      "epoch 50:\t22.30306192821717\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.78448225529148\n",
      "Epoch 25: 0.007975178076342742\n",
      "Epoch 50: 0.0036708642078326355\n",
      "Epoch 75: 0.0024277629318750116\n",
      "Epoch 100: 0.0018300123113348468\n",
      "Epoch 125: 0.0014766624202360245\n",
      "Epoch 150: 0.0012424565322869687\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 266.7939364910126\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.458397486303152\n",
      "epoch 10:\t23.240903879574304\n",
      "epoch 20:\t22.990370546352676\n",
      "epoch 30:\t22.664957263954367\n",
      "epoch 40:\t22.424840915403752\n",
      "epoch 50:\t22.176649467270998\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.2101496976152704\n",
      "Epoch 25: 0.007831579747230429\n",
      "Epoch 50: 0.0027638932735414507\n",
      "Epoch 75: 0.001810474767241198\n",
      "Epoch 100: 0.0013734394252381652\n",
      "Epoch 125: 0.0011176697731232622\n",
      "Epoch 150: 0.0009480677303345992\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 303.39286494255066\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.65569116525012\n",
      "epoch 10:\t21.371186313643847\n",
      "epoch 20:\t21.22903923514204\n",
      "epoch 30:\t21.111701516639307\n",
      "epoch 40:\t20.996300321552802\n",
      "epoch 50:\t20.889397900413606\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.7563248882520366\n",
      "Epoch 25: 0.005283297406773524\n",
      "Epoch 50: 0.0026396737947824806\n",
      "Epoch 75: 0.0017952338769832556\n",
      "Epoch 100: 0.0013727945692252471\n",
      "Epoch 125: 0.0011173062951064956\n",
      "Epoch 150: 0.0009453735436675336\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 324.26872301101685\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.51922074866193\n",
      "epoch 10:\t20.411897298435374\n",
      "epoch 20:\t20.293958918303794\n",
      "epoch 30:\t20.20127079392801\n",
      "epoch 40:\t20.09803963424103\n",
      "epoch 50:\t19.99175866254206\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.682236247484737\n",
      "Epoch 25: 0.008393300408211943\n",
      "Epoch 50: 0.0036676232532250187\n",
      "Epoch 75: 0.002399088397570205\n",
      "Epoch 100: 0.0017987446927263055\n",
      "Epoch 125: 0.001445817800147302\n",
      "Epoch 150: 0.001212388649158878\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 337.45028948783875\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.923820454347645\n",
      "epoch 10:\t20.725307990978603\n",
      "epoch 20:\t20.57279685246638\n",
      "epoch 30:\t20.458851793995706\n",
      "epoch 40:\t20.32550417341708\n",
      "epoch 50:\t20.227381980047614\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.940578348661352\n",
      "Epoch 25: 0.007114570490658397\n",
      "Epoch 50: 0.003445340299008938\n",
      "Epoch 75: 0.002329678197014366\n",
      "Epoch 100: 0.0017787804336665597\n",
      "Epoch 125: 0.001447265470067123\n",
      "Epoch 150: 0.001224628769147826\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 368.565794467926\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t27.58607593496331\n",
      "epoch 10:\t27.182146223035375\n",
      "epoch 20:\t26.80172055065459\n",
      "epoch 30:\t26.392625142462304\n",
      "epoch 40:\t26.064669483753885\n",
      "epoch 50:\t25.7874527559345\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.7634749916188768\n",
      "Epoch 25: 0.0076997294071989636\n",
      "Epoch 50: 0.0033847177148179797\n",
      "Epoch 75: 0.0022627475563197904\n",
      "Epoch 100: 0.0017259672002240731\n",
      "Epoch 125: 0.0014067053084260298\n",
      "Epoch 150: 0.0011932818208849267\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 380.22469544410706\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.31159176318086\n",
      "epoch 10:\t21.12054531201536\n",
      "epoch 20:\t21.06795373836581\n",
      "epoch 30:\t20.9633640609961\n",
      "epoch 40:\t20.85744323944145\n",
      "epoch 50:\t20.72748883003543\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.8755643770221107\n",
      "Epoch 25: 0.008947385034043185\n",
      "Epoch 50: 0.0034603598483261607\n",
      "Epoch 75: 0.0022297904001065366\n",
      "Epoch 100: 0.0016674158525629102\n",
      "Epoch 125: 0.001341241446827791\n",
      "Epoch 150: 0.0011268940423803094\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 405.5441334247589\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.421385923636088\n",
      "epoch 10:\t22.26281990422637\n",
      "epoch 20:\t22.124764165781556\n",
      "epoch 30:\t22.000924773607043\n",
      "epoch 40:\t21.877927393328395\n",
      "epoch 50:\t21.77999184626852\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.711227793063346\n",
      "Epoch 25: 0.004659973546139619\n",
      "Epoch 50: 0.0022946702745019524\n",
      "Epoch 75: 0.0015513461655014091\n",
      "Epoch 100: 0.0011831445186872565\n",
      "Epoch 125: 0.0009618532739573133\n",
      "Epoch 150: 0.0008135254353022598\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 412.2293553352356\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.483424296325254\n",
      "epoch 10:\t21.32296445453031\n",
      "epoch 20:\t21.208561790741996\n",
      "epoch 30:\t21.07646651660164\n",
      "epoch 40:\t20.92304640529438\n",
      "epoch 50:\t20.75964281406563\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.5765765652890162\n",
      "Epoch 25: 0.00343464729970183\n",
      "Epoch 50: 0.0017249583785169116\n",
      "Epoch 75: 0.0011724351114286722\n",
      "Epoch 100: 0.0008957068511127861\n",
      "Epoch 125: 0.0007284170601918034\n",
      "Epoch 150: 0.0006159124343828377\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 444.66883993148804\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t26.179839302784472\n",
      "epoch 10:\t25.576090774997734\n",
      "epoch 20:\t25.205913497963767\n",
      "epoch 30:\t24.991913288263383\n",
      "epoch 40:\t24.741204662997685\n",
      "epoch 50:\t24.442659178674234\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.3928176827891425\n",
      "Epoch 25: 0.0045135437331470405\n",
      "Epoch 50: 0.002266400198116571\n",
      "Epoch 75: 0.0015422260070169311\n",
      "Epoch 100: 0.0011797430327651454\n",
      "Epoch 125: 0.0009606135064677801\n",
      "Epoch 150: 0.0008132255657110363\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 465.2196583747864\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.29926222026892\n",
      "epoch 10:\t21.11488588670334\n",
      "epoch 20:\t20.975203584096853\n",
      "epoch 30:\t20.8222107088519\n",
      "epoch 40:\t20.699779291364077\n",
      "epoch 50:\t20.598483994136803\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.3223790350604925\n",
      "Epoch 25: 0.006836556179405306\n",
      "Epoch 50: 0.0030808352925388053\n",
      "Epoch 75: 0.002042173476105414\n",
      "Epoch 100: 0.001545674896442506\n",
      "Epoch 125: 0.001252033517398972\n",
      "Epoch 150: 0.0010569401463085754\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 290.41162514686584\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.873928573539683\n",
      "epoch 10:\t20.973121449008314\n",
      "epoch 20:\t20.92089117847015\n",
      "epoch 30:\t20.770119413460357\n",
      "epoch 40:\t20.60951863435732\n",
      "epoch 50:\t20.41223513713303\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.506060616646376\n",
      "Epoch 25: 0.005318843104671108\n",
      "Epoch 50: 0.0025992306247313007\n",
      "Epoch 75: 0.0017564939765909078\n",
      "Epoch 100: 0.0013388524918174956\n",
      "Epoch 125: 0.0010874219554021162\n",
      "Epoch 150: 0.0009186486022665955\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 328.465763092041\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.61454244011288\n",
      "epoch 10:\t24.165791871198095\n",
      "epoch 20:\t23.898565013816025\n",
      "epoch 30:\t23.507805629638888\n",
      "epoch 40:\t23.217714559631055\n",
      "epoch 50:\t22.950587830804373\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.8024391887044589\n",
      "Epoch 25: 0.004980292215989616\n",
      "Epoch 50: 0.0024091071341528136\n",
      "Epoch 75: 0.0016343711622303439\n",
      "Epoch 100: 0.0012526584923488843\n",
      "Epoch 125: 0.0010230263031807305\n",
      "Epoch 150: 0.0008687115281633649\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 349.7385263442993\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.57811228164099\n",
      "epoch 10:\t19.531581143426457\n",
      "epoch 20:\t19.454097343032256\n",
      "epoch 30:\t19.33968535376342\n",
      "epoch 40:\t19.26712758466028\n",
      "epoch 50:\t19.189677536941254\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.0452415409938633\n",
      "Epoch 25: 0.009580484759180764\n",
      "Epoch 50: 0.0038255338946474433\n",
      "Epoch 75: 0.002465984767284876\n",
      "Epoch 100: 0.001841062652818794\n",
      "Epoch 125: 0.001478504478329309\n",
      "Epoch 150: 0.001240443892846445\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 373.60481214523315\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.44380365005841\n",
      "epoch 10:\t22.18118133211857\n",
      "epoch 20:\t21.870520614361233\n",
      "epoch 30:\t21.564627985445398\n",
      "epoch 40:\t21.327189328690753\n",
      "epoch 50:\t21.158644859832915\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.3630839237781767\n",
      "Epoch 25: 0.0322486193987614\n",
      "Epoch 50: 0.006470660646891701\n",
      "Epoch 75: 0.0036925446651192334\n",
      "Epoch 100: 0.0026591227651052425\n",
      "Epoch 125: 0.0021045947864983343\n",
      "Epoch 150: 0.001754366663547747\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 394.7416350841522\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.067191727425442\n",
      "epoch 10:\t21.85072824707176\n",
      "epoch 20:\t21.645704386715828\n",
      "epoch 30:\t21.48283035081787\n",
      "epoch 40:\t21.342134753992667\n",
      "epoch 50:\t21.225930878568835\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.664895919697119\n",
      "Epoch 25: 0.011087983155647407\n",
      "Epoch 50: 0.004629468243976476\n",
      "Epoch 75: 0.0030184831242522137\n",
      "Epoch 100: 0.002271065301151509\n",
      "Epoch 125: 0.0018353244462623764\n",
      "Epoch 150: 0.001548141431008787\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 424.0806291103363\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.83735857049623\n",
      "epoch 10:\t21.6966712991304\n",
      "epoch 20:\t21.55373292595226\n",
      "epoch 30:\t21.3729331266656\n",
      "epoch 40:\t21.21196052355603\n",
      "epoch 50:\t21.056937233283783\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.225473312827206\n",
      "Epoch 25: 0.004561033065883681\n",
      "Epoch 50: 0.0023614989326534563\n",
      "Epoch 75: 0.0016313918210705517\n",
      "Epoch 100: 0.0012597303469943078\n",
      "Epoch 125: 0.0010324025330400927\n",
      "Epoch 150: 0.0008781099855099228\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 445.601202249527\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.208023393138784\n",
      "epoch 10:\t22.053769889940078\n",
      "epoch 20:\t21.960512654793757\n",
      "epoch 30:\t21.822568038324405\n",
      "epoch 40:\t21.68941615194226\n",
      "epoch 50:\t21.614434913131582\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.4257325802440945\n",
      "Epoch 25: 0.006749673141193095\n",
      "Epoch 50: 0.002956279186164718\n",
      "Epoch 75: 0.001948320762639671\n",
      "Epoch 100: 0.0014700651116590457\n",
      "Epoch 125: 0.0011878640882593396\n",
      "Epoch 150: 0.001000574793070857\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 467.4432773590088\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.620640634296038\n",
      "epoch 10:\t21.464633082677484\n",
      "epoch 20:\t21.327736501397787\n",
      "epoch 30:\t21.21000642787328\n",
      "epoch 40:\t21.12543875600614\n",
      "epoch 50:\t21.040567549076805\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.7863706957322085\n",
      "Epoch 25: 0.004506047688097083\n",
      "Epoch 50: 0.0021519218612262884\n",
      "Epoch 75: 0.0014379986099198755\n",
      "Epoch 100: 0.0010880538694894388\n",
      "Epoch 125: 0.0008790506792504447\n",
      "Epoch 150: 0.0007396408634628409\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 483.75329208374023\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.21576054852788\n",
      "epoch 10:\t23.834616366594496\n",
      "epoch 20:\t23.634668806716583\n",
      "epoch 30:\t23.389665809572435\n",
      "epoch 40:\t23.172122843374204\n",
      "epoch 50:\t22.973913730877378\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.7932184366998967\n",
      "Epoch 25: 0.004098654616596313\n",
      "Epoch 50: 0.0020359123083156837\n",
      "Epoch 75: 0.0013854775539358676\n",
      "Epoch 100: 0.001060535484453453\n",
      "Epoch 125: 0.0008639618806689597\n",
      "Epoch 150: 0.0007315597144861918\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 506.7841682434082\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.480410300589888\n",
      "epoch 10:\t19.270216239252143\n",
      "epoch 20:\t19.181743317136444\n",
      "epoch 30:\t19.121840605112464\n",
      "epoch 40:\t19.06802197361673\n",
      "epoch 50:\t19.00808566281007\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.9506104756965141\n",
      "Epoch 25: 0.006761239584486656\n",
      "Epoch 50: 0.0029818342097444528\n",
      "Epoch 75: 0.001953693484311047\n",
      "Epoch 100: 0.0014659981608075418\n",
      "Epoch 125: 0.0011792213520753388\n",
      "Epoch 150: 0.0009896156144535853\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 329.0379192829132\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.14537635556963\n",
      "epoch 10:\t22.02428544297504\n",
      "epoch 20:\t21.85806883260969\n",
      "epoch 30:\t21.583794913698213\n",
      "epoch 40:\t21.377077305604647\n",
      "epoch 50:\t21.225253482167155\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.3941687764051753\n",
      "Epoch 25: 0.0068307089400991144\n",
      "Epoch 50: 0.0028415753545386734\n",
      "Epoch 75: 0.001835745346423484\n",
      "Epoch 100: 0.0013667696134449078\n",
      "Epoch 125: 0.001093445452858399\n",
      "Epoch 150: 0.0009138176779571332\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 353.3493106365204\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.197007563022478\n",
      "epoch 10:\t20.973039906864724\n",
      "epoch 20:\t20.840872481148704\n",
      "epoch 30:\t20.746607573113938\n",
      "epoch 40:\t20.65671249527124\n",
      "epoch 50:\t20.573054197491707\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.793341795193364\n",
      "Epoch 25: 0.0071383617300533955\n",
      "Epoch 50: 0.003169629574181511\n",
      "Epoch 75: 0.0020827342965619383\n",
      "Epoch 100: 0.001566120304488051\n",
      "Epoch 125: 0.0012620310666350857\n",
      "Epoch 150: 0.001060850461573082\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 382.7691419124603\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.737049829509935\n",
      "epoch 10:\t23.342088708662683\n",
      "epoch 20:\t22.962459100591115\n",
      "epoch 30:\t22.62586613573776\n",
      "epoch 40:\t22.312403739551865\n",
      "epoch 50:\t22.024203246056192\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.0929574653105982\n",
      "Epoch 25: 0.004528576672762073\n",
      "Epoch 50: 0.0022926927458162237\n",
      "Epoch 75: 0.0015756926622223129\n",
      "Epoch 100: 0.001214070513391502\n",
      "Epoch 125: 0.00099370006400559\n",
      "Epoch 150: 0.0008443876020181528\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 399.6836562156677\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.28239025882685\n",
      "epoch 10:\t21.901378600496578\n",
      "epoch 20:\t21.547192228849006\n",
      "epoch 30:\t21.289890543279974\n",
      "epoch 40:\t21.135101648189934\n",
      "epoch 50:\t21.015108987342487\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.537480533704224\n",
      "Epoch 25: 0.008231209994393723\n",
      "Epoch 50: 0.003304558828085909\n",
      "Epoch 75: 0.002142845705345123\n",
      "Epoch 100: 0.0016035684723513337\n",
      "Epoch 125: 0.0012887353014444285\n",
      "Epoch 150: 0.0010812158844498753\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 422.06435465812683\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.253703588989598\n",
      "epoch 10:\t21.099010866535025\n",
      "epoch 20:\t20.986232313193504\n",
      "epoch 30:\t20.835127505129385\n",
      "epoch 40:\t20.663269739148717\n",
      "epoch 50:\t20.525975899517746\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.6149101901210134\n",
      "Epoch 25: 0.0036736357066465774\n",
      "Epoch 50: 0.0017842374687513315\n",
      "Epoch 75: 0.001206550868734701\n",
      "Epoch 100: 0.0009209337034794187\n",
      "Epoch 125: 0.0007490068757029281\n",
      "Epoch 150: 0.0006335547715515279\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 442.0882349014282\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t25.280431870318672\n",
      "epoch 10:\t24.662556515710882\n",
      "epoch 20:\t24.239630345665656\n",
      "epoch 30:\t23.796720164510795\n",
      "epoch 40:\t23.5056298227452\n",
      "epoch 50:\t23.27857060345561\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.6935389807063561\n",
      "Epoch 25: 0.0037294238250203545\n",
      "Epoch 50: 0.0018301065272088922\n",
      "Epoch 75: 0.001239415518203365\n",
      "Epoch 100: 0.0009451291102197645\n",
      "Epoch 125: 0.0007674239758172187\n",
      "Epoch 150: 0.0006479307032880614\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 462.37775564193726\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.31745512608716\n",
      "epoch 10:\t22.143410409380298\n",
      "epoch 20:\t22.087596483365097\n",
      "epoch 30:\t22.014954046036813\n",
      "epoch 40:\t21.93852485032485\n",
      "epoch 50:\t21.85395940992021\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.0587220238619213\n",
      "Epoch 25: 0.0037490824749823277\n",
      "Epoch 50: 0.0018776769960627741\n",
      "Epoch 75: 0.0012764910312644583\n",
      "Epoch 100: 0.0009752389275076568\n",
      "Epoch 125: 0.0007929442402851879\n",
      "Epoch 150: 0.0006702364178894355\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 489.4837996959686\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.106175220475524\n",
      "epoch 10:\t21.96101478177459\n",
      "epoch 20:\t21.7707268061975\n",
      "epoch 30:\t21.608824572406398\n",
      "epoch 40:\t21.496105958081085\n",
      "epoch 50:\t21.40459548220509\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.8767804274696853\n",
      "Epoch 25: 0.002500961563595113\n",
      "Epoch 50: 0.0012983104447979387\n",
      "Epoch 75: 0.000895135414429764\n",
      "Epoch 100: 0.000689612027524421\n",
      "Epoch 125: 0.0005639379138320189\n",
      "Epoch 150: 0.00047871735271302787\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 511.40969157218933\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.410176788443167\n",
      "epoch 10:\t23.872874250352744\n",
      "epoch 20:\t23.581171205706834\n",
      "epoch 30:\t23.35619177288651\n",
      "epoch 40:\t23.11645783874406\n",
      "epoch 50:\t22.877196906335122\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.8826881760934866\n",
      "Epoch 25: 0.0035599962271792196\n",
      "Epoch 50: 0.0017697080837079432\n",
      "Epoch 75: 0.001201036624417347\n",
      "Epoch 100: 0.0009175641627404349\n",
      "Epoch 125: 0.0007465311871061263\n",
      "Epoch 150: 0.0006316155762591206\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 540.7312471866608\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.32506725036926\n",
      "epoch 10:\t22.948120082494345\n",
      "epoch 20:\t22.67588085175165\n",
      "epoch 30:\t22.419216691680994\n",
      "epoch 40:\t22.21951075020728\n",
      "epoch 50:\t22.041202730160343\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.357492501934542\n",
      "Epoch 25: 0.005289627370135956\n",
      "Epoch 50: 0.0024846411058879986\n",
      "Epoch 75: 0.001662530785728854\n",
      "Epoch 100: 0.0012619977706216795\n",
      "Epoch 125: 0.0010229743627793073\n",
      "Epoch 150: 0.0008633910558913798\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 362.58656549453735\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t25.773203774062928\n",
      "epoch 10:\t25.39464151106916\n",
      "epoch 20:\t24.974959100055656\n",
      "epoch 30:\t24.696571485576015\n",
      "epoch 40:\t24.458980812377412\n",
      "epoch 50:\t24.262749914963138\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.188106651350972\n",
      "Epoch 25: 0.016021883354080963\n",
      "Epoch 50: 0.0031906983974953743\n",
      "Epoch 75: 0.0018693362858012452\n",
      "Epoch 100: 0.0013473847658086267\n",
      "Epoch 125: 0.001062102685673067\n",
      "Epoch 150: 0.0008807185465880609\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 381.96713972091675\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.407852993520674\n",
      "epoch 10:\t22.19765419535068\n",
      "epoch 20:\t22.053118868649726\n",
      "epoch 30:\t21.88080576246812\n",
      "epoch 40:\t21.693944213837582\n",
      "epoch 50:\t21.502920229378386\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.9172130795955686\n",
      "Epoch 25: 0.008242695693232441\n",
      "Epoch 50: 0.0028673337067190124\n",
      "Epoch 75: 0.0018431626432387812\n",
      "Epoch 100: 0.0013780823806670132\n",
      "Epoch 125: 0.0011080332435870245\n",
      "Epoch 150: 0.0009302892208002196\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 416.12929034233093\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t26.23465658431771\n",
      "epoch 10:\t25.865942095217928\n",
      "epoch 20:\t25.50771169969747\n",
      "epoch 30:\t25.20547740437312\n",
      "epoch 40:\t24.940668094720536\n",
      "epoch 50:\t24.701110492119046\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.6232880678609947\n",
      "Epoch 25: 0.008403271454121888\n",
      "Epoch 50: 0.0033914002422520614\n",
      "Epoch 75: 0.002166829298293964\n",
      "Epoch 100: 0.0016044231710331974\n",
      "Epoch 125: 0.001279859924157949\n",
      "Epoch 150: 0.001068014958577013\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 443.16038942337036\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.20188350251103\n",
      "epoch 10:\t21.184679665467165\n",
      "epoch 20:\t21.061031887616757\n",
      "epoch 30:\t20.962291531255946\n",
      "epoch 40:\t20.902442518636207\n",
      "epoch 50:\t20.8387017272986\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.100452511768235\n",
      "Epoch 25: 0.005772479155760136\n",
      "Epoch 50: 0.002741731791377658\n",
      "Epoch 75: 0.0018401175485964164\n",
      "Epoch 100: 0.0013989497672836089\n",
      "Epoch 125: 0.0011349342187632568\n",
      "Epoch 150: 0.0009582731701454707\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 453.88634300231934\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.233396992311647\n",
      "epoch 10:\t19.136532771019983\n",
      "epoch 20:\t19.039107660408487\n",
      "epoch 30:\t18.964745874229916\n",
      "epoch 40:\t18.908266651539336\n",
      "epoch 50:\t18.8680766258808\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.0242023599048307\n",
      "Epoch 25: 0.004200307042197463\n",
      "Epoch 50: 0.0021085711022199366\n",
      "Epoch 75: 0.0014359210522426307\n",
      "Epoch 100: 0.001099250021232709\n",
      "Epoch 125: 0.0008955520042584831\n",
      "Epoch 150: 0.0007583601326421165\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 475.07741618156433\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.23607595117543\n",
      "epoch 10:\t23.03516256578029\n",
      "epoch 20:\t22.871645735345645\n",
      "epoch 30:\t22.68683516354226\n",
      "epoch 40:\t22.51458901428786\n",
      "epoch 50:\t22.355764833754638\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.7401569580610576\n",
      "Epoch 25: 0.00354425683439876\n",
      "Epoch 50: 0.001807268299340847\n",
      "Epoch 75: 0.0012367929765194055\n",
      "Epoch 100: 0.0009484570683868335\n",
      "Epoch 125: 0.000773110689861949\n",
      "Epoch 150: 0.0006546736124327697\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 502.40260910987854\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.52443297041617\n",
      "epoch 10:\t22.371771648213887\n",
      "epoch 20:\t22.166387939094676\n",
      "epoch 30:\t21.976266623127916\n",
      "epoch 40:\t21.794654725466525\n",
      "epoch 50:\t21.639506909476616\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.9845161505359711\n",
      "Epoch 25: 0.0029758075678360946\n",
      "Epoch 50: 0.0014567049426783736\n",
      "Epoch 75: 0.0009944317526608731\n",
      "Epoch 100: 0.0007643288219724917\n",
      "Epoch 125: 0.0006249471765346054\n",
      "Epoch 150: 0.00053083675341374\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 518.047669172287\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.509238814379973\n",
      "epoch 10:\t22.39081293116903\n",
      "epoch 20:\t22.264130199356277\n",
      "epoch 30:\t22.160243785525306\n",
      "epoch 40:\t22.05777670772466\n",
      "epoch 50:\t21.953472981300134\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.1920903385275101\n",
      "Epoch 25: 0.0027584391851697746\n",
      "Epoch 50: 0.001413999952510124\n",
      "Epoch 75: 0.0009679405087190838\n",
      "Epoch 100: 0.0007420950841853303\n",
      "Epoch 125: 0.0006047076177237997\n",
      "Epoch 150: 0.0005119090998462969\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 527.7090079784393\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.078674286206486\n",
      "epoch 10:\t21.045784127123103\n",
      "epoch 20:\t21.000628341071803\n",
      "epoch 30:\t20.94305857595799\n",
      "epoch 40:\t20.81600526490899\n",
      "epoch 50:\t20.70244733744285\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.6150417969505482\n",
      "Epoch 25: 0.0033072562107956415\n",
      "Epoch 50: 0.0016942974460660942\n",
      "Epoch 75: 0.001160200121045973\n",
      "Epoch 100: 0.0008898304969048196\n",
      "Epoch 125: 0.0007253599301384542\n",
      "Epoch 150: 0.0006142749163768871\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 559.8425574302673\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "en_revs = df_full[df_full.Language==\"en\"]\n",
    "tr_revs = df_full[df_full.Language==\"tr\"]\n",
    "test = tr_revs[-100:]\n",
    "tr_revs = tr_revs[:-100]\n",
    "robustness = dict()  # {(num of en reviews, num of tr reviews): scores_dict}\n",
    "for en_size in range(1,11):\n",
    "    for tr_size in range(1,11):\n",
    "        en_train = en_revs.sample(frac=en_size/10.0)\n",
    "        tr_train = tr_revs.sample(frac=tr_size/10.0)\n",
    "        start = time.time()\n",
    "        print(\"En: {}\\tTr: {}\".format(len(en_train),len(tr_train)))\n",
    "        train = pd.concat([en_train, tr_train]).reset_index(drop=True)\n",
    "        robustness_tables = dict()\n",
    "        print(\"Using first variation (Regressor and Classifier with score vectors)\")\n",
    "        LSMR, score_vect_dicts, training_curve = get_score_vects(\n",
    "                                        train, alpha=1e-5, iterations=50)\n",
    "        regressor, classifier = fit(LSMR, score_vect_dicts)\n",
    "        preds, true = predict(test_data, score_vect_dicts, regressor, classifier)\n",
    "        s_regclass = distance_accuracy(true, preds)\n",
    "#         f1_test_regclass = f1_score(true, preds, average='weighted')\n",
    "        robustness_tables[\"DeepSelect (regclass)\"] = s_regclass\n",
    "    \n",
    "        print(\"Using second variation (average of outputs produced by each set of weight matrices)\")\n",
    "        W1, W2, W3, training_curve = train_selective(train, epochs=150, p_every=25)\n",
    "        preds_nn, true_nn = predict_selective(tr_revs, W1, W2, W3)\n",
    "        s_nn = distance_accuracy(true_nn, preds_nn)\n",
    "#         f1_test_nn = f1_score(true_nn, preds_nn, average='weighted')\n",
    "        robustness_tables[\"DeepSelect\"] = s_nn\n",
    "    \n",
    "        print(\"Using well-known algorithms: Logistic Regression, RandomForest and MLP\")\n",
    "        lr = LogisticRegression()\n",
    "        rf = RandomForestClassifier(n_jobs=-1)\n",
    "        mlp = MLPClassifier()\n",
    "        \n",
    "        train_mat = np.array(list(LSMR[\"rev_vec\"]))\n",
    "        train_y = np.array(list(LSMR[\"Score\"]))\n",
    "        test_mat = np.array(list(preprocess_data(tr_revs)[\"rev_vec\"]))\n",
    "        \n",
    "        for name, model in [(\"Logistic Regression\",lr),\n",
    "                            (\"RandomForest\", rf),\n",
    "                            (\"MLP\", mlp)]:\n",
    "            model.fit(train_mat, train_y)\n",
    "            robustness_tables[name] = distance_accuracy(true, model.predict(test_mat))\n",
    "        robustness[(len(en_train),len(tr_train))] = robustness_tables\n",
    "        print(\"Took: {}\".format(time.time()-start))\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(robustness, open(\"robustness.results\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW TO CHEAT LIKE A PRO\n",
    "# \"\"\"\n",
    "# def test_selective(df_test, W1, W2, W3):\n",
    "#     reset_graph()\n",
    "#     x = tf.placeholder(tf.float32, [None, 300])\n",
    "#     y = tf.placeholder(tf.float32, [None, 10]) # 1-10 => 10 classes\n",
    "\n",
    "#     w1 = tf.placeholder(tf.float32, [300, 300])\n",
    "#     w2 = tf.placeholder(tf.float32, [300, 300])\n",
    "#     w3 = tf.placeholder(tf.float32, [300, 10])\n",
    "\n",
    "#     b1 = tf.Variable(tf.zeros([300]))\n",
    "#     b2 = tf.Variable(tf.zeros([300]))\n",
    "#     b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#     l2 = tf.nn.sigmoid(tf.matmul(x, w1) + b1)\n",
    "#     l3 = tf.nn.sigmoid(tf.matmul(l2, w2) + b2)\n",
    "#     pred = tf.nn.softmax(tf.matmul(l3, w3) + b3)\n",
    "    \n",
    "#     correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "#     instance_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#         # Testing the model\n",
    "#         LSMR_test = preprocess_data(df_test)\n",
    "#         X_test, y_test = get_test(LSMR_test)\n",
    "#         accuracy = 0.\n",
    "#         for i in range(len(X_test)):\n",
    "#             best_instance_accuracy = float(\"-inf\")\n",
    "#             for language, score, movie_id in W1:\n",
    "#                 w_1 = W1[(language, score, movie_id)]\n",
    "#                 w_2 = W2[(language, score)]\n",
    "#                 w_3 = W3[score]\n",
    "#                 a = instance_accuracy.eval({x: np.atleast_2d(X_test[i]), y: np.atleast_2d(y_test[i]),\n",
    "#                                    w1:w_1,\n",
    "#                                    w2:w_2,\n",
    "#                                    w3:w_3})\n",
    "#                 if a > best_instance_accuracy:\n",
    "#                     best_instance_accuracy = a\n",
    "#             accuracy += best_instance_accuracy\n",
    "\n",
    "#     return accuracy/len(X_test)\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-layer NN > needs at least 3 days for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu is a must\n",
    "def train_deep(df_train, epochs=100, learning_rate=0.1, random_state=42):\n",
    "    LSMR_train = preprocess_data(df_train)\n",
    "    np.random.seed(random_state)\n",
    "    data_dict, L1, L2, L3 = get_data_dict(LSMR_train, get_L2and3=True)\n",
    "    init_weights = lambda layer, i, o: {k:2*np.random.random((i, o))-1 for k in layer}\n",
    "    W1 = init_weights(L1, 300, 300)  # (languge, score, movie_id)\n",
    "    W2 = init_weights(L2, 300, 300)  # (languge, score):\n",
    "    W3 = init_weights(L3, 300, 10)  # score:\n",
    "    \n",
    "    \n",
    "    reset_graph()\n",
    "    x = tf.placeholder(tf.float32, [None, 300])\n",
    "    y = tf.placeholder(tf.float32, [None, 10]) # 1-10 => 10 classes\n",
    "\n",
    "    w1 = tf.Variable(tf.zeros([300, 300]))\n",
    "    w2 = tf.Variable(tf.zeros([300, 300]))\n",
    "    w3 = tf.Variable(tf.zeros([300, 10]))\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([300]))\n",
    "    b2 = tf.Variable(tf.zeros([300]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    l2 = tf.nn.sigmoid(tf.matmul(x, w1) + b1)\n",
    "    l3 = tf.nn.sigmoid(tf.matmul(l2, w2) + b2)\n",
    "    pred = tf.nn.softmax(tf.matmul(l3, w3) + b3)\n",
    "\n",
    "\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    training_curve = dict()\n",
    "    with tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):\n",
    "        with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for e in range(epochs+1):\n",
    "                start = time.time()\n",
    "                avg_cost = 0.\n",
    "                for _, row in LSMR_train.iterrows():\n",
    "                    score = row[\"Score\"]\n",
    "                    y_ = np.zeros(10)\n",
    "                    y_[score-1] = 1\n",
    "                    y_ = np.atleast_2d(y_)\n",
    "                    x_ = np.atleast_2d(row[\"rev_vec\"])\n",
    "                    w_1, w_2, w_3 , _, c = sess.run([w1, w2, w3, optimizer, cost], feed_dict={x: x_,y: y_})               \n",
    "                    avg_cost += c\n",
    "                avg_cost /= len(LSMR_train)\n",
    "                training_curve[e] = (avg_cost, time.time()-start)\n",
    "                if e%10==0:\n",
    "                    print(\"Epoch {}: {}\".format(e, avg_cost))\n",
    "\n",
    "    return w_1, w_2, w_3, training_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_deep(df_test, w_1, w_2, w_3):\n",
    "    reset_graph()\n",
    "    x = tf.placeholder(tf.float32, [None, 300])\n",
    "    y = tf.placeholder(tf.float32, [None, 10]) # 1-10 => 10 classes\n",
    "\n",
    "    w1 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w2 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w3 = tf.placeholder(tf.float32, [300, 10])\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([300]))\n",
    "    b2 = tf.Variable(tf.zeros([300]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    l2 = tf.nn.sigmoid(tf.matmul(x, w1) + b1)\n",
    "    l3 = tf.nn.sigmoid(tf.matmul(l2, w2) + b2)\n",
    "    pred = tf.nn.softmax(tf.matmul(l3, w3) + b3)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    with tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):\n",
    "        with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # Testing the model\n",
    "            LSMR_test = preprocess_data(df_test)\n",
    "            X_test, y_test = get_test(LSMR_test)\n",
    "            return accuracy.eval({x: X_test,\n",
    "                                  y: y_test,\n",
    "                                  w1:w_1,w2:w_2,\n",
    "                                  w3:w_3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 1\n",
    "scores_incremental = dict()\n",
    "learning_curves = dict()\n",
    "for i in range(NUM_TRIALS):\n",
    "    scores_incremental[i] = dict()\n",
    "    learning_curves[i] = dict()\n",
    "    print(\"Trial:\\t{}\".format(i+1))\n",
    "    k = 0\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=i)\n",
    "    for train_index, test_index in skf.split(df[\"Review\"], df[\"Language\"]):\n",
    "        start = time.time()\n",
    "        w1, w2, w3, learning_curve = train_deep(df.loc[train_index], random_state=i, epochs=10000)\n",
    "        s = test_deep(df.loc[test_index], w1, w2, w3)\n",
    "        k += 1\n",
    "        print(\"K:\\t{}\\nScore:\\t{}\".format(k, s))\n",
    "        print(\"took:\", time.time()-start)\n",
    "        scores_incremental[i][k] = s\n",
    "        learning_curves[i][k] = learning_curve\n",
    "    print(\"*\"*10)\n",
    "    try:\n",
    "        print(\"Trial {} avg score:\\t {}\".format(i+1, np.mean(list(scores_incremental[i].values()))))\n",
    "    except:\n",
    "        continue\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
