{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle, pandas as pd, re, numpy as np, ast, warnings\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import time\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import chain, starmap\n",
    "from itertools import product\n",
    "import unicodedata\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import gensim\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>i love science fiction and i hate superheroes ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>the movie is absolutely incredible all the per...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>in a cinematic era dominated by reboots and mi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>movie review on rise of the planet of the apes...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>during experiments to find a cure for alzheime...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language    Movie_ID                                             Review  \\\n",
       "0       en  -800777728  i love science fiction and i hate superheroes ...   \n",
       "1       en  -800777728  the movie is absolutely incredible all the per...   \n",
       "2       en -1018312192  in a cinematic era dominated by reboots and mi...   \n",
       "3       en -1018312192  movie review on rise of the planet of the apes...   \n",
       "4       en -1018312192  during experiments to find a cure for alzheime...   \n",
       "\n",
       "   Score  \n",
       "0      9  \n",
       "1     10  \n",
       "2      8  \n",
       "3      4  \n",
       "4      7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv(\"../datasets/movie_data.csv\")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Language  Movie_ID  Review\n",
       "Score                            \n",
       "1            29        29      29\n",
       "2            21        21      21\n",
       "3            14        14      14\n",
       "4            23        23      23\n",
       "5            83        83      83\n",
       "6            43        43      43\n",
       "7            71        71      71\n",
       "8           207       207     207\n",
       "9           175       175     175\n",
       "10          334       334     334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.groupby(\"Score\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vects = gensim.models.KeyedVectors.load_word2vec_format(r\"../../NLP_data/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_vects = gensim.models.KeyedVectors.load_word2vec_format(r\"../../NLP_data/wiki.tr/wiki.tr.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "turkish_stemmer = TurkishStemmer()\n",
    "def clean(text, language=\"en\", stem=True):\n",
    "    global turkish_stemmer\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').lower().decode(\"ascii\")\n",
    "    \n",
    "    if language == \"tr\":\n",
    "        if stem:\n",
    "            text= ' '.join([turkish_stemmer.stem(w) for w in text.split()])\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r'[0-9]', '#', text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" \", text)\n",
    "    text = re.sub(r\"\\=\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\":\", \" \", text)\n",
    "    text = re.sub(r\"e(\\s)?-(\\s)?mail\", \"email\", text)\n",
    "\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    return TextBlob(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_SIZE = 300\n",
    "def vectorize(text, language):\n",
    "    global VECTOR_SIZE            \n",
    "    blob = clean(text, language)\n",
    "    vector = np.zeros(VECTOR_SIZE)\n",
    "    if len(blob.words) < 1:\n",
    "        return None\n",
    "\n",
    "    for word in blob.words:\n",
    "        try:\n",
    "            if language == \"en\":\n",
    "                vector += globals()[\"en_vects\"][word]\n",
    "            else:\n",
    "                vector += globals()[\"tr_vects\"][word]\n",
    "        except KeyError as e:\n",
    "#             warnings.warn(str(e))\n",
    "            continue\n",
    "    vector /= max(len(blob.words),1)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvec(x):\n",
    "    lang, rev = x.split(\":::::\")\n",
    "    return vectorize(rev, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LMSR\n",
    "def preprocess_data(df, language_column=\"Language\", review_column=\"Review\"):\n",
    "    LMSR_df = df.copy()\n",
    "    LMSR_df[\"lang_rev\"] = LMSR_df[[language_column, review_column]].apply(lambda x: x[0]+\":::::\"+x[1], axis=1)\n",
    "    LMSR_df[\"rev_vec\"] = LMSR_df[\"lang_rev\"].apply(lambda x:getvec(x))\n",
    "    LMSR_df.drop([\"lang_rev\", \"Review\"], axis=1, inplace=True)\n",
    "    return LMSR_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_accuracy(y_true, y_predict):\n",
    "    res = 0\n",
    "    for i in range(len(y_true)):\n",
    "        res += abs(y_true[i]-y_predict[i])\n",
    "    return 1-res/(len(y_true)*len(set(y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XYy(LMSR):\n",
    "    X = np.zeros((len(LMSR), VECTOR_SIZE))\n",
    "    Y = np.zeros((len(LMSR), VECTOR_SIZE))\n",
    "    y = np.zeros((len(LMSR)))\n",
    "    i = 0\n",
    "    for rev in LMSR.iterrows():\n",
    "        score = rev[1][2]\n",
    "        rev_vec = rev[1][3]\n",
    "        score_vec = rev[1][4]\n",
    "\n",
    "        X[i] = rev_vec\n",
    "        Y[i] = score_vec\n",
    "        y[i] = score\n",
    "\n",
    "        i += 1\n",
    "    return X, Y, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derive=False):\n",
    "    if derive:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dict(df, get_L2and3=False):\n",
    "    data_dict = dict() #{language:{score: {movie_id: [rev1, rev2, ..., revn]}}}\n",
    "    L1 = dict()  # {(languge, score, movie_id): list of reviews with the same score with the same language}\n",
    "    L2 = dict()  # {(language, score): None}\n",
    "    L3 = dict()  # {score: None}\n",
    "    for _, row in df.iterrows():\n",
    "        lang = row[\"Language\"]\n",
    "        movie_id = row[\"Movie_ID\"]\n",
    "        score = row[\"Score\"]\n",
    "        review = row[\"rev_vec\"]\n",
    "\n",
    "        data_dict.setdefault(lang, {})\n",
    "        data_dict[lang].setdefault(score, {})\n",
    "        data_dict[lang][score].setdefault(movie_id, [])\n",
    "        data_dict[lang][score][movie_id].append(review)\n",
    "        \n",
    "        L1.setdefault((lang, score, movie_id), list())\n",
    "        L1[(lang, score, movie_id)].append(review)\n",
    "        if get_L2and3:    \n",
    "            L2[(lang, score)] = None\n",
    "            L3[score] = None\n",
    "    if get_L2and3:\n",
    "        return data_dict, L1, L2, L3\n",
    "    return data_dict, L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_L2(LSM_R, data_dict):\n",
    "    L2 = dict()  # {(language, score): list of movies vectors}\n",
    "    for language in data_dict:\n",
    "        for score in data_dict[language]:\n",
    "            for movie_id in data_dict[language][score]:\n",
    "                L2.setdefault((language, score), list())\n",
    "                L2[(language, score)].append(LSM_R[(language, score, movie_id)])\n",
    "    return L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_L3(LS_MR, data_dict):\n",
    "    L3 = dict()  # {score: vector of merged languages for that score}\n",
    "    for language in data_dict:\n",
    "        for score in data_dict[language]:\n",
    "            L3.setdefault(score, list())\n",
    "            L3[score].append(LS_MR[(language, score)])\n",
    "    return L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(L, W):\n",
    "    merged = dict()  # {item: vector of merged subitems}\n",
    "    for i, item in enumerate(sorted(L)):\n",
    "        for subitem in L[item]:\n",
    "            merged.setdefault(item, [np.zeros(VECTOR_SIZE),0])\n",
    "            merged[item][0] += sigmoid(subitem.dot(W[i]))\n",
    "            merged[item][1] += 1\n",
    "    for item in merged:\n",
    "        merged[item] = merged[item][0]/ merged[item][1]\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(L, delta, W, alpha=0.1):\n",
    "    for i, k in enumerate(sorted(L)):\n",
    "        for l in L[k]:\n",
    "            W[i] += l.T.dot(delta[i]) *alpha\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_error(delta, W):\n",
    "    error = 0\n",
    "    for i in range(len(delta)):\n",
    "        error += delta[i].dot(W[i].T)\n",
    "    return error/len(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_delta(error, layer, size):\n",
    "    delta = np.zeros((size, VECTOR_SIZE))\n",
    "    j = 0\n",
    "    for i,k in enumerate(sorted(layer)):\n",
    "        for l in layer[k]:\n",
    "            delta[j] = error[i]*sigmoid(l, True)\n",
    "            j += 1\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_vects(df, iterations=100, alpha=0.1, random_state=42, W1=None, W2=None, W3=None, W4=None):\n",
    "    LSMR = preprocess_data(df)\n",
    "    data_dict, L1 = get_data_dict(LSMR)\n",
    "    y = softmax(list(LSMR.Score))\n",
    "#     np.random.seed(random_state)\n",
    "    learning_curve = dict()\n",
    "    for i in range(iterations+1):\n",
    "        # forward propagation\n",
    "        if W1 is None:\n",
    "            W1 = 2*np.random.random((len(L1), 300, 300))-1\n",
    "\n",
    "        LSM_R = merge(L1, W1)\n",
    "        L2 = get_L2(LSM_R, data_dict)\n",
    "        if W2 is None:\n",
    "            W2 = 2*np.random.random((len(L2), 300, 300))-1\n",
    "\n",
    "        LS_MR = merge(L2, W2)\n",
    "        L3 = get_L3(LS_MR, data_dict)\n",
    "        if W3 is None:\n",
    "            W3 = 2*np.random.random((len(L3), 300, 300))-1\n",
    "\n",
    "        score_vectors_dict = merge(L3, W3)\n",
    "        l4 = sigmoid(np.array([v for k, v in sorted(score_vectors_dict.items())]))\n",
    "        if W4 is None:\n",
    "            W4 = 2*np.random.random((300, len(LSMR)))-1\n",
    "        \n",
    "        l5 = softmax(l4.dot(W4))  # predicted scores\n",
    "        \n",
    "        # Calculate the error\n",
    "        l5_error = np.mean(np.dot(np.log(l5), y))\n",
    "        \n",
    "        # Back propagation\n",
    "        l5_delta = l5_error * sigmoid(l5, True)\n",
    "        W4 += l4.T.dot(l5_delta)*alpha\n",
    "        \n",
    "        l4_error = l5_delta.dot(W4.T)\n",
    "        l4_delta = l4_error * sigmoid(l4, True)\n",
    "        \n",
    "        W3 = update_weights(L3, l4_delta, W3, alpha)\n",
    "        \n",
    "        l3_error = get_layer_error(l4_delta, W3)\n",
    "        l3_delta = get_layer_delta(l3_error, L3, len(L2))\n",
    "        \n",
    "        W2 = update_weights(L2, l3_delta, W2, alpha)\n",
    "        \n",
    "        l2_error = get_layer_error(l3_delta, W2)\n",
    "        l2_delta = get_layer_delta(l2_error, L2, len(LSMR))\n",
    "        \n",
    "        W1 = update_weights(L1, l2_delta, W1, alpha)\n",
    "        learning_curve[i] = l5_error\n",
    "        if i%10 == 0:\n",
    "            print(\"epoch {}:\\t{}\".format(i, np.abs(l5_error)))\n",
    "        if i%100 == 0:\n",
    "            alpha *= 0.9\n",
    "    return LSMR, score_vectors_dict, learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(LSMR, score_vect_dicts,random_state=42, regressor=MLPRegressor(), classifier=MLPClassifier()):\n",
    "    LSMR[\"score_vec\"] = LSMR[\"Score\"].apply(lambda x: score_vect_dicts[x] if x in score_vect_dicts else np.NaN)\n",
    "    LSMR.dropna(inplace=True)\n",
    "    \n",
    "    X, Y, y = get_XYy(LSMR)\n",
    "    \n",
    "    regressor.random_state = random_state\n",
    "    classifier.random_state = random_state\n",
    "        \n",
    "    regressor.fit(X, Y)\n",
    "    classifier.fit(Y, y)\n",
    "    return regressor, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(LSMR, score_vect_dicts, regressor, classifier):\n",
    "    LSMR[\"score_vec\"] = LSMR[\"Score\"].apply(lambda x: score_vect_dicts[x] if x in score_vect_dicts else np.NaN)\n",
    "    LSMR.dropna(inplace=True)\n",
    "    \n",
    "    X, Y, y = get_XYy(LSMR)\n",
    "    \n",
    "    preds_score_vecs = regressor.predict(X)\n",
    "    pred_scores = classifier.predict(preds_score_vecs)\n",
    "    \n",
    "    return pred_scores, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language    0\n",
       "Movie_ID    0\n",
       "Score       0\n",
       "rev_vec     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tronly_test_raw = df_full[-100:]\n",
    "tronly_test = preprocess_data(tronly_test_raw)\n",
    "df = df_full[:-100]\n",
    "tronly_test[tronly_test.Language==\"en\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models(model, train, test, tronly, ytrain, ytest, ytronly):\n",
    "    _ = time.time()\n",
    "    model.fit(train, ytrain)\n",
    "    predtra = time.time()-_\n",
    "    \n",
    "    _ = time.time()\n",
    "    predtrain = model.predict(train)\n",
    "    trat = time.time()-_\n",
    "    s_train = distance_accuracy(ytrain, predtrain)\n",
    "    f1_train = f1_score(ytrain, predtrain, average='weighted')\n",
    "    \n",
    "    _ = time.time()\n",
    "    predtest= model.predict(test)\n",
    "    tet = time.time()-_\n",
    "    s_test = distance_accuracy(ytest, predtest)\n",
    "    f1_test = f1_score(ytest, predtest, average='weighted')\n",
    "    \n",
    "    _ = time.time()\n",
    "    predtronly = model.predict(tronly)\n",
    "    trt = time.time()-_\n",
    "    s_tr = distance_accuracy(ytronly, predtronly)\n",
    "    f1_tronly = f1_score(ytronly, predtronly, average='weighted')\n",
    "    \n",
    "    evals = OrderedDict()\n",
    "    evals[\"Train\"] = s_train\n",
    "    evals[\"Test\"] = s_test\n",
    "    evals[\"Tr. Only\"] = s_tr\n",
    "    evals[\"Training Time\"] = trat\n",
    "    evals[\"Pred.Tra. Time\"] = predtra\n",
    "    evals[\"Testing Time\"] = tet\n",
    "    evals[\"Tr.Test Time\"] = trt\n",
    "    evals[\"F1 Test\"] = f1_test\n",
    "    evals[\"F1 Train\"] = f1_train\n",
    "    evals[\"F1 Tr. only\"] = f1_tronly\n",
    "    return evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_average(scores_tables):\n",
    "#     scores_tables: {i_th trial:\n",
    "#                     {k_th fold:\n",
    "#                         {'Model': {'Test': 0.8090301003344482,\n",
    "#                                    'Train': 0.783361064891847,\n",
    "#                                    'Turkish only': 0.7414285714285714}}}\n",
    "    avgs = dict()\n",
    "    for trial in scores_tables:\n",
    "        for table in scores_tables[trial]:\n",
    "            for model in scores_tables[trial][table]:\n",
    "                avgs.setdefault(model, dict())\n",
    "                for metric, score in scores_tables[trial][table][model].items():\n",
    "                    avgs[model].setdefault(metric, list())\n",
    "                    avgs[model][metric].append(score)\n",
    "    for model in avgs:\n",
    "        for metric in avgs[model]:\n",
    "            avgs[model][metric] = np.mean(avgs[model][metric])\n",
    "    return pd.DataFrame(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_score(trial_scores_tables):\n",
    "#  trial_scores_tables: {k_th fold:\n",
    "#                             {'Model': {'Test': 0.8090301003344482,\n",
    "#                                        'Train': 0.783361064891847,\n",
    "#                                        'Turkish only': 0.7414285714285714}}}\n",
    "    avgs = dict()\n",
    "    for table in trial_scores_tables:\n",
    "        for model in trial_scores_tables[table]:\n",
    "            avgs.setdefault(model, dict())\n",
    "            for metric, score in trial_scores_tables[table][model].items():\n",
    "                avgs[model].setdefault(metric, list())\n",
    "                avgs[model][metric].append(score)\n",
    "    for model in avgs:\n",
    "        for metric in avgs[model]:\n",
    "            avgs[model][metric] = np.mean(avgs[model][metric])\n",
    "    return pd.DataFrame(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_selectivewaves_regclass(df, tronly_test_raw, NUM_TRIALS=1, splits=10):  \n",
    "    learning_curves = dict()\n",
    "    scores_tables = OrderedDict()\n",
    "    tronly_test = preprocess_data(tronly_test_raw)\n",
    "    for i in range(NUM_TRIALS):\n",
    "        print(\"Trial:\\t{}\".format(i+1))\n",
    "        scores_tables[i] = OrderedDict()\n",
    "        learning_curves[i] = OrderedDict()\n",
    "        k = 0\n",
    "        skf = StratifiedKFold(n_splits=splits, random_state=i)\n",
    "        for train_index, test_index in skf.split(df[\"Review\"], df[\"Language\"]):\n",
    "            print(\"K:\\t{}\".format(k+1))\n",
    "            scores_tables[i][k] = OrderedDict()\n",
    "            start = time.time()\n",
    "            LSMR, score_vect_dicts, training_curve = get_score_vects(\n",
    "                df.loc[train_index], random_state=i, alpha=1e-5, iterations=50)\n",
    "            regressor, classifier = fit(LSMR, score_vect_dicts, random_state=i)\n",
    "            trat = time.time()- start\n",
    "\n",
    "            test_data = preprocess_data(df.loc[test_index])\n",
    "            _ = time.time()\n",
    "            preds, true = predict(test_data, score_vect_dicts, regressor, classifier)\n",
    "            tet = time.time()-_\n",
    "\n",
    "            _ = time.time()\n",
    "            preds_train, true_train = predict(preprocess_data(df.loc[train_index]),\n",
    "                                              score_vect_dicts,\n",
    "                                              regressor, classifier)\n",
    "            predtra = time.time()-_\n",
    "\n",
    "            _ = time.time()\n",
    "            preds_tr, true_tr = predict(tronly_test, score_vect_dicts, regressor, classifier)\n",
    "            trt = time.time()-_\n",
    "\n",
    "            elapsed = time.time()-start\n",
    "\n",
    "            s = distance_accuracy(true, preds)\n",
    "            f1_test = f1_score(true, preds, average='weighted')\n",
    "\n",
    "            s_train = distance_accuracy(true_train, preds_train)\n",
    "            f1_train = f1_score(true_train, preds_train, average='weighted')\n",
    "\n",
    "            s_tr = distance_accuracy(true_tr, preds_tr)\n",
    "            f1_tronly = f1_test = f1_score(true_tr, preds_tr, average='weighted')        \n",
    "\n",
    "\n",
    "            lr = LogisticRegression(random_state=i)\n",
    "            mlp = MLPClassifier(random_state=i)\n",
    "            rf = RandomForestClassifier(random_state=i,n_jobs=-1)\n",
    "            train_mat = np.array(list(LSMR[\"rev_vec\"]))\n",
    "            test_mat = np.array(list(test_data[\"rev_vec\"]))\n",
    "            tronly_mat = np.array(list(tronly_test[\"rev_vec\"]))\n",
    "\n",
    "            evals = OrderedDict()\n",
    "            evals[\"Train\"] = s_train\n",
    "            evals[\"Test\"] = s\n",
    "            evals[\"Tr. Only\"] = s_tr\n",
    "            evals[\"Training Time\"] = trat\n",
    "            evals[\"Pred.Tra. Time\"] = predtra\n",
    "            evals[\"Testing Time\"] = tet\n",
    "            evals[\"Tr.Test Time\"] = trt\n",
    "            evals[\"F1 Test\"] = f1_test\n",
    "            evals[\"F1 Train\"] = f1_train\n",
    "            evals[\"F1 Tr. only\"] = f1_tronly\n",
    "            scores_tables[i][k][\"DeepSelect\"] = evals\n",
    "            scores_tables[i][k][\"MLP\"] = eval_models(\n",
    "                mlp, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "            scores_tables[i][k][\"Logistic Regression\"] = eval_models(\n",
    "                lr, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "            scores_tables[i][k][\"RandomForest\"] = eval_models(\n",
    "                rf, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "\n",
    "            print()\n",
    "            print(\"K:\\t{}\".format(k+1))\n",
    "            print(pd.DataFrame(scores_tables[i][k]))\n",
    "            print(\"\\nThis fold took:\", elapsed, \"seconds\\n\")\n",
    "            learning_curves[i][k] = training_curve\n",
    "            k += 1\n",
    "            print(\"*\"*10+\"\\n\")\n",
    "        print(\"Average scores for trial {}\".format(i))\n",
    "        print(get_trial_score(scores_tables[i]))\n",
    "        print(\"-\"*30)\n",
    "    print(\"%%\"*20)\n",
    "    print(\"Average of {} trials\".format(NUM_TRIALS))\n",
    "    print(get_total_average(scores_tables))\n",
    "    return scores_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial:\t1\n",
      "K:\t1\n",
      "epoch 0:\t24.76686600092429\n",
      "epoch 10:\t24.450570421325914\n",
      "epoch 20:\t24.044721181809056\n",
      "epoch 30:\t23.659809859445378\n",
      "epoch 40:\t23.372617877461806\n",
      "epoch 50:\t23.145493307660868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t1\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.202264  0.205265             0.196250      0.242046\n",
      "F1 Tr. only       0.202264  0.240859             0.303204      0.287112\n",
      "F1 Train          0.236986  0.331770             0.336056      0.995061\n",
      "Pred.Tra. Time    1.799902  0.455240             0.177022      0.108307\n",
      "Test              0.803704  0.811111             0.802469      0.798765\n",
      "Testing Time      0.009492  0.000347             0.000145      0.105107\n",
      "Tr. Only          0.804286  0.798571             0.781429      0.714286\n",
      "Tr.Test Time      0.013290  0.000324             0.000156      0.106326\n",
      "Train             0.812840  0.823333             0.823086      0.999259\n",
      "Training Time    15.069148  0.004432             0.000827      0.105972\n",
      "\n",
      "This fold took: 17.099502563476562 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t2\n",
      "epoch 0:\t24.92346767130208\n",
      "epoch 10:\t24.564709301632753\n",
      "epoch 20:\t24.2073859671301\n",
      "epoch 30:\t23.935115071168564\n",
      "epoch 40:\t23.6987205718208\n",
      "epoch 50:\t23.486057918315307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t2\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.181481  0.208627             0.217063      0.270889\n",
      "F1 Tr. only       0.181481  0.321167             0.297630      0.267191\n",
      "F1 Train          0.066203  0.334973             0.329319      0.992585\n",
      "Pred.Tra. Time    1.777080  0.431015             0.162320      0.108316\n",
      "Test              0.791111  0.772222             0.773333      0.793333\n",
      "Testing Time      0.009697  0.000659             0.000160      0.105429\n",
      "Tr. Only          0.801429  0.817143             0.782857      0.748571\n",
      "Tr.Test Time      0.013545  0.000781             0.000156      0.105695\n",
      "Train             0.825802  0.829877             0.829506      0.998889\n",
      "Training Time    14.483696  0.001688             0.000736      0.106070\n",
      "\n",
      "This fold took: 16.476651191711426 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t3\n",
      "epoch 0:\t24.38693266071134\n",
      "epoch 10:\t24.36671859100121\n",
      "epoch 20:\t24.141229575106586\n",
      "epoch 30:\t23.950204384628034\n",
      "epoch 40:\t23.76446889932159\n",
      "epoch 50:\t23.54198691144533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t3\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.180303  0.199350             0.178009      0.211884\n",
      "F1 Tr. only       0.180303  0.298937             0.302416      0.282611\n",
      "F1 Train          0.239626  0.318162             0.325155      0.993821\n",
      "Pred.Tra. Time    1.703255  0.476871             0.174251      0.108089\n",
      "Test              0.783951  0.771605             0.756790      0.770370\n",
      "Testing Time      0.008917  0.000309             0.000123      0.103327\n",
      "Tr. Only          0.798571  0.797143             0.780000      0.754286\n",
      "Tr.Test Time      0.014533  0.000587             0.000115      0.103675\n",
      "Train             0.816420  0.826420             0.827531      0.998395\n",
      "Training Time    15.074522  0.002025             0.000899      0.103266\n",
      "\n",
      "This fold took: 17.02352285385132 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t4\n",
      "epoch 0:\t22.97082298668301\n",
      "epoch 10:\t22.82736282802089\n",
      "epoch 20:\t22.696021554263883\n",
      "epoch 30:\t22.547027378871025\n",
      "epoch 40:\t22.4013970031759\n",
      "epoch 50:\t22.240539348597185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t4\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.171136  0.254857             0.255074      0.293663\n",
      "F1 Tr. only       0.171136  0.323662             0.341750      0.307138\n",
      "F1 Train          0.178423  0.299336             0.310901      0.996292\n",
      "Pred.Tra. Time    1.826833  0.604097             0.166308      0.109244\n",
      "Test              0.813333  0.807778             0.805556      0.785556\n",
      "Testing Time      0.008838  0.000611             0.000100      0.104795\n",
      "Tr. Only          0.730000  0.787143             0.801429      0.790000\n",
      "Tr.Test Time      0.014428  0.000319             0.000102      0.104845\n",
      "Train             0.792222  0.821111             0.823457      0.999259\n",
      "Training Time    13.542790  0.001891             0.000707      0.103283\n",
      "\n",
      "This fold took: 15.608597040176392 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t5\n",
      "epoch 0:\t21.27403529190793\n",
      "epoch 10:\t21.150054938585143\n",
      "epoch 20:\t20.966579648248388\n",
      "epoch 30:\t20.77070906470299\n",
      "epoch 40:\t20.615861525301906\n",
      "epoch 50:\t20.444709706088176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t5\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.202264  0.289502             0.241477      0.261729\n",
      "F1 Tr. only       0.202264  0.313378             0.287556      0.279572\n",
      "F1 Train          0.222821  0.288964             0.306291      0.996295\n",
      "Pred.Tra. Time    1.790706  0.687872             0.167190      0.108454\n",
      "Test              0.813580  0.809877             0.792593      0.746914\n",
      "Testing Time      0.008772  0.000309             0.000109      0.101528\n",
      "Tr. Only          0.804286  0.804286             0.775714      0.742857\n",
      "Tr.Test Time      0.014600  0.000322             0.000135      0.101608\n",
      "Train             0.812099  0.823827             0.820617      0.999259\n",
      "Training Time    15.534183  0.001626             0.000750      0.102017\n",
      "\n",
      "This fold took: 17.551403522491455 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t6\n",
      "epoch 0:\t23.328142026006237\n",
      "epoch 10:\t22.943384216296288\n",
      "epoch 20:\t22.669671286466247\n",
      "epoch 30:\t22.547168520151004\n",
      "epoch 40:\t22.340511062595017\n",
      "epoch 50:\t22.13583784828388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t6\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.202264  0.228530             0.243285      0.258241\n",
      "F1 Tr. only       0.202264  0.370055             0.292236      0.308313\n",
      "F1 Train          0.228288  0.321539             0.334170      0.991355\n",
      "Pred.Tra. Time    1.811466  0.558301             0.192604      0.108248\n",
      "Test              0.801111  0.790000             0.793333      0.805556\n",
      "Testing Time      0.010818  0.014003             0.000101      0.105598\n",
      "Tr. Only          0.804286  0.810000             0.767143      0.747143\n",
      "Tr.Test Time      0.013106  0.000635             0.000111      0.105049\n",
      "Train             0.814938  0.829630             0.827901      0.998025\n",
      "Training Time    16.667842  0.021832             0.000720      0.103447\n",
      "\n",
      "This fold took: 18.714858531951904 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t7\n",
      "epoch 0:\t22.822449440498122\n",
      "epoch 10:\t22.487452789556254\n",
      "epoch 20:\t22.203279160148504\n",
      "epoch 30:\t21.99624966967625\n",
      "epoch 40:\t21.829642595852597\n",
      "epoch 50:\t21.738356185460745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t7\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.197836  0.261481             0.224081      0.265556\n",
      "F1 Tr. only       0.197836  0.383894             0.332195      0.335966\n",
      "F1 Train          0.228624  0.350501             0.325914      0.991345\n",
      "Pred.Tra. Time    1.867791  1.079048             0.158678      0.107991\n",
      "Test              0.800000  0.787778             0.783333      0.777778\n",
      "Testing Time      0.009044  0.000311             0.000105      0.105295\n",
      "Tr. Only          0.801429  0.814286             0.788571      0.771429\n",
      "Tr.Test Time      0.013583  0.000318             0.000100      0.104778\n",
      "Train             0.815926  0.834198             0.827160      0.998148\n",
      "Training Time    14.991585  0.001625             0.000746      0.103639\n",
      "\n",
      "This fold took: 17.10541844367981 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t8\n",
      "epoch 0:\t23.57382025575771\n",
      "epoch 10:\t23.405012021192853\n",
      "epoch 20:\t23.026254836512017\n",
      "epoch 30:\t22.713405503505832\n",
      "epoch 40:\t22.441812420193592\n",
      "epoch 50:\t22.279979468534044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t8\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.281460  0.219282             0.240992      0.236479\n",
      "F1 Tr. only       0.281460  0.321095             0.348020      0.231954\n",
      "F1 Train          0.205937  0.282132             0.313870      0.993809\n",
      "Pred.Tra. Time    1.858663  0.651061             0.187132      0.107837\n",
      "Test              0.841667  0.816667             0.825000      0.775000\n",
      "Testing Time      0.009346  0.000345             0.000113      0.104412\n",
      "Tr. Only          0.750000  0.821429             0.800000      0.688571\n",
      "Tr.Test Time      0.010101  0.000335             0.000146      0.105883\n",
      "Train             0.792716  0.819383             0.821235      0.998025\n",
      "Training Time    17.200065  0.001734             0.000848      0.102837\n",
      "\n",
      "This fold took: 19.294219493865967 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t9\n",
      "epoch 0:\t19.9516426349678\n",
      "epoch 10:\t19.848213856978084\n",
      "epoch 20:\t19.74263647426656\n",
      "epoch 30:\t19.618040343969476\n",
      "epoch 40:\t19.512793585691988\n",
      "epoch 50:\t19.41919679289311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t9\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.206488  0.185791             0.133072      0.230364\n",
      "F1 Tr. only       0.206488  0.341620             0.308476      0.303576\n",
      "F1 Train          0.275839  0.438538             0.336940      0.995064\n",
      "Pred.Tra. Time    1.765091  1.229238             0.167646      0.108062\n",
      "Test              0.776667  0.768889             0.757778      0.754444\n",
      "Testing Time      0.009656  0.000679             0.000111      0.104964\n",
      "Tr. Only          0.797143  0.800000             0.781429      0.737143\n",
      "Tr.Test Time      0.014234  0.000328             0.000101      0.104991\n",
      "Train             0.819259  0.845679             0.828148      0.998642\n",
      "Training Time    14.691512  0.001661             0.000756      0.103207\n",
      "\n",
      "This fold took: 16.728501319885254 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t10\n",
      "epoch 0:\t24.667802115791478\n",
      "epoch 10:\t24.143970182603308\n",
      "epoch 20:\t23.83940182489085\n",
      "epoch 30:\t23.550858148647933\n",
      "epoch 40:\t23.32982883919447\n",
      "epoch 50:\t23.124156661682825\n",
      "\n",
      "K:\t10\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.202264  0.338667             0.306383      0.287274\n",
      "F1 Tr. only       0.202264  0.286406             0.266340      0.296579\n",
      "F1 Train          0.221775  0.438964             0.303478      0.995059\n",
      "Pred.Tra. Time    1.820277  1.275109             0.160689      0.108840\n",
      "Test              0.819444  0.793056             0.806944      0.773611\n",
      "Testing Time      0.009311  0.000600             0.000132      0.105698\n",
      "Tr. Only          0.804286  0.735714             0.771429      0.760000\n",
      "Tr.Test Time      0.014679  0.000322             0.000144      0.105209\n",
      "Train             0.810000  0.837284             0.816173      0.998889\n",
      "Training Time    14.899025  0.001693             0.000764      0.106309\n",
      "\n",
      "This fold took: 16.956726789474487 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "Average scores for trial 0\n",
      "                DeepSelect  Logistic Regression       MLP  RandomForest\n",
      "F1 Test           0.202776             0.223569  0.239135      0.255812\n",
      "F1 Tr. only       0.202776             0.307982  0.320107      0.290001\n",
      "F1 Train          0.210452             0.322209  0.340488      0.994069\n",
      "Pred.Tra. Time    1.802106             0.171384  0.744785      0.108339\n",
      "Test              0.804457             0.789713  0.792898      0.778133\n",
      "Testing Time      0.009389             0.000120  0.001817      0.104615\n",
      "Tr. Only          0.789571             0.783000  0.798571      0.745429\n",
      "Tr.Test Time      0.013610             0.000126  0.000427      0.104806\n",
      "Train             0.811222             0.824481  0.829074      0.998679\n",
      "Training Time    15.215437             0.000775  0.004021      0.104005\n",
      "------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Average of 1 trials\n",
      "                DeepSelect  Logistic Regression       MLP  RandomForest\n",
      "F1 Test           0.202776             0.223569  0.239135      0.255812\n",
      "F1 Tr. only       0.202776             0.307982  0.320107      0.290001\n",
      "F1 Train          0.210452             0.322209  0.340488      0.994069\n",
      "Pred.Tra. Time    1.802106             0.171384  0.744785      0.108339\n",
      "Test              0.804457             0.789713  0.792898      0.778133\n",
      "Testing Time      0.009389             0.000120  0.001817      0.104615\n",
      "Tr. Only          0.789571             0.783000  0.798571      0.745429\n",
      "Tr.Test Time      0.013610             0.000126  0.000427      0.104806\n",
      "Train             0.811222             0.824481  0.829074      0.998679\n",
      "Training Time    15.215437             0.000775  0.004021      0.104005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores_tables = eval_selectivewaves_regclass(df, tronly_test_raw)\n",
    "pickle.dump(scores_tables, open(\"../results/batch_no_tf_tables.results\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the full network for prediction\n",
    "### P.S. this variation supports online (incremental) training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(LSMR):\n",
    "    X = dict()\n",
    "    y = dict()\n",
    "    for _, row in LSMR.iterrows():\n",
    "        score = row[\"Score\"]\n",
    "        y_ = np.zeros(10)\n",
    "        y_[score-1] = 1\n",
    "        y[len(y)] = y_\n",
    "        X[len(X)] = row[\"rev_vec\"]\n",
    "    return np.array(list(X.values())), np.array(list(y.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_selective(df_train,epochs=100, learning_rate = 0.1, random_state=42, p_every=10):\n",
    "    LSMR_train = preprocess_data(df_train)\n",
    "    np.random.seed(random_state)\n",
    "    data_dict, L1, L2, L3 = get_data_dict(LSMR_train, get_L2and3=True)\n",
    "    init_weights = lambda layer, i, o: {k:2*np.random.random((i, o))-1 for k in layer}\n",
    "    W1 = init_weights(L1, 300, 300)  # (languge, score, movie_id)\n",
    "    W2 = init_weights(L2, 300, 300)  # (languge, score):\n",
    "    W3 = init_weights(L3, 300, 10)  # score:\n",
    "    \n",
    "    \n",
    "    reset_graph()\n",
    "    x = tf.placeholder(tf.float32, [None, 300])\n",
    "    y = tf.placeholder(tf.float32, [None, 10]) # 1-10 => 10 classes\n",
    "\n",
    "    w1 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w2 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w3 = tf.placeholder(tf.float32, [300, 10])\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([300]))\n",
    "    b2 = tf.Variable(tf.zeros([300]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    l2 = tf.nn.sigmoid(tf.matmul(x, w1) + b1)\n",
    "    l3 = tf.nn.sigmoid(tf.matmul(l2, w2) + b2)\n",
    "    pred = tf.nn.softmax(tf.matmul(l3, w3) + b3)\n",
    "\n",
    "\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    training_curve = dict()\n",
    "    with tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):\n",
    "        with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for e in range(epochs+1):\n",
    "                avg_cost = 0.\n",
    "                for _, row in LSMR_train.iterrows():\n",
    "                    lang = row[\"Language\"]\n",
    "                    movie_id = row[\"Movie_ID\"]\n",
    "                    score = row[\"Score\"]\n",
    "                    y_ = np.zeros(10)\n",
    "                    y_[score-1] = 1\n",
    "                    y_ = np.atleast_2d(y_)\n",
    "                    x_ = np.atleast_2d(row[\"rev_vec\"])\n",
    "                    w1_,w2_,w3_,_, c = sess.run([w1, w2, w3, optimizer, cost],\n",
    "                                             feed_dict={x: x_,\n",
    "                                                        y: y_,\n",
    "                                                        w1:W1[(lang, score, movie_id)],\n",
    "                                                        w2:W2[(lang, score)],\n",
    "                                                        w3:W3[score]})\n",
    "                    W1[(lang, score, movie_id)] = w1_\n",
    "                    W2[(lang, score)] = w2_\n",
    "                    W3[score] = w3_\n",
    "\n",
    "                    avg_cost += c\n",
    "                training_curve[e] = avg_cost\n",
    "                if e%p_every==0:\n",
    "                    print(\"Epoch {}: {}\".format(e, avg_cost/len(LSMR_train)))\n",
    "\n",
    "            return W1, W2, W3, training_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_index(array):\n",
    "    indx = None\n",
    "    max_ = float(\"-inf\")\n",
    "    for i, e in enumerate(array):\n",
    "        if e > max_:\n",
    "            max_ = e\n",
    "            indx = i\n",
    "    return indx, max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_selective(df, W1, W2, W3):\n",
    "    LSMR = preprocess_data(df)\n",
    "    reset_graph()\n",
    "    x = tf.placeholder(tf.float32, [None, 300])\n",
    "\n",
    "    w1 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w2 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w3 = tf.placeholder(tf.float32, [300, 10])\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([300]))\n",
    "    b2 = tf.Variable(tf.zeros([300]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    l2 = tf.nn.sigmoid(tf.matmul(x, w1) + b1)\n",
    "    l3 = tf.nn.sigmoid(tf.matmul(l2, w2) + b2)\n",
    "    pred = tf.nn.softmax(tf.matmul(l3, w3) + b3)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    prediction = tf.argmax(pred, 1)\n",
    "    preds = np.zeros(len(LSMR))\n",
    "    with tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):\n",
    "        with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            j = 0\n",
    "            for _, row in LSMR.iterrows():\n",
    "                v = row[\"rev_vec\"]\n",
    "                predicted_scores = np.zeros(len(W1))\n",
    "                for i, info in enumerate(W1):\n",
    "                    language, score, movie_id = info\n",
    "                    w_1 = W1[(language, score, movie_id)]\n",
    "                    w_2 = W2[(language, score)]\n",
    "                    w_3 = W3[score]\n",
    "\n",
    "                    predicted_scores[i] = prediction.eval({x: np.atleast_2d(v),\n",
    "                                                           w1:w_1,w2:w_2,w3:w_3})\n",
    "\n",
    "                max_index, probability = get_max_index(softmax(predicted_scores))\n",
    "                predicted_score = predicted_scores[max_index]\n",
    "\n",
    "                preds[j] = predicted_score\n",
    "                j+=1\n",
    "\n",
    "\n",
    "    return preds, np.array(list(LSMR.Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_selectivewaves_nn(df, tronly_test_raw, NUM_TRIALS=1, splits=10):  \n",
    "    learning_curves = OrderedDict()\n",
    "    scores_tables_nn = OrderedDict()\n",
    "    tronly_test = preprocess_data(tronly_test_raw)\n",
    "    for i in range(NUM_TRIALS):\n",
    "        print(\"Trial:\\t{}\".format(i+1))\n",
    "        learning_curves[i] = OrderedDict()\n",
    "        k = 0\n",
    "        skf = StratifiedKFold(n_splits=splits, random_state=i)\n",
    "        scores_tables_nn[i] = dict()\n",
    "        for train_index, test_index in skf.split(df[\"Review\"], df[\"Language\"]):\n",
    "            print(\"K: \\t{}\".format(k+1))\n",
    "            scores_tables_nn[i][k] = OrderedDict()\n",
    "            start = time.time()\n",
    "            # approx 3 epochs per second\n",
    "            LSMR = preprocess_data(df.loc[train_index])\n",
    "            W1, W2, W3, training_curve = train_selective(df.loc[train_index], epochs=150, p_every=25)\n",
    "            _ = time.time()\n",
    "            trat = _-start\n",
    "            print(\"Took: {} for training\".format(trat))\n",
    "\n",
    "            _ = time.time()\n",
    "            preds_train, true_train = predict_selective(df.loc[train_index], W1, W2, W3)\n",
    "            predtra = time.time()-_\n",
    "            print(\"Took: {} for predicting {} training instances\".format(predtra, len(train_index)))\n",
    "\n",
    "            test_data = preprocess_data(df.loc[test_index])\n",
    "            _ = time.time()\n",
    "            preds, true = predict_selective(df.loc[test_index], W1, W2, W3)\n",
    "            tet = time.time()-_\n",
    "            print(\"Took: {} for predicting {} test instances\".format(tet, len(test_index)))\n",
    "\n",
    "            _ = time.time()\n",
    "            preds_tr, true_tr = predict_selective(tronly_test_raw, W1, W2, W3)\n",
    "            trt = time.time()-_\n",
    "            print(\"Took: {} for predicting {} Turkish test instances\".format(trt, len(tronly_test)))\n",
    "\n",
    "            elapsed = time.time()-start\n",
    "\n",
    "            s = distance_accuracy(true, preds)\n",
    "            s_train = distance_accuracy(true_train, preds_train)\n",
    "            s_tr = distance_accuracy(true_tr, preds_tr)\n",
    "\n",
    "            f1_test = f1_score(true, preds, average='weighted')\n",
    "            f1_train = f1_score(true_train, preds_train, average='weighted')\n",
    "            f1_tronly = f1_score(true_tr, preds_tr, average='weighted')\n",
    "\n",
    "            mlp = MLPClassifier(random_state=i)\n",
    "            lr = LogisticRegression(random_state=i)\n",
    "            rf = RandomForestClassifier(random_state=i,n_jobs=-1)\n",
    "            train_mat = np.array(list(LSMR[\"rev_vec\"]))\n",
    "            test_mat = np.array(list(test_data[\"rev_vec\"]))\n",
    "            tronly_mat = np.array(list(tronly_test[\"rev_vec\"]))\n",
    "\n",
    "            evals = OrderedDict()\n",
    "            evals[\"Train\"] = s_train\n",
    "            evals[\"Test\"] = s\n",
    "            evals[\"Tr. Only\"] = s_tr\n",
    "            evals[\"Training Time\"] = trat\n",
    "            evals[\"Pred.Tra. Time\"] = predtra\n",
    "            evals[\"Testing Time\"] = tet\n",
    "            evals[\"Tr.Test Time\"] = trt\n",
    "            evals[\"F1 Test\"] = f1_test\n",
    "            evals[\"F1 Train\"] = f1_train\n",
    "            evals[\"F1 Tr. only\"] = f1_tronly\n",
    "            scores_tables_nn[i][k][\"DeepSelect\"] = evals\n",
    "\n",
    "            scores_tables_nn[i][k][\"LogisticRegression\"] = eval_models(lr, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "            scores_tables_nn[i][k][\"MLP\"] = eval_models(mlp, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "            scores_tables_nn[i][k][\"RandomForest\"] = eval_models(rf, train_mat, test_mat, tronly_mat, true_train, true, true_tr)\n",
    "\n",
    "            print()\n",
    "            print(pd.DataFrame(scores_tables_nn[i][k]))\n",
    "            print(\"took:\", elapsed, \"seconds\\n\")\n",
    "            learning_curves[i][k] = training_curve\n",
    "            k += 1\n",
    "            print(\"*\"*10+\"\\n\")\n",
    "        print(\"Average scores for trial {}\".format(i))\n",
    "        print(get_trial_score(scores_tables_nn[i]))\n",
    "        print(\"-\"*30)\n",
    "    print(\"%%\"*20)\n",
    "    print(\"Average of {} trials\".format(NUM_TRIALS))\n",
    "    print(get_total_average(scores_tables_nn))\n",
    "    return scores_tables_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial:\t1\n",
      "K: \t1\n",
      "Epoch 0: 1.9773333567116693\n",
      "Epoch 25: 0.003818575064216644\n",
      "Epoch 50: 0.0019198051157985323\n",
      "Epoch 75: 0.0012996401052061156\n",
      "Epoch 100: 0.000988080382333894\n",
      "Epoch 125: 0.0007996864090740125\n",
      "Epoch 150: 0.0006731128424478581\n",
      "Took: 183.70366883277893 for training\n",
      "Took: 615.1565337181091 for predicting 810 training instances\n",
      "Took: 65.2965362071991 for predicting 90 test instances\n",
      "Took: 73.59039640426636 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.120773            0.196250  0.205265      0.242046\n",
      "F1 Tr. only       0.021802            0.303204  0.240859      0.287112\n",
      "F1 Train          0.050270            0.336056  0.331770      0.995061\n",
      "Pred.Tra. Time  615.156534            0.175007  0.563957      0.111384\n",
      "Test              0.833333            0.802469  0.811111      0.798765\n",
      "Testing Time     65.296536            0.000103  0.000311      0.105492\n",
      "Tr. Only          0.787143            0.781429  0.798571      0.714286\n",
      "Tr.Test Time     73.590396            0.000098  0.000322      0.105752\n",
      "Train             0.822469            0.823086  0.823333      0.999259\n",
      "Training Time   183.703669            0.000723  0.001884      0.102581\n",
      "took: 937.9249000549316 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t2\n",
      "Epoch 0: 2.3775782500775855\n",
      "Epoch 25: 0.004348101737080323\n",
      "Epoch 50: 0.0020806660097174457\n",
      "Epoch 75: 0.0013976375215784987\n",
      "Epoch 100: 0.0010624149531730678\n",
      "Epoch 125: 0.0008616164289622017\n",
      "Epoch 150: 0.0007272326177424357\n",
      "Took: 180.36139559745789 for training\n",
      "Took: 513.9241342544556 for predicting 810 training instances\n",
      "Took: 59.309340715408325 for predicting 90 test instances\n",
      "Took: 63.074501514434814 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.050294            0.217063  0.208627      0.270889\n",
      "F1 Tr. only       0.150864            0.297630  0.321167      0.267191\n",
      "F1 Train          0.087336            0.329319  0.334973      0.992585\n",
      "Pred.Tra. Time  513.924134            0.169826  0.434763      0.127065\n",
      "Test              0.783333            0.773333  0.772222      0.793333\n",
      "Testing Time     59.309341            0.000108  0.000311      0.104064\n",
      "Tr. Only          0.795714            0.782857  0.817143      0.748571\n",
      "Tr.Test Time     63.074502            0.000108  0.000331      0.105528\n",
      "Train             0.823457            0.829506  0.829877      0.998889\n",
      "Training Time   180.361396            0.000723  0.001676      0.102903\n",
      "took: 816.843035697937 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t3\n",
      "Epoch 0: 2.1105157300578643\n",
      "Epoch 25: 0.004087267299817969\n",
      "Epoch 50: 0.0019113149940726908\n",
      "Epoch 75: 0.0012732374629505147\n",
      "Epoch 100: 0.0009633172474697583\n",
      "Epoch 125: 0.000778884561837312\n",
      "Epoch 150: 0.0006560410923149108\n",
      "Took: 192.57593369483948 for training\n",
      "Took: 520.1284375190735 for predicting 810 training instances\n",
      "Took: 55.579052448272705 for predicting 90 test instances\n",
      "Took: 62.73327016830444 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.066667            0.178009  0.199350      0.211884\n",
      "F1 Tr. only       0.021802            0.302416  0.298937      0.282611\n",
      "F1 Train          0.055054            0.325155  0.318162      0.993821\n",
      "Pred.Tra. Time  520.128438            0.176462  0.427962      0.129727\n",
      "Test              0.796296            0.756790  0.771605      0.770370\n",
      "Testing Time     55.579052            0.000159  0.000334      0.105165\n",
      "Tr. Only          0.787143            0.780000  0.797143      0.754286\n",
      "Tr.Test Time     62.733270            0.000147  0.000330      0.104523\n",
      "Train             0.826173            0.827531  0.826420      0.998395\n",
      "Training Time   192.575934            0.000753  0.001710      0.106050\n",
      "took: 831.2531008720398 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t4\n",
      "Epoch 0: 2.47723830999529\n",
      "Epoch 25: 0.006543009063156722\n",
      "Epoch 50: 0.002836956465667322\n",
      "Epoch 75: 0.001875388481338503\n",
      "Epoch 100: 0.0014193576503870459\n",
      "Epoch 125: 0.0011497064898872587\n",
      "Epoch 150: 0.0009702312833957124\n",
      "Took: 214.42865920066833 for training\n",
      "Took: 533.9337005615234 for predicting 810 training instances\n",
      "Took: 56.72276759147644 for predicting 90 test instances\n",
      "Took: 62.730045318603516 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.041880            0.255074  0.254857      0.293663\n",
      "F1 Tr. only       0.021802            0.341750  0.323662      0.307138\n",
      "F1 Train          0.057870            0.310901  0.299336      0.996292\n",
      "Pred.Tra. Time  533.933701            0.148086  0.375179      0.110834\n",
      "Test              0.824444            0.805556  0.807778      0.785556\n",
      "Testing Time     56.722768            0.000132  0.000314      0.104963\n",
      "Tr. Only          0.787143            0.801429  0.787143      0.790000\n",
      "Tr.Test Time     62.730045            0.000101  0.000318      0.104890\n",
      "Train             0.825309            0.823457  0.821111      0.999259\n",
      "Training Time   214.428659            0.000704  0.001636      0.102548\n",
      "took: 868.0068027973175 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t5\n",
      "Epoch 0: 2.4254132675827416\n",
      "Epoch 25: 0.007124853473765367\n",
      "Epoch 50: 0.0029632288716947815\n",
      "Epoch 75: 0.001946002681710592\n",
      "Epoch 100: 0.0014707003281763337\n",
      "Epoch 125: 0.001191508610895653\n",
      "Epoch 150: 0.0010063985808415055\n",
      "Took: 193.84930992126465 for training\n",
      "Took: 523.990800857544 for predicting 810 training instances\n",
      "Took: 58.46610379219055 for predicting 90 test instances\n",
      "Took: 65.26005339622498 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.031373            0.241477  0.289502      0.261729\n",
      "F1 Tr. only       0.021802            0.287556  0.313378      0.279572\n",
      "F1 Train          0.059300            0.306291  0.288964      0.996295\n",
      "Pred.Tra. Time  523.990801            0.144853  0.490867      0.110879\n",
      "Test              0.806173            0.792593  0.809877      0.746914\n",
      "Testing Time     58.466104            0.000131  0.000310      0.104856\n",
      "Tr. Only          0.787143            0.775714  0.804286      0.742857\n",
      "Tr.Test Time     65.260053            0.000136  0.000318      0.104731\n",
      "Train             0.825185            0.820617  0.823827      0.999259\n",
      "Training Time   193.849310            0.000654  0.001686      0.102402\n",
      "took: 841.7475633621216 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t6\n",
      "Epoch 0: 2.5140747782521813\n",
      "Epoch 25: 0.004502532258827418\n",
      "Epoch 50: 0.002211785128756912\n",
      "Epoch 75: 0.0014994027829871998\n",
      "Epoch 100: 0.001145901822772649\n",
      "Epoch 125: 0.0009330131943834358\n",
      "Epoch 150: 0.0007901334228653956\n",
      "Took: 193.82340168952942 for training\n",
      "Took: 521.019739151001 for predicting 810 training instances\n",
      "Took: 57.46411204338074 for predicting 90 test instances\n",
      "Took: 64.15533757209778 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.026623            0.243285  0.228530      0.258241\n",
      "F1 Tr. only       0.021802            0.292236  0.370055      0.308313\n",
      "F1 Train          0.060083            0.334170  0.321539      0.991355\n",
      "Pred.Tra. Time  521.019739            0.149468  0.518251      0.135072\n",
      "Test              0.803333            0.793333  0.790000      0.805556\n",
      "Testing Time     57.464112            0.000103  0.000301      0.104838\n",
      "Tr. Only          0.787143            0.767143  0.810000      0.747143\n",
      "Tr.Test Time     64.155338            0.000103  0.000323      0.104754\n",
      "Train             0.827778            0.827901  0.829630      0.998025\n",
      "Training Time   193.823402            0.000649  0.001684      0.103200\n",
      "took: 836.6289052963257 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t7\n",
      "Epoch 0: 2.0252993080216304\n",
      "Epoch 25: 0.004158288826428316\n",
      "Epoch 50: 0.0019495924537374248\n",
      "Epoch 75: 0.0013167823257401639\n",
      "Epoch 100: 0.001006455283062156\n",
      "Epoch 125: 0.000819903696613179\n",
      "Epoch 150: 0.0006945743623698125\n",
      "Took: 194.56617617607117 for training\n",
      "Took: 536.1434712409973 for predicting 810 training instances\n",
      "Took: 58.2746045589447 for predicting 90 test instances\n",
      "Took: 64.16651034355164 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.026623            0.224081  0.261481      0.265556\n",
      "F1 Tr. only       0.021802            0.332195  0.383894      0.335966\n",
      "F1 Train          0.060021            0.325914  0.350501      0.991345\n",
      "Pred.Tra. Time  536.143471            0.154256  0.783379      0.111752\n",
      "Test              0.795556            0.783333  0.787778      0.777778\n",
      "Testing Time     58.274605            0.000102  0.000305      0.104939\n",
      "Tr. Only          0.787143            0.788571  0.814286      0.771429\n",
      "Tr.Test Time     64.166510            0.000101  0.000321      0.105597\n",
      "Train             0.828519            0.827160  0.834198      0.998148\n",
      "Training Time   194.566176            0.000626  0.001614      0.102175\n",
      "took: 853.3530278205872 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t8\n",
      "Epoch 0: 2.386953772464716\n",
      "Epoch 25: 0.005820904014874234\n",
      "Epoch 50: 0.0026788789231635534\n",
      "Epoch 75: 0.0017896633637661456\n",
      "Epoch 100: 0.001360831037431109\n",
      "Epoch 125: 0.0011058854826850155\n",
      "Epoch 150: 0.0009358523425970097\n",
      "Took: 197.08762121200562 for training\n",
      "Took: 519.3965420722961 for predicting 810 training instances\n",
      "Took: 57.6979603767395 for predicting 90 test instances\n",
      "Took: 61.745113134384155 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.112281            0.240992  0.219282      0.236479\n",
      "F1 Tr. only       0.021802            0.348020  0.321095      0.231954\n",
      "F1 Train          0.050942            0.313870  0.282132      0.993809\n",
      "Pred.Tra. Time  519.396542            0.150652  0.478358      0.110773\n",
      "Test              0.863889            0.825000  0.816667      0.775000\n",
      "Testing Time     57.697960            0.000103  0.000320      0.104861\n",
      "Tr. Only          0.787143            0.800000  0.821429      0.688571\n",
      "Tr.Test Time     61.745113            0.000103  0.000319      0.105430\n",
      "Train             0.817901            0.821235  0.819383      0.998025\n",
      "Training Time   197.087621            0.000610  0.001600      0.103175\n",
      "took: 836.1293518543243 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t9\n",
      "Epoch 0: 2.9021928498045635\n",
      "Epoch 25: 0.005129504039105984\n",
      "Epoch 50: 0.002507706557218379\n",
      "Epoch 75: 0.0016960249718019924\n",
      "Epoch 100: 0.0012941287556573733\n",
      "Epoch 125: 0.001052249841851801\n",
      "Epoch 150: 0.0008898748942328894\n",
      "Took: 191.99448561668396 for training\n",
      "Took: 528.0968854427338 for predicting 810 training instances\n",
      "Took: 55.99299335479736 for predicting 90 test instances\n",
      "Took: 61.0268759727478 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.060021            0.133072  0.185791      0.230364\n",
      "F1 Tr. only       0.021802            0.308476  0.341620      0.303576\n",
      "F1 Train          0.055753            0.336940  0.438538      0.995064\n",
      "Pred.Tra. Time  528.096885            0.151687  1.024017      0.110780\n",
      "Test              0.798889            0.757778  0.768889      0.754444\n",
      "Testing Time     55.992993            0.000116  0.000320      0.104057\n",
      "Tr. Only          0.787143            0.781429  0.800000      0.737143\n",
      "Tr.Test Time     61.026876            0.000130  0.000322      0.105283\n",
      "Train             0.828148            0.828148  0.845679      0.998642\n",
      "Training Time   191.994486            0.000657  0.001659      0.102299\n",
      "took: 837.3354005813599 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t10\n",
      "Epoch 0: 2.313656463823308\n",
      "Epoch 25: 0.004104317455820494\n",
      "Epoch 50: 0.002030699017542741\n",
      "Epoch 75: 0.0013742376939195242\n",
      "Epoch 100: 0.0010469946722385733\n",
      "Epoch 125: 0.0008495575762263618\n",
      "Epoch 150: 0.000716896278712469\n",
      "Took: 191.57597875595093 for training\n",
      "Took: 533.8623700141907 for predicting 810 training instances\n",
      "Took: 63.952608823776245 for predicting 90 test instances\n",
      "Took: 59.9774386882782 for predicting 100 Turkish test instances\n",
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.082961            0.306383  0.338667      0.287274\n",
      "F1 Tr. only       0.020183            0.266340  0.286406      0.296579\n",
      "F1 Train          0.072491            0.303478  0.438964      0.995059\n",
      "Pred.Tra. Time  533.862370            0.147035  1.028941      0.111132\n",
      "Test              0.783333            0.806944  0.793056      0.773611\n",
      "Testing Time     63.952609            0.000118  0.000307      0.104713\n",
      "Tr. Only          0.787143            0.771429  0.735714      0.760000\n",
      "Tr.Test Time     59.977439            0.000104  0.000317      0.104804\n",
      "Train             0.800247            0.816173  0.837284      0.998889\n",
      "Training Time   191.575979            0.000640  0.001690      0.106039\n",
      "took: 849.5751967430115 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "Average scores for trial 0\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.061949            0.223569  0.239135      0.255812\n",
      "F1 Tr. only       0.034546            0.307982  0.320107      0.290001\n",
      "F1 Train          0.060912            0.322209  0.340488      0.994069\n",
      "Pred.Tra. Time  534.565261            0.156733  0.612567      0.116940\n",
      "Test              0.808858            0.789713  0.792898      0.778133\n",
      "Testing Time     58.875608            0.000117  0.000313      0.104795\n",
      "Tr. Only          0.788000            0.783000  0.798571      0.745429\n",
      "Tr.Test Time     63.845954            0.000113  0.000322      0.105129\n",
      "Train             0.822519            0.824481  0.829074      0.998679\n",
      "Training Time   193.396663            0.000674  0.001684      0.103337\n",
      "------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Average of 1 trials\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.061949            0.223569  0.239135      0.255812\n",
      "F1 Tr. only       0.034546            0.307982  0.320107      0.290001\n",
      "F1 Train          0.060912            0.322209  0.340488      0.994069\n",
      "Pred.Tra. Time  534.565261            0.156733  0.612567      0.116940\n",
      "Test              0.808858            0.789713  0.792898      0.778133\n",
      "Testing Time     58.875608            0.000117  0.000313      0.104795\n",
      "Tr. Only          0.788000            0.783000  0.798571      0.745429\n",
      "Tr.Test Time     63.845954            0.000113  0.000322      0.105129\n",
      "Train             0.822519            0.824481  0.829074      0.998679\n",
      "Training Time   193.396663            0.000674  0.001684      0.103337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores_tables_nn = eval_selectivewaves_nn(df, tronly_test_raw)\n",
    "pickle.dump(scores_tables_nn, open(\"../results/incremental_tf_tables.results\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustness_test(df_full, separate_test_size=100):    \n",
    "    en_revs = df_full[df_full.Language==\"en\"]\n",
    "    tr_revs = df_full[df_full.Language==\"tr\"]\n",
    "    separate_test_size = min(len(tr_revs)+1, separate_test_size)\n",
    "    test = tr_revs[-separate_test_size:]\n",
    "    tr_revs = tr_revs[:-separate_test_size]\n",
    "    robustness = dict()  # {(num of en reviews, num of tr reviews): scores_dict}\n",
    "    for en_size in range(1,11):\n",
    "        for tr_size in range(1,11):\n",
    "            en_train = en_revs.sample(frac=en_size/10.0)\n",
    "            tr_train = tr_revs.sample(frac=tr_size/10.0)\n",
    "            start = time.time()\n",
    "            print(\"En: {}\\tTr: {}\".format(len(en_train),len(tr_train)))\n",
    "            train = pd.concat([en_train, tr_train]).reset_index(drop=True)\n",
    "            robustness_tables = dict()\n",
    "            print(\"Using first variation (Regressor and Classifier with score vectors)\")\n",
    "            LSMR, score_vect_dicts, training_curve = get_score_vects(\n",
    "                                            train, alpha=1e-5, iterations=50)\n",
    "            regressor, classifier = fit(LSMR, score_vect_dicts)\n",
    "            preds, true = predict(test_data, score_vect_dicts, regressor, classifier)\n",
    "            s_regclass = distance_accuracy(true, preds)\n",
    "    #         f1_test_regclass = f1_score(true, preds, average='weighted')\n",
    "            robustness_tables[\"DeepSelect (regclass)\"] = s_regclass\n",
    "\n",
    "            print(\"Using second variation (average of outputs produced by each set of weight matrices)\")\n",
    "            W1, W2, W3, training_curve = train_selective(train, epochs=150, p_every=25)\n",
    "            preds_nn, true_nn = predict_selective(tr_revs, W1, W2, W3)\n",
    "            s_nn = distance_accuracy(true_nn, preds_nn)\n",
    "    #         f1_test_nn = f1_score(true_nn, preds_nn, average='weighted')\n",
    "            robustness_tables[\"DeepSelect\"] = s_nn\n",
    "\n",
    "            print(\"Using well-known algorithms: Logistic Regression, RandomForest and MLP\")\n",
    "            lr = LogisticRegression()\n",
    "            rf = RandomForestClassifier(n_jobs=-1)\n",
    "            mlp = MLPClassifier()\n",
    "\n",
    "            train_mat = np.array(list(LSMR[\"rev_vec\"]))\n",
    "            train_y = np.array(list(LSMR[\"Score\"]))\n",
    "            test_mat = np.array(list(preprocess_data(tr_revs)[\"rev_vec\"]))\n",
    "\n",
    "            for name, model in [(\"Logistic Regression\",lr),\n",
    "                                (\"RandomForest\", rf),\n",
    "                                (\"MLP\", mlp)]:\n",
    "                model.fit(train_mat, train_y)\n",
    "                robustness_tables[name] = distance_accuracy(true, model.predict(test_mat))\n",
    "            robustness[(len(en_train),len(tr_train))] = robustness_tables\n",
    "            print(\"Took: {}\".format(time.time()-start))\n",
    "            print(\"-\"*50)\n",
    "    return robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En: 50\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t16.52820921224812\n",
      "epoch 10:\t16.39311794442145\n",
      "epoch 20:\t16.28053593823387\n",
      "epoch 30:\t16.17463017163827\n",
      "epoch 40:\t16.067564309247263\n",
      "epoch 50:\t15.964494623225281\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 7.339794548606778\n",
      "Epoch 25: 0.08729174313691143\n",
      "Epoch 50: 0.015980279772296057\n",
      "Epoch 75: 0.008813390556133843\n",
      "Epoch 100: 0.006229110769650169\n",
      "Epoch 125: 0.004865745641478409\n",
      "Epoch 150: 0.00401580884632106\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 67.90573191642761\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.17242087221081\n",
      "epoch 10:\t19.943121625922586\n",
      "epoch 20:\t19.747438776393345\n",
      "epoch 30:\t19.562883062061417\n",
      "epoch 40:\t19.343043317450203\n",
      "epoch 50:\t19.134988594722827\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.537748518779587\n",
      "Epoch 25: 0.02896918413554466\n",
      "Epoch 50: 0.011732149529388362\n",
      "Epoch 75: 0.00750067419797303\n",
      "Epoch 100: 0.00556290933663359\n",
      "Epoch 125: 0.0044437062310127935\n",
      "Epoch 150: 0.0037117885535350907\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 97.6483633518219\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.558661043428863\n",
      "epoch 10:\t18.275162920900748\n",
      "epoch 20:\t18.0690512800357\n",
      "epoch 30:\t18.011163026017886\n",
      "epoch 40:\t17.979688741120565\n",
      "epoch 50:\t17.893496160064807\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 5.529079747339197\n",
      "Epoch 25: 0.020512997728527646\n",
      "Epoch 50: 0.009145965525856488\n",
      "Epoch 75: 0.006014972501543525\n",
      "Epoch 100: 0.004513847238152213\n",
      "Epoch 125: 0.003624595370665167\n",
      "Epoch 150: 0.003033832769629311\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 115.3185076713562\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.650004065424067\n",
      "epoch 10:\t20.501010042838722\n",
      "epoch 20:\t20.39800701220522\n",
      "epoch 30:\t20.278491025736592\n",
      "epoch 40:\t20.11572724965626\n",
      "epoch 50:\t19.923114970322096\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 5.586502467327262\n",
      "Epoch 25: 0.012770103482683311\n",
      "Epoch 50: 0.00597685394368238\n",
      "Epoch 75: 0.00401376832193299\n",
      "Epoch 100: 0.0030581356741225005\n",
      "Epoch 125: 0.0024870354660931427\n",
      "Epoch 150: 0.0021050228487172803\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 147.89269638061523\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.207572227998376\n",
      "epoch 10:\t19.083247898189956\n",
      "epoch 20:\t19.03569606932404\n",
      "epoch 30:\t18.94439668950445\n",
      "epoch 40:\t18.87147352515329\n",
      "epoch 50:\t18.787741274334515\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.921140831965866\n",
      "Epoch 25: 0.008907715815676056\n",
      "Epoch 50: 0.004296590380481575\n",
      "Epoch 75: 0.002905163657736011\n",
      "Epoch 100: 0.00222057767339993\n",
      "Epoch 125: 0.0018094544650148236\n",
      "Epoch 150: 0.0015336333086393096\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 165.94341206550598\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.207796265508662\n",
      "epoch 10:\t21.99923903785189\n",
      "epoch 20:\t21.8343851582949\n",
      "epoch 30:\t21.63882946082881\n",
      "epoch 40:\t21.4389646683601\n",
      "epoch 50:\t21.222813907040518\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.8077726276764787\n",
      "Epoch 25: 0.008134934987037924\n",
      "Epoch 50: 0.003975011260735661\n",
      "Epoch 75: 0.0026854954341419654\n",
      "Epoch 100: 0.002047992654231699\n",
      "Epoch 125: 0.0016648195952402131\n",
      "Epoch 150: 0.0014078559791512596\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 194.4621250629425\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.233458047309444\n",
      "epoch 10:\t20.041739636448913\n",
      "epoch 20:\t19.891385162254203\n",
      "epoch 30:\t19.71715369944107\n",
      "epoch 40:\t19.561088087049676\n",
      "epoch 50:\t19.43148609784066\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.821938721553482\n",
      "Epoch 25: 0.01253030508266668\n",
      "Epoch 50: 0.005854549981108214\n",
      "Epoch 75: 0.0039043113349882994\n",
      "Epoch 100: 0.002959969207274822\n",
      "Epoch 125: 0.0023984562801987607\n",
      "Epoch 150: 0.0020243045445926273\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 215.1549551486969\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.430905383380168\n",
      "epoch 10:\t23.18144371995767\n",
      "epoch 20:\t22.94502573587449\n",
      "epoch 30:\t22.70553442408163\n",
      "epoch 40:\t22.466395823016427\n",
      "epoch 50:\t22.25169961727304\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.5469703360552067\n",
      "Epoch 25: 0.008192623501099353\n",
      "Epoch 50: 0.003823824644709131\n",
      "Epoch 75: 0.002550301385817598\n",
      "Epoch 100: 0.001932100512973451\n",
      "Epoch 125: 0.0015639287674667451\n",
      "Epoch 150: 0.0013184374155939223\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 228.99712491035461\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.13661317279356\n",
      "epoch 10:\t21.035086856216374\n",
      "epoch 20:\t20.90981561251643\n",
      "epoch 30:\t20.738727637396543\n",
      "epoch 40:\t20.59078150136115\n",
      "epoch 50:\t20.456599832109802\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.27495084668355\n",
      "Epoch 25: 0.008682058947574772\n",
      "Epoch 50: 0.003922100654622726\n",
      "Epoch 75: 0.002587961226206156\n",
      "Epoch 100: 0.0019491792230337246\n",
      "Epoch 125: 0.001571730005687824\n",
      "Epoch 150: 0.0013214073862277556\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 257.6350030899048\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.7418612024327\n",
      "epoch 10:\t20.61126471828218\n",
      "epoch 20:\t20.427651514925522\n",
      "epoch 30:\t20.224610123807626\n",
      "epoch 40:\t20.038430630643447\n",
      "epoch 50:\t19.87129637088691\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.0611462647272694\n",
      "Epoch 25: 0.013180303992127544\n",
      "Epoch 50: 0.004980258201166584\n",
      "Epoch 75: 0.0031414944836789496\n",
      "Epoch 100: 0.0023115928415877026\n",
      "Epoch 125: 0.001836346504895927\n",
      "Epoch 150: 0.0015275294163778754\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 271.9390392303467\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.86882168245634\n",
      "epoch 10:\t19.9092612408944\n",
      "epoch 20:\t19.805491090237812\n",
      "epoch 30:\t19.614890601752453\n",
      "epoch 40:\t19.394302070273426\n",
      "epoch 50:\t19.202363324633318\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 5.129584824559944\n",
      "Epoch 25: 0.07302809065203064\n",
      "Epoch 50: 0.018936178862778822\n",
      "Epoch 75: 0.008098027134043865\n",
      "Epoch 100: 0.005344458754093954\n",
      "Epoch 125: 0.004043634303583791\n",
      "Epoch 150: 0.003275666567844837\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 106.9969220161438\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.8334635842836\n",
      "epoch 10:\t19.596365687491907\n",
      "epoch 20:\t19.42477436447093\n",
      "epoch 30:\t19.18635338742181\n",
      "epoch 40:\t18.98612432579517\n",
      "epoch 50:\t18.824622419099178\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.073025793182993\n",
      "Epoch 25: 0.024851973619600662\n",
      "Epoch 50: 0.009547373446093844\n",
      "Epoch 75: 0.006075273871617052\n",
      "Epoch 100: 0.004498353506844271\n",
      "Epoch 125: 0.0035907408257824297\n",
      "Epoch 150: 0.00299853506651036\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 131.9662082195282\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.16143237968937\n",
      "epoch 10:\t22.895519960223215\n",
      "epoch 20:\t22.630408198515518\n",
      "epoch 30:\t22.393349482121188\n",
      "epoch 40:\t22.15018465776216\n",
      "epoch 50:\t21.9228406337818\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.097704803931992\n",
      "Epoch 25: 0.01171999797953421\n",
      "Epoch 50: 0.005583083305720555\n",
      "Epoch 75: 0.0037276106836987887\n",
      "Epoch 100: 0.002820443417107816\n",
      "Epoch 125: 0.0022790729098708406\n",
      "Epoch 150: 0.0019179223946500976\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 157.23956084251404\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.030692492409532\n",
      "epoch 10:\t17.966970356394008\n",
      "epoch 20:\t17.902395139477072\n",
      "epoch 30:\t17.842417408589657\n",
      "epoch 40:\t17.792289593120998\n",
      "epoch 50:\t17.742208190843115\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.6150671737271365\n",
      "Epoch 25: 0.02688962801029832\n",
      "Epoch 50: 0.008102054117510376\n",
      "Epoch 75: 0.004946322766180454\n",
      "Epoch 100: 0.0035976783454416887\n",
      "Epoch 125: 0.0028439896536409694\n",
      "Epoch 150: 0.0023607819092273546\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 177.96316170692444\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.79707911365647\n",
      "epoch 10:\t21.579340775055037\n",
      "epoch 20:\t21.319263888025546\n",
      "epoch 30:\t21.083574187988813\n",
      "epoch 40:\t20.877853598556165\n",
      "epoch 50:\t20.678224027628165\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.022157329743908\n",
      "Epoch 25: 0.013149791939492653\n",
      "Epoch 50: 0.005074322252737223\n",
      "Epoch 75: 0.003283855563414401\n",
      "Epoch 100: 0.0024660120824588224\n",
      "Epoch 125: 0.0019900957459336155\n",
      "Epoch 150: 0.0016760999038595513\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 200.16781044006348\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.48452854974004\n",
      "epoch 10:\t20.36027199581928\n",
      "epoch 20:\t20.1939450112428\n",
      "epoch 30:\t20.05790142204325\n",
      "epoch 40:\t19.93724989704214\n",
      "epoch 50:\t19.82781621670487\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.5623621198098268\n",
      "Epoch 25: 0.008550410627038475\n",
      "Epoch 50: 0.003926103010309678\n",
      "Epoch 75: 0.002606454517836872\n",
      "Epoch 100: 0.001970258335651293\n",
      "Epoch 125: 0.0015927595037199434\n",
      "Epoch 150: 0.0013416406704134895\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 229.26985144615173\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.10494286979153\n",
      "epoch 10:\t20.89894679956469\n",
      "epoch 20:\t20.685748409781187\n",
      "epoch 30:\t20.5010005360481\n",
      "epoch 40:\t20.354514089265002\n",
      "epoch 50:\t20.182619935342764\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.8759061492468296\n",
      "Epoch 25: 0.011034273873407361\n",
      "Epoch 50: 0.004876591607318771\n",
      "Epoch 75: 0.003214784715911073\n",
      "Epoch 100: 0.0024239204727803695\n",
      "Epoch 125: 0.0019574643842038076\n",
      "Epoch 150: 0.0016482350777347451\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 249.13368248939514\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.020764458651293\n",
      "epoch 10:\t20.891886241392378\n",
      "epoch 20:\t20.68192359233935\n",
      "epoch 30:\t20.49713849051033\n",
      "epoch 40:\t20.373689276336414\n",
      "epoch 50:\t20.265332904851938\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.676640738699782\n",
      "Epoch 25: 0.029177015036527466\n",
      "Epoch 50: 0.006549534974939369\n",
      "Epoch 75: 0.0038066155166732295\n",
      "Epoch 100: 0.0027189252839662005\n",
      "Epoch 125: 0.0021315732859940387\n",
      "Epoch 150: 0.0017631736603724287\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 271.3981873989105\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.611996609227326\n",
      "epoch 10:\t19.550913302986253\n",
      "epoch 20:\t19.484419036839885\n",
      "epoch 30:\t19.43057801214237\n",
      "epoch 40:\t19.370563558298308\n",
      "epoch 50:\t19.308662664746727\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.5847677716950102\n",
      "Epoch 25: 0.004585617790633147\n",
      "Epoch 50: 0.0023508130706804556\n",
      "Epoch 75: 0.0016081602297063568\n",
      "Epoch 100: 0.0012323498404728885\n",
      "Epoch 125: 0.0010039285088413964\n",
      "Epoch 150: 0.0008497835313989153\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 289.33306646347046\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.4479804995722\n",
      "epoch 10:\t22.235946698893777\n",
      "epoch 20:\t22.00800224306249\n",
      "epoch 30:\t21.790577228389363\n",
      "epoch 40:\t21.61653206921743\n",
      "epoch 50:\t21.48750014526655\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.1582032730954523\n",
      "Epoch 25: 0.004965149507272372\n",
      "Epoch 50: 0.002417920444570882\n",
      "Epoch 75: 0.0016318884558484115\n",
      "Epoch 100: 0.0012430625843048802\n",
      "Epoch 125: 0.0010091691360825052\n",
      "Epoch 150: 0.0008522512376118243\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 316.6615414619446\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.15616335692374\n",
      "epoch 10:\t21.857546057276803\n",
      "epoch 20:\t21.3647330114568\n",
      "epoch 30:\t20.99977583926535\n",
      "epoch 40:\t20.714517377219174\n",
      "epoch 50:\t20.453905815546484\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.791492950846441\n",
      "Epoch 25: 0.022575320332503236\n",
      "Epoch 50: 0.0074050309615406726\n",
      "Epoch 75: 0.004584078676560622\n",
      "Epoch 100: 0.0033654293342543066\n",
      "Epoch 125: 0.0026786330240826683\n",
      "Epoch 150: 0.00223509240462303\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 142.16614723205566\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.8172021139943\n",
      "epoch 10:\t21.598703792211186\n",
      "epoch 20:\t21.425414424510098\n",
      "epoch 30:\t21.246898187583902\n",
      "epoch 40:\t21.076554412868582\n",
      "epoch 50:\t20.922790006585526\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.6764972273495875\n",
      "Epoch 25: 0.008017707224739158\n",
      "Epoch 50: 0.004025442810036664\n",
      "Epoch 75: 0.0027544117511554404\n",
      "Epoch 100: 0.0021162931054356667\n",
      "Epoch 125: 0.0017289250559770152\n",
      "Epoch 150: 0.0014673169815701524\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 167.22138571739197\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.48992700144672\n",
      "epoch 10:\t19.316554728702908\n",
      "epoch 20:\t19.1712271567448\n",
      "epoch 30:\t18.991007348601958\n",
      "epoch 40:\t18.83458985944437\n",
      "epoch 50:\t18.71095832879485\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.7186488738201056\n",
      "Epoch 25: 0.015392832230211886\n",
      "Epoch 50: 0.005814481665725503\n",
      "Epoch 75: 0.0037161891812222286\n",
      "Epoch 100: 0.0027641083468274196\n",
      "Epoch 125: 0.0022143103348145976\n",
      "Epoch 150: 0.0018540579293586377\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 187.22345805168152\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.585262591379355\n",
      "epoch 10:\t18.527532554101132\n",
      "epoch 20:\t18.44668109394878\n",
      "epoch 30:\t18.379011969405234\n",
      "epoch 40:\t18.31026156791402\n",
      "epoch 50:\t18.235632920667165\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 6.386730050672181\n",
      "Epoch 25: 0.03168226513110224\n",
      "Epoch 50: 0.008378137390590998\n",
      "Epoch 75: 0.00513829306515955\n",
      "Epoch 100: 0.003777836485899629\n",
      "Epoch 125: 0.0030132118734275447\n",
      "Epoch 150: 0.0025192542548068326\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 210.33798003196716\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.573434935504174\n",
      "epoch 10:\t23.351050803686526\n",
      "epoch 20:\t23.149934728436136\n",
      "epoch 30:\t22.98582652364161\n",
      "epoch 40:\t22.85166469344882\n",
      "epoch 50:\t22.726070760664655\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.103576277324547\n",
      "Epoch 25: 0.007391933911624327\n",
      "Epoch 50: 0.003524582524425617\n",
      "Epoch 75: 0.002367519000686156\n",
      "Epoch 100: 0.0018002176498481098\n",
      "Epoch 125: 0.0014604808573380572\n",
      "Epoch 150: 0.0012331005110168495\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 233.06008338928223\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.00986803254752\n",
      "epoch 10:\t21.822853833190955\n",
      "epoch 20:\t21.689463576386274\n",
      "epoch 30:\t21.537908730465613\n",
      "epoch 40:\t21.382265836372866\n",
      "epoch 50:\t21.254283402042567\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.8044332785358748\n",
      "Epoch 25: 0.010539666725563644\n",
      "Epoch 50: 0.004936709455316117\n",
      "Epoch 75: 0.003311756141178753\n",
      "Epoch 100: 0.002522434524942769\n",
      "Epoch 125: 0.0020510104281689003\n",
      "Epoch 150: 0.0017355997590129846\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 264.267028093338\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.989097355594925\n",
      "epoch 10:\t19.91210693328592\n",
      "epoch 20:\t19.850295174191455\n",
      "epoch 30:\t19.788516176000545\n",
      "epoch 40:\t19.729596618388232\n",
      "epoch 50:\t19.67257795478231\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.9771409824188848\n",
      "Epoch 25: 0.005876495422645285\n",
      "Epoch 50: 0.0027761702840356796\n",
      "Epoch 75: 0.0018485769343563989\n",
      "Epoch 100: 0.00139673410024094\n",
      "Epoch 125: 0.0011277702119314675\n",
      "Epoch 150: 0.0009487010400361278\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 283.77928614616394\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.15872654945169\n",
      "epoch 10:\t20.994643254515445\n",
      "epoch 20:\t20.889219108199434\n",
      "epoch 30:\t20.77700338469528\n",
      "epoch 40:\t20.685846463670977\n",
      "epoch 50:\t20.5934540559441\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.9829293372635877\n",
      "Epoch 25: 0.00890653217077941\n",
      "Epoch 50: 0.0036769324435628266\n",
      "Epoch 75: 0.0023857103837788096\n",
      "Epoch 100: 0.0017877976719415877\n",
      "Epoch 125: 0.0014393954148816076\n",
      "Epoch 150: 0.0012098678454590492\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 307.3232114315033\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t26.114602819401682\n",
      "epoch 10:\t25.760612354606614\n",
      "epoch 20:\t25.27181005061845\n",
      "epoch 30:\t24.814327419460774\n",
      "epoch 40:\t24.364151873191403\n",
      "epoch 50:\t23.952279100798513\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.2453539410875405\n",
      "Epoch 25: 0.007221409808606522\n",
      "Epoch 50: 0.003292698211774169\n",
      "Epoch 75: 0.002175347149274303\n",
      "Epoch 100: 0.0016407766716837408\n",
      "Epoch 125: 0.0013255510151176238\n",
      "Epoch 150: 0.0011168204209540962\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 331.32477378845215\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.851142158405626\n",
      "epoch 10:\t22.801282839150993\n",
      "epoch 20:\t22.576772341395934\n",
      "epoch 30:\t22.336404643846812\n",
      "epoch 40:\t22.13157604571347\n",
      "epoch 50:\t21.936151582047092\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.835650669848189\n",
      "Epoch 25: 0.008615990609600265\n",
      "Epoch 50: 0.0037791118000726244\n",
      "Epoch 75: 0.0024965943380578894\n",
      "Epoch 100: 0.0018896010808659143\n",
      "Epoch 125: 0.001531597887463983\n",
      "Epoch 150: 0.0012937564252620021\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 344.8439230918884\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.87951329775793\n",
      "epoch 10:\t21.609583785677806\n",
      "epoch 20:\t21.374985183572463\n",
      "epoch 30:\t21.146925251475402\n",
      "epoch 40:\t20.908895052425535\n",
      "epoch 50:\t20.683415301318153\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.0130757942501516\n",
      "Epoch 25: 0.018946271147936265\n",
      "Epoch 50: 0.004527614615739613\n",
      "Epoch 75: 0.002793914477332393\n",
      "Epoch 100: 0.0020625949514161118\n",
      "Epoch 125: 0.0016485953188882499\n",
      "Epoch 150: 0.0013795942953673665\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 169.36197710037231\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.141952502430648\n",
      "epoch 10:\t20.986465825104034\n",
      "epoch 20:\t20.73812942822706\n",
      "epoch 30:\t20.522807447303148\n",
      "epoch 40:\t20.32276133698312\n",
      "epoch 50:\t20.147302365526336\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 5.931420692024758\n",
      "Epoch 25: 0.0274967080895619\n",
      "Epoch 50: 0.007544038837314864\n",
      "Epoch 75: 0.004652672860395666\n",
      "Epoch 100: 0.0034209811425203692\n",
      "Epoch 125: 0.0027264560565738193\n",
      "Epoch 150: 0.0022766816292249\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 193.20699405670166\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.8286005941117\n",
      "epoch 10:\t18.73982597343862\n",
      "epoch 20:\t18.63870677704113\n",
      "epoch 30:\t18.557730064488265\n",
      "epoch 40:\t18.490939181058966\n",
      "epoch 50:\t18.41826496452496\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 5.717472193680078\n",
      "Epoch 25: 0.027288279246897675\n",
      "Epoch 50: 0.00819466482400628\n",
      "Epoch 75: 0.00500264523851115\n",
      "Epoch 100: 0.0036470251293508225\n",
      "Epoch 125: 0.0028877940763777587\n",
      "Epoch 150: 0.0023996049808403088\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 218.02778792381287\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.833737199558858\n",
      "epoch 10:\t22.53110330653086\n",
      "epoch 20:\t22.30699458248825\n",
      "epoch 30:\t22.11693086532055\n",
      "epoch 40:\t21.960229457232266\n",
      "epoch 50:\t21.824923931630057\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.33508396314053\n",
      "Epoch 25: 0.01592504507264165\n",
      "Epoch 50: 0.005995053685411891\n",
      "Epoch 75: 0.0038420682688142605\n",
      "Epoch 100: 0.0028688629922456244\n",
      "Epoch 125: 0.00230762209648216\n",
      "Epoch 150: 0.0019401352673391948\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 262.4925711154938\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t25.313367207873036\n",
      "epoch 10:\t25.199084836044797\n",
      "epoch 20:\t24.978783905433346\n",
      "epoch 30:\t24.71380693032838\n",
      "epoch 40:\t24.44487538676406\n",
      "epoch 50:\t24.182971413031176\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.084877554877587\n",
      "Epoch 25: 0.006880885046975323\n",
      "Epoch 50: 0.0034188256505302663\n",
      "Epoch 75: 0.0023227515433063674\n",
      "Epoch 100: 0.001776408325976604\n",
      "Epoch 125: 0.0014465876076837957\n",
      "Epoch 150: 0.0012247978951802452\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 272.2025966644287\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.50827004943057\n",
      "epoch 10:\t18.40771581824874\n",
      "epoch 20:\t18.278970912527704\n",
      "epoch 30:\t18.170394785411673\n",
      "epoch 40:\t18.08557541778162\n",
      "epoch 50:\t18.02176877612144\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.258408594256848\n",
      "Epoch 25: 0.03581006818670341\n",
      "Epoch 50: 0.007744724390673499\n",
      "Epoch 75: 0.004443860824132819\n",
      "Epoch 100: 0.0031487209098165956\n",
      "Epoch 125: 0.0024498513996005305\n",
      "Epoch 150: 0.0020104004706405993\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 300.81946086883545\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t30.120137697344433\n",
      "epoch 10:\t29.69258176729101\n",
      "epoch 20:\t29.2924536832179\n",
      "epoch 30:\t29.092448989197653\n",
      "epoch 40:\t29.197482055681814\n",
      "epoch 50:\t28.996832828671863\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.712213295086008\n",
      "Epoch 25: 0.006052407208360933\n",
      "Epoch 50: 0.002970356582228343\n",
      "Epoch 75: 0.0019962239565464537\n",
      "Epoch 100: 0.0015132678838424064\n",
      "Epoch 125: 0.0012232408024338485\n",
      "Epoch 150: 0.0010291367877735583\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 322.5249376296997\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.488690836008942\n",
      "epoch 10:\t18.44451361650892\n",
      "epoch 20:\t18.401417866662825\n",
      "epoch 30:\t18.35061118800551\n",
      "epoch 40:\t18.289243706219736\n",
      "epoch 50:\t18.227061270656314\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.1896447209087393\n",
      "Epoch 25: 0.010615806706615362\n",
      "Epoch 50: 0.003953996544274219\n",
      "Epoch 75: 0.002516640535156748\n",
      "Epoch 100: 0.0018705631424802724\n",
      "Epoch 125: 0.001499050186277683\n",
      "Epoch 150: 0.0012561569093688918\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 337.04653096199036\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.7590645417584\n",
      "epoch 10:\t21.577269451447524\n",
      "epoch 20:\t21.45013678703915\n",
      "epoch 30:\t21.364717144900236\n",
      "epoch 40:\t21.290260857748514\n",
      "epoch 50:\t21.216369578558403\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.47821453957151\n",
      "Epoch 25: 0.006764135695345073\n",
      "Epoch 50: 0.0031654199016721966\n",
      "Epoch 75: 0.002120024489424769\n",
      "Epoch 100: 0.0016114300280725452\n",
      "Epoch 125: 0.0013077016186826996\n",
      "Epoch 150: 0.0011046192404086648\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 356.83785462379456\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t25.60914285300418\n",
      "epoch 10:\t25.22745892870912\n",
      "epoch 20:\t24.866948447984914\n",
      "epoch 30:\t24.58809774502688\n",
      "epoch 40:\t24.292140936662708\n",
      "epoch 50:\t23.97734841748848\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.646724799795411\n",
      "Epoch 25: 0.008839020231458411\n",
      "Epoch 50: 0.00433057249042785\n",
      "Epoch 75: 0.002948463788459132\n",
      "Epoch 100: 0.002262426031124297\n",
      "Epoch 125: 0.00184795593677336\n",
      "Epoch 150: 0.001568709950307247\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 381.79757475852966\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.952726617239424\n",
      "epoch 10:\t20.817256859920686\n",
      "epoch 20:\t20.707687955423584\n",
      "epoch 30:\t20.601828493966888\n",
      "epoch 40:\t20.502902709480832\n",
      "epoch 50:\t20.406839692033632\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.6536252902080566\n",
      "Epoch 25: 0.011118674516534345\n",
      "Epoch 50: 0.0045866840274701925\n",
      "Epoch 75: 0.003002458423781781\n",
      "Epoch 100: 0.0022629215808655286\n",
      "Epoch 125: 0.001829097366257413\n",
      "Epoch 150: 0.0015418871873313538\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 204.3739891052246\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.8784085718491\n",
      "epoch 10:\t19.702857991683402\n",
      "epoch 20:\t19.501702421596452\n",
      "epoch 30:\t19.33651598095254\n",
      "epoch 40:\t19.206772382684413\n",
      "epoch 50:\t19.080008138963034\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.958588392660904\n",
      "Epoch 25: 0.01252805821377754\n",
      "Epoch 50: 0.005421447953675383\n",
      "Epoch 75: 0.00352707057868291\n",
      "Epoch 100: 0.002636141976610375\n",
      "Epoch 125: 0.002114606324275056\n",
      "Epoch 150: 0.0017707202359898391\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 241.1300253868103\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.50984084546834\n",
      "epoch 10:\t19.41343576482552\n",
      "epoch 20:\t19.33363715062497\n",
      "epoch 30:\t19.245676341982495\n",
      "epoch 40:\t19.15225546774284\n",
      "epoch 50:\t19.064223896230608\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.4761431308412876\n",
      "Epoch 25: 0.010081440418464907\n",
      "Epoch 50: 0.004786870506798034\n",
      "Epoch 75: 0.0031992668994594415\n",
      "Epoch 100: 0.00242245679423432\n",
      "Epoch 125: 0.001958343715649347\n",
      "Epoch 150: 0.0016485054008571014\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 264.4336893558502\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.216309278630806\n",
      "epoch 10:\t19.194461330104858\n",
      "epoch 20:\t19.12608715508994\n",
      "epoch 30:\t19.03428923330069\n",
      "epoch 40:\t18.929643425467948\n",
      "epoch 50:\t18.840975112275867\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.7402938980374927\n",
      "Epoch 25: 0.00514508184037035\n",
      "Epoch 50: 0.002627125040819409\n",
      "Epoch 75: 0.0018052588430137115\n",
      "Epoch 100: 0.001389780850608875\n",
      "Epoch 125: 0.0011366604193848084\n",
      "Epoch 150: 0.0009653131772466157\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 285.7581968307495\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.070488543865814\n",
      "epoch 10:\t20.943190681980205\n",
      "epoch 20:\t20.765631263675466\n",
      "epoch 30:\t20.619234313766523\n",
      "epoch 40:\t20.499348097753654\n",
      "epoch 50:\t20.393535740504692\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.284200203139723\n",
      "Epoch 25: 0.012114724326319345\n",
      "Epoch 50: 0.005178028020056647\n",
      "Epoch 75: 0.003403758857051192\n",
      "Epoch 100: 0.002569238529373858\n",
      "Epoch 125: 0.002078996623845847\n",
      "Epoch 150: 0.0017544423478324865\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 308.22048258781433\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.13082299579924\n",
      "epoch 10:\t20.93985571266741\n",
      "epoch 20:\t20.79405430130888\n",
      "epoch 30:\t20.52842073454652\n",
      "epoch 40:\t20.313880828448106\n",
      "epoch 50:\t20.115741299331088\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.1386772949409374\n",
      "Epoch 25: 0.012147004881993854\n",
      "Epoch 50: 0.0038992278246273693\n",
      "Epoch 75: 0.002499413326609101\n",
      "Epoch 100: 0.0018749466613380904\n",
      "Epoch 125: 0.0015148897302090202\n",
      "Epoch 150: 0.0012784832698455328\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 328.01486110687256\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.28392720614052\n",
      "epoch 10:\t20.16524281941698\n",
      "epoch 20:\t20.05266255221482\n",
      "epoch 30:\t19.937405853721472\n",
      "epoch 40:\t19.85109249759553\n",
      "epoch 50:\t19.76797902459815\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.749173306745193\n",
      "Epoch 25: 0.005152725766729171\n",
      "Epoch 50: 0.002573071666336815\n",
      "Epoch 75: 0.0017550996828565005\n",
      "Epoch 100: 0.0013450042285652573\n",
      "Epoch 125: 0.0010961843947604997\n",
      "Epoch 150: 0.0009282196819177317\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 348.3618206977844\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.214948044520476\n",
      "epoch 10:\t22.749101182281315\n",
      "epoch 20:\t22.52291352422376\n",
      "epoch 30:\t22.2283484491143\n",
      "epoch 40:\t21.99950670311144\n",
      "epoch 50:\t21.799729907863714\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.7062756595164932\n",
      "Epoch 25: 0.004697346904462295\n",
      "Epoch 50: 0.0023597265071381864\n",
      "Epoch 75: 0.0016125991305116578\n",
      "Epoch 100: 0.0012376489428418294\n",
      "Epoch 125: 0.0010100535591528856\n",
      "Epoch 150: 0.0008563226516329543\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 375.36515069007874\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.9796712891421\n",
      "epoch 10:\t22.74682510757704\n",
      "epoch 20:\t22.461683607206236\n",
      "epoch 30:\t22.166642274140553\n",
      "epoch 40:\t21.934790859440838\n",
      "epoch 50:\t21.730711688571624\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.955847713540484\n",
      "Epoch 25: 0.011883186281515098\n",
      "Epoch 50: 0.0051278996162420565\n",
      "Epoch 75: 0.0033815795689898535\n",
      "Epoch 100: 0.0025604518606393016\n",
      "Epoch 125: 0.0020775237672341225\n",
      "Epoch 150: 0.0017572520026235116\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 393.17196106910706\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.145035685847127\n",
      "epoch 10:\t22.961444867638857\n",
      "epoch 20:\t22.800300878752246\n",
      "epoch 30:\t22.649455385917292\n",
      "epoch 40:\t22.514695851232112\n",
      "epoch 50:\t22.377291874631887\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.160434352555984\n",
      "Epoch 25: 0.005160337744698434\n",
      "Epoch 50: 0.002580344217461306\n",
      "Epoch 75: 0.0017586434629277812\n",
      "Epoch 100: 0.0013470655700029092\n",
      "Epoch 125: 0.0010975944098074182\n",
      "Epoch 150: 0.0009292922926643035\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 407.61310338974\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.00293898528469\n",
      "epoch 10:\t21.80178594233744\n",
      "epoch 20:\t21.620557175868647\n",
      "epoch 30:\t21.38161168538247\n",
      "epoch 40:\t21.13645009528317\n",
      "epoch 50:\t20.915321559398684\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.6980728767266984\n",
      "Epoch 25: 0.008137032215544798\n",
      "Epoch 50: 0.0032344357458281166\n",
      "Epoch 75: 0.0020930516317214237\n",
      "Epoch 100: 0.0015684026222756715\n",
      "Epoch 125: 0.0012636639357899238\n",
      "Epoch 150: 0.0010632610615703818\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 238.04393458366394\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.526886122801898\n",
      "epoch 10:\t24.065891438433823\n",
      "epoch 20:\t23.700930914062432\n",
      "epoch 30:\t23.428588806547776\n",
      "epoch 40:\t23.20742315846807\n",
      "epoch 50:\t22.963659580181464\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.8929623735854157\n",
      "Epoch 25: 0.011117439200126299\n",
      "Epoch 50: 0.004842279212243739\n",
      "Epoch 75: 0.0032271784414277995\n",
      "Epoch 100: 0.002458861794002587\n",
      "Epoch 125: 0.0020031184658268774\n",
      "Epoch 150: 0.001698961645405162\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 266.552695274353\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.67502496924017\n",
      "epoch 10:\t21.383501030426277\n",
      "epoch 20:\t21.19323519433857\n",
      "epoch 30:\t21.035232985458055\n",
      "epoch 40:\t20.891465500634453\n",
      "epoch 50:\t20.760009787720982\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.7341412948312827\n",
      "Epoch 25: 0.008669030578916395\n",
      "Epoch 50: 0.003921413069413878\n",
      "Epoch 75: 0.0025925106799344834\n",
      "Epoch 100: 0.001954601717245298\n",
      "Epoch 125: 0.001576843445554048\n",
      "Epoch 150: 0.0013258921469579425\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 286.59071946144104\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.041746420127573\n",
      "epoch 10:\t23.779847022675277\n",
      "epoch 20:\t23.49091149963166\n",
      "epoch 30:\t23.300782376701022\n",
      "epoch 40:\t23.15711748149478\n",
      "epoch 50:\t23.023955710410497\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.9281752178022091\n",
      "Epoch 25: 0.008197828841674021\n",
      "Epoch 50: 0.0036887857709604326\n",
      "Epoch 75: 0.002434244551146677\n",
      "Epoch 100: 0.001834922189502826\n",
      "Epoch 125: 0.0014809828738638385\n",
      "Epoch 150: 0.0012462341748594643\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 315.76285672187805\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.70394025915572\n",
      "epoch 10:\t21.610268296580728\n",
      "epoch 20:\t21.587209888569767\n",
      "epoch 30:\t21.522669543179568\n",
      "epoch 40:\t21.432579596532612\n",
      "epoch 50:\t21.3178972458377\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.17281551660852\n",
      "Epoch 25: 0.013922408836180693\n",
      "Epoch 50: 0.005509425762244064\n",
      "Epoch 75: 0.0035312491943113853\n",
      "Epoch 100: 0.0026259100250244955\n",
      "Epoch 125: 0.0021015814355432668\n",
      "Epoch 150: 0.0017577115177391533\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 334.5150303840637\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.806555730606654\n",
      "epoch 10:\t22.478975681761572\n",
      "epoch 20:\t22.32324112611806\n",
      "epoch 30:\t22.184692875291386\n",
      "epoch 40:\t22.021589944065738\n",
      "epoch 50:\t21.85981746801544\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.5704141190396816\n",
      "Epoch 25: 0.00581188155946919\n",
      "Epoch 50: 0.002750116382206034\n",
      "Epoch 75: 0.0018484664724330404\n",
      "Epoch 100: 0.001407294011144068\n",
      "Epoch 125: 0.001142923501280456\n",
      "Epoch 150: 0.0009657868739594206\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 357.9664890766144\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t27.7877659579056\n",
      "epoch 10:\t27.28060726695208\n",
      "epoch 20:\t26.861793717591194\n",
      "epoch 30:\t26.5156232289071\n",
      "epoch 40:\t26.151737369553736\n",
      "epoch 50:\t25.792026847774974\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.5845950818573202\n",
      "Epoch 25: 0.0067961114938161074\n",
      "Epoch 50: 0.0032799630812640882\n",
      "Epoch 75: 0.0022104156976422867\n",
      "Epoch 100: 0.0016827501860412777\n",
      "Epoch 125: 0.0013659554146617492\n",
      "Epoch 150: 0.001153763605490722\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 393.20270228385925\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.620714075008696\n",
      "epoch 10:\t21.564670666911866\n",
      "epoch 20:\t21.461081662918136\n",
      "epoch 30:\t21.350367148281826\n",
      "epoch 40:\t21.23047550451202\n",
      "epoch 50:\t21.109757343529292\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.4620138788820922\n",
      "Epoch 25: 0.003627448999766568\n",
      "Epoch 50: 0.0018960977684239957\n",
      "Epoch 75: 0.0013088087846062119\n",
      "Epoch 100: 0.0010082517931969902\n",
      "Epoch 125: 0.000824230684981311\n",
      "Epoch 150: 0.0006994362657218243\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 390.75848746299744\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.586691053320486\n",
      "epoch 10:\t23.283824528945345\n",
      "epoch 20:\t23.181527020408776\n",
      "epoch 30:\t22.92851255474014\n",
      "epoch 40:\t22.63724653412549\n",
      "epoch 50:\t22.37500433865825\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.970863287982867\n",
      "Epoch 25: 0.006628275355538363\n",
      "Epoch 50: 0.0032079747681834623\n",
      "Epoch 75: 0.0021760516404550814\n",
      "Epoch 100: 0.0016661011466729207\n",
      "Epoch 125: 0.0013585199725833325\n",
      "Epoch 150: 0.00115136702317207\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 426.1990637779236\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.370965675660774\n",
      "epoch 10:\t23.041347087166763\n",
      "epoch 20:\t22.815533198437226\n",
      "epoch 30:\t22.603692476160468\n",
      "epoch 40:\t22.374366857126894\n",
      "epoch 50:\t22.140637718632778\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.71432944500629\n",
      "Epoch 25: 0.005269735050367542\n",
      "Epoch 50: 0.0025028521668108233\n",
      "Epoch 75: 0.0016617323160962119\n",
      "Epoch 100: 0.0012518985148484976\n",
      "Epoch 125: 0.0010082903701803454\n",
      "Epoch 150: 0.0008463903871268031\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 439.8830053806305\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.840406400134363\n",
      "epoch 10:\t22.72766914257078\n",
      "epoch 20:\t22.658416132407698\n",
      "epoch 30:\t22.54305212473543\n",
      "epoch 40:\t22.42056184173374\n",
      "epoch 50:\t22.30306192821717\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.78448225529148\n",
      "Epoch 25: 0.007975178076342742\n",
      "Epoch 50: 0.0036708642078326355\n",
      "Epoch 75: 0.0024277629318750116\n",
      "Epoch 100: 0.0018300123113348468\n",
      "Epoch 125: 0.0014766624202360245\n",
      "Epoch 150: 0.0012424565322869687\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 266.7939364910126\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.458397486303152\n",
      "epoch 10:\t23.240903879574304\n",
      "epoch 20:\t22.990370546352676\n",
      "epoch 30:\t22.664957263954367\n",
      "epoch 40:\t22.424840915403752\n",
      "epoch 50:\t22.176649467270998\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.2101496976152704\n",
      "Epoch 25: 0.007831579747230429\n",
      "Epoch 50: 0.0027638932735414507\n",
      "Epoch 75: 0.001810474767241198\n",
      "Epoch 100: 0.0013734394252381652\n",
      "Epoch 125: 0.0011176697731232622\n",
      "Epoch 150: 0.0009480677303345992\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 303.39286494255066\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.65569116525012\n",
      "epoch 10:\t21.371186313643847\n",
      "epoch 20:\t21.22903923514204\n",
      "epoch 30:\t21.111701516639307\n",
      "epoch 40:\t20.996300321552802\n",
      "epoch 50:\t20.889397900413606\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.7563248882520366\n",
      "Epoch 25: 0.005283297406773524\n",
      "Epoch 50: 0.0026396737947824806\n",
      "Epoch 75: 0.0017952338769832556\n",
      "Epoch 100: 0.0013727945692252471\n",
      "Epoch 125: 0.0011173062951064956\n",
      "Epoch 150: 0.0009453735436675336\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 324.26872301101685\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.51922074866193\n",
      "epoch 10:\t20.411897298435374\n",
      "epoch 20:\t20.293958918303794\n",
      "epoch 30:\t20.20127079392801\n",
      "epoch 40:\t20.09803963424103\n",
      "epoch 50:\t19.99175866254206\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.682236247484737\n",
      "Epoch 25: 0.008393300408211943\n",
      "Epoch 50: 0.0036676232532250187\n",
      "Epoch 75: 0.002399088397570205\n",
      "Epoch 100: 0.0017987446927263055\n",
      "Epoch 125: 0.001445817800147302\n",
      "Epoch 150: 0.001212388649158878\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 337.45028948783875\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.923820454347645\n",
      "epoch 10:\t20.725307990978603\n",
      "epoch 20:\t20.57279685246638\n",
      "epoch 30:\t20.458851793995706\n",
      "epoch 40:\t20.32550417341708\n",
      "epoch 50:\t20.227381980047614\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.940578348661352\n",
      "Epoch 25: 0.007114570490658397\n",
      "Epoch 50: 0.003445340299008938\n",
      "Epoch 75: 0.002329678197014366\n",
      "Epoch 100: 0.0017787804336665597\n",
      "Epoch 125: 0.001447265470067123\n",
      "Epoch 150: 0.001224628769147826\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 368.565794467926\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t27.58607593496331\n",
      "epoch 10:\t27.182146223035375\n",
      "epoch 20:\t26.80172055065459\n",
      "epoch 30:\t26.392625142462304\n",
      "epoch 40:\t26.064669483753885\n",
      "epoch 50:\t25.7874527559345\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.7634749916188768\n",
      "Epoch 25: 0.0076997294071989636\n",
      "Epoch 50: 0.0033847177148179797\n",
      "Epoch 75: 0.0022627475563197904\n",
      "Epoch 100: 0.0017259672002240731\n",
      "Epoch 125: 0.0014067053084260298\n",
      "Epoch 150: 0.0011932818208849267\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 380.22469544410706\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.31159176318086\n",
      "epoch 10:\t21.12054531201536\n",
      "epoch 20:\t21.06795373836581\n",
      "epoch 30:\t20.9633640609961\n",
      "epoch 40:\t20.85744323944145\n",
      "epoch 50:\t20.72748883003543\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.8755643770221107\n",
      "Epoch 25: 0.008947385034043185\n",
      "Epoch 50: 0.0034603598483261607\n",
      "Epoch 75: 0.0022297904001065366\n",
      "Epoch 100: 0.0016674158525629102\n",
      "Epoch 125: 0.001341241446827791\n",
      "Epoch 150: 0.0011268940423803094\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 405.5441334247589\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.421385923636088\n",
      "epoch 10:\t22.26281990422637\n",
      "epoch 20:\t22.124764165781556\n",
      "epoch 30:\t22.000924773607043\n",
      "epoch 40:\t21.877927393328395\n",
      "epoch 50:\t21.77999184626852\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.711227793063346\n",
      "Epoch 25: 0.004659973546139619\n",
      "Epoch 50: 0.0022946702745019524\n",
      "Epoch 75: 0.0015513461655014091\n",
      "Epoch 100: 0.0011831445186872565\n",
      "Epoch 125: 0.0009618532739573133\n",
      "Epoch 150: 0.0008135254353022598\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 412.2293553352356\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.483424296325254\n",
      "epoch 10:\t21.32296445453031\n",
      "epoch 20:\t21.208561790741996\n",
      "epoch 30:\t21.07646651660164\n",
      "epoch 40:\t20.92304640529438\n",
      "epoch 50:\t20.75964281406563\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.5765765652890162\n",
      "Epoch 25: 0.00343464729970183\n",
      "Epoch 50: 0.0017249583785169116\n",
      "Epoch 75: 0.0011724351114286722\n",
      "Epoch 100: 0.0008957068511127861\n",
      "Epoch 125: 0.0007284170601918034\n",
      "Epoch 150: 0.0006159124343828377\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 444.66883993148804\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t26.179839302784472\n",
      "epoch 10:\t25.576090774997734\n",
      "epoch 20:\t25.205913497963767\n",
      "epoch 30:\t24.991913288263383\n",
      "epoch 40:\t24.741204662997685\n",
      "epoch 50:\t24.442659178674234\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.3928176827891425\n",
      "Epoch 25: 0.0045135437331470405\n",
      "Epoch 50: 0.002266400198116571\n",
      "Epoch 75: 0.0015422260070169311\n",
      "Epoch 100: 0.0011797430327651454\n",
      "Epoch 125: 0.0009606135064677801\n",
      "Epoch 150: 0.0008132255657110363\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 465.2196583747864\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.29926222026892\n",
      "epoch 10:\t21.11488588670334\n",
      "epoch 20:\t20.975203584096853\n",
      "epoch 30:\t20.8222107088519\n",
      "epoch 40:\t20.699779291364077\n",
      "epoch 50:\t20.598483994136803\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.3223790350604925\n",
      "Epoch 25: 0.006836556179405306\n",
      "Epoch 50: 0.0030808352925388053\n",
      "Epoch 75: 0.002042173476105414\n",
      "Epoch 100: 0.001545674896442506\n",
      "Epoch 125: 0.001252033517398972\n",
      "Epoch 150: 0.0010569401463085754\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 290.41162514686584\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.873928573539683\n",
      "epoch 10:\t20.973121449008314\n",
      "epoch 20:\t20.92089117847015\n",
      "epoch 30:\t20.770119413460357\n",
      "epoch 40:\t20.60951863435732\n",
      "epoch 50:\t20.41223513713303\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.506060616646376\n",
      "Epoch 25: 0.005318843104671108\n",
      "Epoch 50: 0.0025992306247313007\n",
      "Epoch 75: 0.0017564939765909078\n",
      "Epoch 100: 0.0013388524918174956\n",
      "Epoch 125: 0.0010874219554021162\n",
      "Epoch 150: 0.0009186486022665955\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 328.465763092041\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.61454244011288\n",
      "epoch 10:\t24.165791871198095\n",
      "epoch 20:\t23.898565013816025\n",
      "epoch 30:\t23.507805629638888\n",
      "epoch 40:\t23.217714559631055\n",
      "epoch 50:\t22.950587830804373\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.8024391887044589\n",
      "Epoch 25: 0.004980292215989616\n",
      "Epoch 50: 0.0024091071341528136\n",
      "Epoch 75: 0.0016343711622303439\n",
      "Epoch 100: 0.0012526584923488843\n",
      "Epoch 125: 0.0010230263031807305\n",
      "Epoch 150: 0.0008687115281633649\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 349.7385263442993\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.57811228164099\n",
      "epoch 10:\t19.531581143426457\n",
      "epoch 20:\t19.454097343032256\n",
      "epoch 30:\t19.33968535376342\n",
      "epoch 40:\t19.26712758466028\n",
      "epoch 50:\t19.189677536941254\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.0452415409938633\n",
      "Epoch 25: 0.009580484759180764\n",
      "Epoch 50: 0.0038255338946474433\n",
      "Epoch 75: 0.002465984767284876\n",
      "Epoch 100: 0.001841062652818794\n",
      "Epoch 125: 0.001478504478329309\n",
      "Epoch 150: 0.001240443892846445\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 373.60481214523315\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.44380365005841\n",
      "epoch 10:\t22.18118133211857\n",
      "epoch 20:\t21.870520614361233\n",
      "epoch 30:\t21.564627985445398\n",
      "epoch 40:\t21.327189328690753\n",
      "epoch 50:\t21.158644859832915\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.3630839237781767\n",
      "Epoch 25: 0.0322486193987614\n",
      "Epoch 50: 0.006470660646891701\n",
      "Epoch 75: 0.0036925446651192334\n",
      "Epoch 100: 0.0026591227651052425\n",
      "Epoch 125: 0.0021045947864983343\n",
      "Epoch 150: 0.001754366663547747\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 394.7416350841522\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.067191727425442\n",
      "epoch 10:\t21.85072824707176\n",
      "epoch 20:\t21.645704386715828\n",
      "epoch 30:\t21.48283035081787\n",
      "epoch 40:\t21.342134753992667\n",
      "epoch 50:\t21.225930878568835\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 4.664895919697119\n",
      "Epoch 25: 0.011087983155647407\n",
      "Epoch 50: 0.004629468243976476\n",
      "Epoch 75: 0.0030184831242522137\n",
      "Epoch 100: 0.002271065301151509\n",
      "Epoch 125: 0.0018353244462623764\n",
      "Epoch 150: 0.001548141431008787\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 424.0806291103363\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.83735857049623\n",
      "epoch 10:\t21.6966712991304\n",
      "epoch 20:\t21.55373292595226\n",
      "epoch 30:\t21.3729331266656\n",
      "epoch 40:\t21.21196052355603\n",
      "epoch 50:\t21.056937233283783\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.225473312827206\n",
      "Epoch 25: 0.004561033065883681\n",
      "Epoch 50: 0.0023614989326534563\n",
      "Epoch 75: 0.0016313918210705517\n",
      "Epoch 100: 0.0012597303469943078\n",
      "Epoch 125: 0.0010324025330400927\n",
      "Epoch 150: 0.0008781099855099228\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 445.601202249527\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.208023393138784\n",
      "epoch 10:\t22.053769889940078\n",
      "epoch 20:\t21.960512654793757\n",
      "epoch 30:\t21.822568038324405\n",
      "epoch 40:\t21.68941615194226\n",
      "epoch 50:\t21.614434913131582\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.4257325802440945\n",
      "Epoch 25: 0.006749673141193095\n",
      "Epoch 50: 0.002956279186164718\n",
      "Epoch 75: 0.001948320762639671\n",
      "Epoch 100: 0.0014700651116590457\n",
      "Epoch 125: 0.0011878640882593396\n",
      "Epoch 150: 0.001000574793070857\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 467.4432773590088\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.620640634296038\n",
      "epoch 10:\t21.464633082677484\n",
      "epoch 20:\t21.327736501397787\n",
      "epoch 30:\t21.21000642787328\n",
      "epoch 40:\t21.12543875600614\n",
      "epoch 50:\t21.040567549076805\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.7863706957322085\n",
      "Epoch 25: 0.004506047688097083\n",
      "Epoch 50: 0.0021519218612262884\n",
      "Epoch 75: 0.0014379986099198755\n",
      "Epoch 100: 0.0010880538694894388\n",
      "Epoch 125: 0.0008790506792504447\n",
      "Epoch 150: 0.0007396408634628409\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 483.75329208374023\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.21576054852788\n",
      "epoch 10:\t23.834616366594496\n",
      "epoch 20:\t23.634668806716583\n",
      "epoch 30:\t23.389665809572435\n",
      "epoch 40:\t23.172122843374204\n",
      "epoch 50:\t22.973913730877378\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.7932184366998967\n",
      "Epoch 25: 0.004098654616596313\n",
      "Epoch 50: 0.0020359123083156837\n",
      "Epoch 75: 0.0013854775539358676\n",
      "Epoch 100: 0.001060535484453453\n",
      "Epoch 125: 0.0008639618806689597\n",
      "Epoch 150: 0.0007315597144861918\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 506.7841682434082\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.480410300589888\n",
      "epoch 10:\t19.270216239252143\n",
      "epoch 20:\t19.181743317136444\n",
      "epoch 30:\t19.121840605112464\n",
      "epoch 40:\t19.06802197361673\n",
      "epoch 50:\t19.00808566281007\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.9506104756965141\n",
      "Epoch 25: 0.006761239584486656\n",
      "Epoch 50: 0.0029818342097444528\n",
      "Epoch 75: 0.001953693484311047\n",
      "Epoch 100: 0.0014659981608075418\n",
      "Epoch 125: 0.0011792213520753388\n",
      "Epoch 150: 0.0009896156144535853\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 329.0379192829132\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.14537635556963\n",
      "epoch 10:\t22.02428544297504\n",
      "epoch 20:\t21.85806883260969\n",
      "epoch 30:\t21.583794913698213\n",
      "epoch 40:\t21.377077305604647\n",
      "epoch 50:\t21.225253482167155\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.3941687764051753\n",
      "Epoch 25: 0.0068307089400991144\n",
      "Epoch 50: 0.0028415753545386734\n",
      "Epoch 75: 0.001835745346423484\n",
      "Epoch 100: 0.0013667696134449078\n",
      "Epoch 125: 0.001093445452858399\n",
      "Epoch 150: 0.0009138176779571332\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 353.3493106365204\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.197007563022478\n",
      "epoch 10:\t20.973039906864724\n",
      "epoch 20:\t20.840872481148704\n",
      "epoch 30:\t20.746607573113938\n",
      "epoch 40:\t20.65671249527124\n",
      "epoch 50:\t20.573054197491707\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.793341795193364\n",
      "Epoch 25: 0.0071383617300533955\n",
      "Epoch 50: 0.003169629574181511\n",
      "Epoch 75: 0.0020827342965619383\n",
      "Epoch 100: 0.001566120304488051\n",
      "Epoch 125: 0.0012620310666350857\n",
      "Epoch 150: 0.001060850461573082\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 382.7691419124603\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.737049829509935\n",
      "epoch 10:\t23.342088708662683\n",
      "epoch 20:\t22.962459100591115\n",
      "epoch 30:\t22.62586613573776\n",
      "epoch 40:\t22.312403739551865\n",
      "epoch 50:\t22.024203246056192\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.0929574653105982\n",
      "Epoch 25: 0.004528576672762073\n",
      "Epoch 50: 0.0022926927458162237\n",
      "Epoch 75: 0.0015756926622223129\n",
      "Epoch 100: 0.001214070513391502\n",
      "Epoch 125: 0.00099370006400559\n",
      "Epoch 150: 0.0008443876020181528\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 399.6836562156677\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.28239025882685\n",
      "epoch 10:\t21.901378600496578\n",
      "epoch 20:\t21.547192228849006\n",
      "epoch 30:\t21.289890543279974\n",
      "epoch 40:\t21.135101648189934\n",
      "epoch 50:\t21.015108987342487\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.537480533704224\n",
      "Epoch 25: 0.008231209994393723\n",
      "Epoch 50: 0.003304558828085909\n",
      "Epoch 75: 0.002142845705345123\n",
      "Epoch 100: 0.0016035684723513337\n",
      "Epoch 125: 0.0012887353014444285\n",
      "Epoch 150: 0.0010812158844498753\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 422.06435465812683\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.253703588989598\n",
      "epoch 10:\t21.099010866535025\n",
      "epoch 20:\t20.986232313193504\n",
      "epoch 30:\t20.835127505129385\n",
      "epoch 40:\t20.663269739148717\n",
      "epoch 50:\t20.525975899517746\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.6149101901210134\n",
      "Epoch 25: 0.0036736357066465774\n",
      "Epoch 50: 0.0017842374687513315\n",
      "Epoch 75: 0.001206550868734701\n",
      "Epoch 100: 0.0009209337034794187\n",
      "Epoch 125: 0.0007490068757029281\n",
      "Epoch 150: 0.0006335547715515279\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 442.0882349014282\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t25.280431870318672\n",
      "epoch 10:\t24.662556515710882\n",
      "epoch 20:\t24.239630345665656\n",
      "epoch 30:\t23.796720164510795\n",
      "epoch 40:\t23.5056298227452\n",
      "epoch 50:\t23.27857060345561\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.6935389807063561\n",
      "Epoch 25: 0.0037294238250203545\n",
      "Epoch 50: 0.0018301065272088922\n",
      "Epoch 75: 0.001239415518203365\n",
      "Epoch 100: 0.0009451291102197645\n",
      "Epoch 125: 0.0007674239758172187\n",
      "Epoch 150: 0.0006479307032880614\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 462.37775564193726\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.31745512608716\n",
      "epoch 10:\t22.143410409380298\n",
      "epoch 20:\t22.087596483365097\n",
      "epoch 30:\t22.014954046036813\n",
      "epoch 40:\t21.93852485032485\n",
      "epoch 50:\t21.85395940992021\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.0587220238619213\n",
      "Epoch 25: 0.0037490824749823277\n",
      "Epoch 50: 0.0018776769960627741\n",
      "Epoch 75: 0.0012764910312644583\n",
      "Epoch 100: 0.0009752389275076568\n",
      "Epoch 125: 0.0007929442402851879\n",
      "Epoch 150: 0.0006702364178894355\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 489.4837996959686\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.106175220475524\n",
      "epoch 10:\t21.96101478177459\n",
      "epoch 20:\t21.7707268061975\n",
      "epoch 30:\t21.608824572406398\n",
      "epoch 40:\t21.496105958081085\n",
      "epoch 50:\t21.40459548220509\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.8767804274696853\n",
      "Epoch 25: 0.002500961563595113\n",
      "Epoch 50: 0.0012983104447979387\n",
      "Epoch 75: 0.000895135414429764\n",
      "Epoch 100: 0.000689612027524421\n",
      "Epoch 125: 0.0005639379138320189\n",
      "Epoch 150: 0.00047871735271302787\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 511.40969157218933\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.410176788443167\n",
      "epoch 10:\t23.872874250352744\n",
      "epoch 20:\t23.581171205706834\n",
      "epoch 30:\t23.35619177288651\n",
      "epoch 40:\t23.11645783874406\n",
      "epoch 50:\t22.877196906335122\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.8826881760934866\n",
      "Epoch 25: 0.0035599962271792196\n",
      "Epoch 50: 0.0017697080837079432\n",
      "Epoch 75: 0.001201036624417347\n",
      "Epoch 100: 0.0009175641627404349\n",
      "Epoch 125: 0.0007465311871061263\n",
      "Epoch 150: 0.0006316155762591206\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 540.7312471866608\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.32506725036926\n",
      "epoch 10:\t22.948120082494345\n",
      "epoch 20:\t22.67588085175165\n",
      "epoch 30:\t22.419216691680994\n",
      "epoch 40:\t22.21951075020728\n",
      "epoch 50:\t22.041202730160343\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.357492501934542\n",
      "Epoch 25: 0.005289627370135956\n",
      "Epoch 50: 0.0024846411058879986\n",
      "Epoch 75: 0.001662530785728854\n",
      "Epoch 100: 0.0012619977706216795\n",
      "Epoch 125: 0.0010229743627793073\n",
      "Epoch 150: 0.0008633910558913798\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 362.58656549453735\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t25.773203774062928\n",
      "epoch 10:\t25.39464151106916\n",
      "epoch 20:\t24.974959100055656\n",
      "epoch 30:\t24.696571485576015\n",
      "epoch 40:\t24.458980812377412\n",
      "epoch 50:\t24.262749914963138\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.188106651350972\n",
      "Epoch 25: 0.016021883354080963\n",
      "Epoch 50: 0.0031906983974953743\n",
      "Epoch 75: 0.0018693362858012452\n",
      "Epoch 100: 0.0013473847658086267\n",
      "Epoch 125: 0.001062102685673067\n",
      "Epoch 150: 0.0008807185465880609\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 381.96713972091675\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.407852993520674\n",
      "epoch 10:\t22.19765419535068\n",
      "epoch 20:\t22.053118868649726\n",
      "epoch 30:\t21.88080576246812\n",
      "epoch 40:\t21.693944213837582\n",
      "epoch 50:\t21.502920229378386\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.9172130795955686\n",
      "Epoch 25: 0.008242695693232441\n",
      "Epoch 50: 0.0028673337067190124\n",
      "Epoch 75: 0.0018431626432387812\n",
      "Epoch 100: 0.0013780823806670132\n",
      "Epoch 125: 0.0011080332435870245\n",
      "Epoch 150: 0.0009302892208002196\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 416.12929034233093\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t26.23465658431771\n",
      "epoch 10:\t25.865942095217928\n",
      "epoch 20:\t25.50771169969747\n",
      "epoch 30:\t25.20547740437312\n",
      "epoch 40:\t24.940668094720536\n",
      "epoch 50:\t24.701110492119046\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.6232880678609947\n",
      "Epoch 25: 0.008403271454121888\n",
      "Epoch 50: 0.0033914002422520614\n",
      "Epoch 75: 0.002166829298293964\n",
      "Epoch 100: 0.0016044231710331974\n",
      "Epoch 125: 0.001279859924157949\n",
      "Epoch 150: 0.001068014958577013\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 443.16038942337036\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.20188350251103\n",
      "epoch 10:\t21.184679665467165\n",
      "epoch 20:\t21.061031887616757\n",
      "epoch 30:\t20.962291531255946\n",
      "epoch 40:\t20.902442518636207\n",
      "epoch 50:\t20.8387017272986\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.100452511768235\n",
      "Epoch 25: 0.005772479155760136\n",
      "Epoch 50: 0.002741731791377658\n",
      "Epoch 75: 0.0018401175485964164\n",
      "Epoch 100: 0.0013989497672836089\n",
      "Epoch 125: 0.0011349342187632568\n",
      "Epoch 150: 0.0009582731701454707\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 453.88634300231934\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.233396992311647\n",
      "epoch 10:\t19.136532771019983\n",
      "epoch 20:\t19.039107660408487\n",
      "epoch 30:\t18.964745874229916\n",
      "epoch 40:\t18.908266651539336\n",
      "epoch 50:\t18.8680766258808\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.0242023599048307\n",
      "Epoch 25: 0.004200307042197463\n",
      "Epoch 50: 0.0021085711022199366\n",
      "Epoch 75: 0.0014359210522426307\n",
      "Epoch 100: 0.001099250021232709\n",
      "Epoch 125: 0.0008955520042584831\n",
      "Epoch 150: 0.0007583601326421165\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 475.07741618156433\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.23607595117543\n",
      "epoch 10:\t23.03516256578029\n",
      "epoch 20:\t22.871645735345645\n",
      "epoch 30:\t22.68683516354226\n",
      "epoch 40:\t22.51458901428786\n",
      "epoch 50:\t22.355764833754638\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.7401569580610576\n",
      "Epoch 25: 0.00354425683439876\n",
      "Epoch 50: 0.001807268299340847\n",
      "Epoch 75: 0.0012367929765194055\n",
      "Epoch 100: 0.0009484570683868335\n",
      "Epoch 125: 0.000773110689861949\n",
      "Epoch 150: 0.0006546736124327697\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 502.40260910987854\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.52443297041617\n",
      "epoch 10:\t22.371771648213887\n",
      "epoch 20:\t22.166387939094676\n",
      "epoch 30:\t21.976266623127916\n",
      "epoch 40:\t21.794654725466525\n",
      "epoch 50:\t21.639506909476616\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.9845161505359711\n",
      "Epoch 25: 0.0029758075678360946\n",
      "Epoch 50: 0.0014567049426783736\n",
      "Epoch 75: 0.0009944317526608731\n",
      "Epoch 100: 0.0007643288219724917\n",
      "Epoch 125: 0.0006249471765346054\n",
      "Epoch 150: 0.00053083675341374\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 518.047669172287\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.509238814379973\n",
      "epoch 10:\t22.39081293116903\n",
      "epoch 20:\t22.264130199356277\n",
      "epoch 30:\t22.160243785525306\n",
      "epoch 40:\t22.05777670772466\n",
      "epoch 50:\t21.953472981300134\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.1920903385275101\n",
      "Epoch 25: 0.0027584391851697746\n",
      "Epoch 50: 0.001413999952510124\n",
      "Epoch 75: 0.0009679405087190838\n",
      "Epoch 100: 0.0007420950841853303\n",
      "Epoch 125: 0.0006047076177237997\n",
      "Epoch 150: 0.0005119090998462969\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 527.7090079784393\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.078674286206486\n",
      "epoch 10:\t21.045784127123103\n",
      "epoch 20:\t21.000628341071803\n",
      "epoch 30:\t20.94305857595799\n",
      "epoch 40:\t20.81600526490899\n",
      "epoch 50:\t20.70244733744285\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.6150417969505482\n",
      "Epoch 25: 0.0033072562107956415\n",
      "Epoch 50: 0.0016942974460660942\n",
      "Epoch 75: 0.001160200121045973\n",
      "Epoch 100: 0.0008898304969048196\n",
      "Epoch 125: 0.0007253599301384542\n",
      "Epoch 150: 0.0006142749163768871\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 559.8425574302673\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "robustness = robustness_test(df_full)\n",
    "pickle.dump(robustness, open(\"../results/robustness.results\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grouping labels\n",
    "### label = 1   if review_score > 7\n",
    "### label = 0   if 7 >= review_score >= 4\n",
    "### label = -1  if review_score < 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_labels(x):\n",
    "    if x>7:\n",
    "        return 1\n",
    "    elif x>=4:\n",
    "        return 0\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>i love science fiction and i hate superheroes ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>-800777728</td>\n",
       "      <td>the movie is absolutely incredible all the per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>in a cinematic era dominated by reboots and mi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>movie review on rise of the planet of the apes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>-1018312192</td>\n",
       "      <td>during experiments to find a cure for alzheime...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language    Movie_ID                                             Review  \\\n",
       "0       en  -800777728  i love science fiction and i hate superheroes ...   \n",
       "1       en  -800777728  the movie is absolutely incredible all the per...   \n",
       "2       en -1018312192  in a cinematic era dominated by reboots and mi...   \n",
       "3       en -1018312192  movie review on rise of the planet of the apes...   \n",
       "4       en -1018312192  during experiments to find a cure for alzheime...   \n",
       "\n",
       "   Score  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_trilabels = deepcopy(df_full)\n",
    "df_full_trilabels[\"Score\"] = df_full_trilabels.Score.apply(group_labels)\n",
    "df_full_trilabels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Language  Movie_ID  Review\n",
       "Score                            \n",
       "-1           64        64      64\n",
       " 0          220       220     220\n",
       " 1          716       716     716"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_trilabels.groupby(\"Score\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language    0\n",
       "Movie_ID    0\n",
       "Score       0\n",
       "rev_vec     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tronly_test_raw_trilabels = df_full_trilabels[-100:]\n",
    "tronly_test_trilabels = preprocess_data(tronly_test_raw_trilabels)\n",
    "df_trilabels = df_full_trilabels[:-100]\n",
    "tronly_test_trilabels[tronly_test_trilabels.Language==\"en\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial:\t1\n",
      "K:\t1\n",
      "epoch 0:\t22.650155571017667\n",
      "epoch 10:\t22.073118889791676\n",
      "epoch 20:\t21.82168886420062\n",
      "epoch 30:\t21.582884354284335\n",
      "epoch 40:\t21.34637720791348\n",
      "epoch 50:\t21.112244486388292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t1\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.711111  0.591053             0.591053      0.618290\n",
      "F1 Tr. only       0.711111  0.706145             0.701124      0.668459\n",
      "F1 Train          0.584560  0.604176             0.593118      0.996289\n",
      "Pred.Tra. Time    1.707660  0.393944             0.057058      0.110873\n",
      "Test              0.888889  0.888889             0.888889      0.881481\n",
      "Testing Time      0.008877  0.000282             0.000124      0.105226\n",
      "Tr. Only          0.923333  0.920000             0.916667      0.883333\n",
      "Tr.Test Time      0.015710  0.000294             0.000123      0.105094\n",
      "Train             0.878601  0.881481             0.879835      0.998354\n",
      "Training Time    12.685263  0.001345             0.000767      0.102662\n",
      "\n",
      "This fold took: 14.613837003707886 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t2\n",
      "epoch 0:\t22.288924771394065\n",
      "epoch 10:\t21.602296069315912\n",
      "epoch 20:\t21.32415641307116\n",
      "epoch 30:\t21.127078974128935\n",
      "epoch 40:\t20.99560946572786\n",
      "epoch 50:\t20.830319485990717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t2\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.711111  0.491156             0.491156      0.522780\n",
      "F1 Tr. only       0.711111  0.728007             0.701124      0.674265\n",
      "F1 Train          0.595936  0.623656             0.610103      0.993807\n",
      "Pred.Tra. Time    1.664749  0.289395             0.057090      0.111122\n",
      "Test              0.837037  0.837037             0.837037      0.829630\n",
      "Testing Time      0.008778  0.000287             0.000124      0.105061\n",
      "Tr. Only          0.923333  0.923333             0.916667      0.890000\n",
      "Tr.Test Time      0.013137  0.000301             0.000124      0.105001\n",
      "Train             0.884362  0.888477             0.886420      0.997531\n",
      "Training Time    12.272733  0.001343             0.000684      0.105668\n",
      "\n",
      "This fold took: 14.148903131484985 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t3\n",
      "epoch 0:\t20.002111430148986\n",
      "epoch 10:\t19.379256656984044\n",
      "epoch 20:\t18.853666409482347\n",
      "epoch 30:\t18.424730668675167\n",
      "epoch 40:\t18.09115768799444\n",
      "epoch 50:\t17.864346846524498\n",
      "\n",
      "K:\t3\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.711111  0.556586             0.556586      0.567148\n",
      "F1 Tr. only       0.711111  0.741472             0.701124      0.669286\n",
      "F1 Train          0.587804  0.617918             0.599170      0.990111\n",
      "Pred.Tra. Time    1.634997  0.457150             0.052774      0.123620\n",
      "Test              0.877778  0.874074             0.874074      0.859259\n",
      "Testing Time      0.009024  0.000289             0.000121      0.105053\n",
      "Tr. Only          0.923333  0.923333             0.916667      0.886667\n",
      "Tr.Test Time      0.013751  0.000290             0.000126      0.105129\n",
      "Train             0.879835  0.884774             0.881481      0.995885\n",
      "Training Time    14.533818  0.001337             0.000696      0.106053\n",
      "\n",
      "This fold took: 16.453377962112427 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t4\n",
      "epoch 0:\t19.907020039989774\n",
      "epoch 10:\t19.5234102587636\n",
      "epoch 20:\t19.351872055067073\n",
      "epoch 30:\t19.218439605607323\n",
      "epoch 40:\t19.09873810360405\n",
      "epoch 50:\t18.980468580576247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t4\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.711111  0.635386             0.660374      0.620592\n",
      "F1 Tr. only       0.711111  0.728007             0.706145      0.685266\n",
      "F1 Train          0.579703  0.593836             0.591059      0.995053\n",
      "Pred.Tra. Time    1.665494  0.344976             0.052073      0.111387\n",
      "Test              0.888889  0.888889             0.892593      0.870370\n",
      "Testing Time      0.008560  0.000298             0.000121      0.105182\n",
      "Tr. Only          0.923333  0.923333             0.920000      0.893333\n",
      "Tr.Test Time      0.013078  0.000293             0.000125      0.105642\n",
      "Train             0.878601  0.880658             0.880247      0.998354\n",
      "Training Time    13.276147  0.001330             0.000633      0.106190\n",
      "\n",
      "This fold took: 15.169223546981812 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t5\n",
      "epoch 0:\t22.222981249684864\n",
      "epoch 10:\t21.555949972817185\n",
      "epoch 20:\t20.937196327080965\n",
      "epoch 30:\t20.483172210113846\n",
      "epoch 40:\t20.089431292801827\n",
      "epoch 50:\t19.64094013044043\n",
      "\n",
      "K:\t5\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.711111  0.576471             0.571053      0.555408\n",
      "F1 Tr. only       0.711111  0.711111             0.701124      0.664327\n",
      "F1 Train          0.586181  0.589061             0.594743      0.988838\n",
      "Pred.Tra. Time    1.666732  0.127554             0.051814      0.110841\n",
      "Test              0.877778  0.877778             0.874074      0.844444\n",
      "Testing Time      0.008585  0.000280             0.000122      0.105059\n",
      "Tr. Only          0.923333  0.923333             0.916667      0.890000\n",
      "Tr.Test Time      0.013031  0.000289             0.000125      0.105019\n",
      "Train             0.879835  0.880247             0.881070      0.995473\n",
      "Training Time    10.658969  0.001344             0.000686      0.103199\n",
      "\n",
      "This fold took: 12.544023036956787 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t6\n",
      "epoch 0:\t20.36698679279655\n",
      "epoch 10:\t19.97698848592996\n",
      "epoch 20:\t19.439983593508543\n",
      "epoch 30:\t18.958855478047262\n",
      "epoch 40:\t18.565424371641264\n",
      "epoch 50:\t18.18903334387512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t6\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.711111  0.505105             0.499773      0.600453\n",
      "F1 Tr. only       0.711111  0.711111             0.701124      0.718570\n",
      "F1 Train          0.594307  0.608464             0.605685      0.995055\n",
      "Pred.Tra. Time    1.651813  0.268831             0.057167      0.110991\n",
      "Test              0.855556  0.855556             0.851852      0.866667\n",
      "Testing Time      0.008681  0.000283             0.000119      0.105078\n",
      "Tr. Only          0.923333  0.923333             0.916667      0.903333\n",
      "Tr.Test Time      0.013058  0.000296             0.000124      0.105011\n",
      "Train             0.882305  0.884362             0.883951      0.997942\n",
      "Training Time    10.295485  0.001358             0.000661      0.103498\n",
      "\n",
      "This fold took: 12.149736881256104 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t7\n",
      "epoch 0:\t25.244865522482666\n",
      "epoch 10:\t25.357449528385988\n",
      "epoch 20:\t24.999167771879318\n",
      "epoch 30:\t24.616329202458672\n",
      "epoch 40:\t24.24634632948812\n",
      "epoch 50:\t23.87739188421547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t7\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.711111  0.505105             0.529875      0.511895\n",
      "F1 Tr. only       0.711111  0.706145             0.706145      0.715572\n",
      "F1 Train          0.594307  0.600049             0.597191      0.992593\n",
      "Pred.Tra. Time    1.632726  0.180760             0.055703      0.110774\n",
      "Test              0.851852  0.851852             0.855556      0.848148\n",
      "Testing Time      0.008614  0.000278             0.000119      0.104759\n",
      "Tr. Only          0.923333  0.920000             0.920000      0.910000\n",
      "Tr.Test Time      0.014314  0.000295             0.000123      0.105585\n",
      "Train             0.882716  0.883539             0.883128      0.997531\n",
      "Training Time    10.495215  0.001314             0.000646      0.103481\n",
      "\n",
      "This fold took: 12.35408902168274 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t8\n",
      "epoch 0:\t19.18732006793987\n",
      "epoch 10:\t18.71293921984405\n",
      "epoch 20:\t18.4857610301639\n",
      "epoch 30:\t18.298757531374164\n",
      "epoch 40:\t18.109904032480284\n",
      "epoch 50:\t17.891675775991185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t8\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.711111  0.773226             0.773226      0.737905\n",
      "F1 Tr. only       0.711111  0.706145             0.706145      0.699060\n",
      "F1 Train          0.565198  0.576527             0.579654      0.992586\n",
      "Pred.Tra. Time    1.638776  0.180944             0.055472      0.110960\n",
      "Test              0.940741  0.940741             0.940741      0.903704\n",
      "Testing Time      0.008738  0.000287             0.000120      0.104914\n",
      "Tr. Only          0.923333  0.920000             0.920000      0.893333\n",
      "Tr.Test Time      0.013122  0.000291             0.000123      0.105670\n",
      "Train             0.872840  0.874486             0.875309      0.996708\n",
      "Training Time    10.552996  0.001330             0.000642      0.102982\n",
      "\n",
      "This fold took: 12.421394348144531 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t9\n",
      "epoch 0:\t23.137530649032247\n",
      "epoch 10:\t22.945788681893067\n",
      "epoch 20:\t22.711957715326168\n",
      "epoch 30:\t22.49708290984199\n",
      "epoch 40:\t22.32512547120508\n",
      "epoch 50:\t22.210690359185495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K:\t9\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.711111  0.519165             0.519165      0.502956\n",
      "F1 Tr. only       0.711111  0.706145             0.701124      0.703801\n",
      "F1 Train          0.592680  0.604056             0.606836      0.993821\n",
      "Pred.Tra. Time    1.591599  0.164976             0.056133      0.110764\n",
      "Test              0.855556  0.855556             0.855556      0.837037\n",
      "Testing Time      0.008438  0.000278             0.000117      0.105282\n",
      "Tr. Only          0.923333  0.920000             0.916667      0.900000\n",
      "Tr.Test Time      0.013092  0.000286             0.000122      0.105204\n",
      "Train             0.882305  0.883951             0.884362      0.997942\n",
      "Training Time    10.529876  0.001351             0.000651      0.103498\n",
      "\n",
      "This fold took: 12.372519731521606 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K:\t10\n",
      "epoch 0:\t20.549927871835465\n",
      "epoch 10:\t20.426777623843154\n",
      "epoch 20:\t20.339111426539663\n",
      "epoch 30:\t20.232817062020874\n",
      "epoch 40:\t20.130280554745102\n",
      "epoch 50:\t20.028899489201518\n",
      "\n",
      "K:\t10\n",
      "                DeepSelect       MLP  Logistic Regression  RandomForest\n",
      "F1 Test           0.711111  0.711111             0.711111      0.670287\n",
      "F1 Tr. only       0.711111  0.706145             0.706145      0.690952\n",
      "F1 Train          0.571632  0.591223             0.585746      0.995044\n",
      "Pred.Tra. Time    1.631185  0.302874             0.052995      0.110984\n",
      "Test              0.922222  0.922222             0.922222      0.885185\n",
      "Testing Time      0.008649  0.000288             0.000120      0.104853\n",
      "Tr. Only          0.923333  0.920000             0.920000      0.893333\n",
      "Tr.Test Time      0.013139  0.000287             0.000124      0.105101\n",
      "Train             0.874897  0.877778             0.876955      0.998354\n",
      "Training Time    10.629421  0.001322             0.000627      0.103517\n",
      "\n",
      "This fold took: 12.47294807434082 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "Average scores for trial 0\n",
      "                DeepSelect  Logistic Regression       MLP  RandomForest\n",
      "F1 Test           0.711111             0.590337  0.586436      0.590771\n",
      "F1 Tr. only       0.711111             0.703132  0.715043      0.688956\n",
      "F1 Train          0.585231             0.596330  0.600897      0.993320\n",
      "Pred.Tra. Time    1.648573             0.054828  0.271140      0.112232\n",
      "Test              0.879630             0.879259  0.879259      0.862593\n",
      "Testing Time      0.008694             0.000121  0.000285      0.105047\n",
      "Tr. Only          0.923333             0.918000  0.921667      0.894333\n",
      "Tr.Test Time      0.013543             0.000124  0.000292      0.105246\n",
      "Train             0.879630             0.881276  0.881975      0.997407\n",
      "Training Time    11.592992             0.000669  0.001337      0.104075\n",
      "------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Average of 1 trials\n",
      "                DeepSelect  Logistic Regression       MLP  RandomForest\n",
      "F1 Test           0.711111             0.590337  0.586436      0.590771\n",
      "F1 Tr. only       0.711111             0.703132  0.715043      0.688956\n",
      "F1 Train          0.585231             0.596330  0.600897      0.993320\n",
      "Pred.Tra. Time    1.648573             0.054828  0.271140      0.112232\n",
      "Test              0.879630             0.879259  0.879259      0.862593\n",
      "Testing Time      0.008694             0.000121  0.000285      0.105047\n",
      "Tr. Only          0.923333             0.918000  0.921667      0.894333\n",
      "Tr.Test Time      0.013543             0.000124  0.000292      0.105246\n",
      "Train             0.879630             0.881276  0.881975      0.997407\n",
      "Training Time    11.592992             0.000669  0.001337      0.104075\n"
     ]
    }
   ],
   "source": [
    "scores_tables_tri = eval_selectivewaves_regclass(df_trilabels, tronly_test_raw_trilabels)\n",
    "pickle.dump(scores_tables_tri, open(\"../results/batch_no_tf_tables_tri.results\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial:\t1\n",
      "K: \t1\n",
      "Epoch 0: 0.315561436039335\n",
      "Epoch 25: 0.00042994266900565475\n",
      "Epoch 50: 0.00022212025069337908\n",
      "Epoch 75: 0.00015223542093216225\n",
      "Epoch 100: 0.00011671745724591088\n",
      "Epoch 125: 9.507159175227304e-05\n",
      "Epoch 150: 8.04304753173226e-05\n",
      "Took: 192.23054766654968 for training\n",
      "Took: 377.1332776546478 for predicting 810 training instances\n",
      "Took: 43.681052446365356 for predicting 90 test instances\n",
      "Took: 45.09070563316345 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.591053  0.591053      0.618290\n",
      "F1 Tr. only       0.000000            0.701124  0.706145      0.668459\n",
      "F1 Train          0.000000            0.593118  0.604176      0.996289\n",
      "Pred.Tra. Time  377.133278            0.053318  0.401434      0.127310\n",
      "Test             -1.777778            0.888889  0.888889      0.881481\n",
      "Testing Time     43.681052            0.000093  0.000284      0.104870\n",
      "Tr. Only         -1.743333            0.916667  0.920000      0.883333\n",
      "Tr.Test Time     45.090706            0.000093  0.000299      0.105671\n",
      "Train            -1.787654            0.879835  0.881481      0.998354\n",
      "Training Time   192.230548            0.000528  0.001347      0.105613\n",
      "took: 658.3094427585602 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t2\n",
      "Epoch 0: 0.27275653368483654\n",
      "Epoch 25: 0.0004359435601744866\n",
      "Epoch 50: 0.00022582358212328704\n",
      "Epoch 75: 0.00015464912579680944\n",
      "Epoch 100: 0.00011836858247669551\n",
      "Epoch 125: 9.623441065119876e-05\n",
      "Epoch 150: 8.126430757667821e-05\n",
      "Took: 195.61917877197266 for training\n",
      "Took: 392.8300278186798 for predicting 810 training instances\n",
      "Took: 41.2190260887146 for predicting 90 test instances\n",
      "Took: 45.6029212474823 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.491156  0.491156      0.522780\n",
      "F1 Tr. only       0.000000            0.701124  0.728007      0.674265\n",
      "F1 Train          0.000000            0.610103  0.623656      0.993807\n",
      "Pred.Tra. Time  392.830028            0.071658  0.696512      0.111697\n",
      "Test             -1.829630            0.837037  0.837037      0.829630\n",
      "Testing Time     41.219026            0.000160  0.000448      0.101721\n",
      "Tr. Only         -1.743333            0.916667  0.923333      0.890000\n",
      "Tr.Test Time     45.602921            0.000164  0.000335      0.102146\n",
      "Train            -1.782305            0.886420  0.888477      0.997531\n",
      "Training Time   195.619179            0.001032  0.001677      0.102051\n",
      "took: 675.4395296573639 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t3\n",
      "Epoch 0: 0.8090225003948518\n",
      "Epoch 25: 0.0005761887490094266\n",
      "Epoch 50: 0.00029983124284126323\n",
      "Epoch 75: 0.00020525051111488008\n",
      "Epoch 100: 0.00015690805419113984\n",
      "Epoch 125: 0.00012739954465758522\n",
      "Epoch 150: 0.00010744225108189654\n",
      "Took: 196.0550558567047 for training\n",
      "Took: 389.4923896789551 for predicting 810 training instances\n",
      "Took: 43.669029712677 for predicting 90 test instances\n",
      "Took: 48.85340452194214 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.556586  0.556586      0.567148\n",
      "F1 Tr. only       0.000000            0.701124  0.741472      0.669286\n",
      "F1 Train          0.000000            0.599170  0.617918      0.990111\n",
      "Pred.Tra. Time  389.492390            0.050546  0.381268      0.126925\n",
      "Test             -1.788889            0.874074  0.874074      0.859259\n",
      "Testing Time     43.669030            0.000090  0.000289      0.104090\n",
      "Tr. Only         -1.743333            0.916667  0.923333      0.886667\n",
      "Tr.Test Time     48.853405            0.000094  0.000294      0.104248\n",
      "Train            -1.786831            0.881481  0.884774      0.995885\n",
      "Training Time   196.055056            0.000520  0.001441      0.102655\n",
      "took: 678.2971503734589 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t4\n",
      "Epoch 0: 0.5020248687625486\n",
      "Epoch 25: 0.0004985337687454329\n",
      "Epoch 50: 0.00025423814848079683\n",
      "Epoch 75: 0.00017277277040397303\n",
      "Epoch 100: 0.00013154684027294526\n",
      "Epoch 125: 0.0001065082426381079\n",
      "Epoch 150: 8.963891977206329e-05\n",
      "Took: 190.64324307441711 for training\n",
      "Took: 410.05815601348877 for predicting 810 training instances\n",
      "Took: 39.97868013381958 for predicting 90 test instances\n",
      "Took: 45.61820673942566 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.660374  0.635386      0.620592\n",
      "F1 Tr. only       0.000000            0.706145  0.728007      0.685266\n",
      "F1 Train          0.000000            0.591059  0.593836      0.995053\n",
      "Pred.Tra. Time  410.058156            0.049302  0.347414      0.126993\n",
      "Test             -1.777778            0.892593  0.888889      0.870370\n",
      "Testing Time     39.978680            0.000092  0.000282      0.105148\n",
      "Tr. Only         -1.743333            0.920000  0.923333      0.893333\n",
      "Tr.Test Time     45.618207            0.000120  0.000295      0.105575\n",
      "Train            -1.788066            0.880247  0.880658      0.998354\n",
      "Training Time   190.643243            0.000495  0.001371      0.103326\n",
      "took: 686.5147051811218 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t5\n",
      "Epoch 0: 0.37268882308623946\n",
      "Epoch 25: 0.00044749568455736615\n",
      "Epoch 50: 0.0002351128920696826\n",
      "Epoch 75: 0.00016152292121079072\n",
      "Epoch 100: 0.00012375296240671113\n",
      "Epoch 125: 0.00010064885444513566\n",
      "Epoch 150: 8.500529642653285e-05\n",
      "Took: 196.3608238697052 for training\n",
      "Took: 390.9738538265228 for predicting 810 training instances\n",
      "Took: 45.07271337509155 for predicting 90 test instances\n",
      "Took: 47.92903017997742 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.571053  0.576471      0.555408\n",
      "F1 Tr. only       0.000000            0.701124  0.711111      0.664327\n",
      "F1 Train          0.000000            0.594743  0.589061      0.988838\n",
      "Pred.Tra. Time  390.973854            0.051586  0.155233      0.119027\n",
      "Test             -1.488889            0.874074  0.877778      0.844444\n",
      "Testing Time     45.072713            0.000091  0.000278      0.104923\n",
      "Tr. Only         -1.740000            0.916667  0.923333      0.890000\n",
      "Tr.Test Time     47.929030            0.000101  0.000290      0.105143\n",
      "Train            -1.481070            0.881070  0.880247      0.995473\n",
      "Training Time   196.360824            0.000536  0.001443      0.102306\n",
      "took: 680.5185244083405 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t6\n",
      "Epoch 0: 1.1623212807411736\n",
      "Epoch 25: 0.0007433629029903182\n",
      "Epoch 50: 0.00037555846671405094\n",
      "Epoch 75: 0.0002566206104966092\n",
      "Epoch 100: 0.00019653268982374863\n",
      "Epoch 125: 0.00015995940338756553\n",
      "Epoch 150: 0.00013524758993282255\n",
      "Took: 191.04717564582825 for training\n",
      "Took: 387.24992299079895 for predicting 810 training instances\n",
      "Took: 44.63475275039673 for predicting 90 test instances\n",
      "Took: 47.29118037223816 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.499773  0.505105      0.600453\n",
      "F1 Tr. only       0.000000            0.701124  0.711111      0.718570\n",
      "F1 Train          0.000000            0.605685  0.608464      0.995055\n",
      "Pred.Tra. Time  387.249923            0.060218  0.280376      0.132864\n",
      "Test             -1.811111            0.851852  0.855556      0.866667\n",
      "Testing Time     44.634753            0.000093  0.000273      0.104924\n",
      "Tr. Only         -1.743333            0.916667  0.923333      0.903333\n",
      "Tr.Test Time     47.291180            0.000122  0.000293      0.104821\n",
      "Train            -1.784362            0.883951  0.884362      0.997942\n",
      "Training Time   191.047176            0.000524  0.001420      0.106055\n",
      "took: 670.3878631591797 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t7\n",
      "Epoch 0: 0.6562899414727674\n",
      "Epoch 25: 0.0006038592571614374\n",
      "Epoch 50: 0.00030800459675628606\n",
      "Epoch 75: 0.00020892129392951507\n",
      "Epoch 100: 0.0001587517857148913\n",
      "Epoch 125: 0.0001282972281888342\n",
      "Epoch 150: 0.00010780958345633716\n",
      "Took: 202.31063652038574 for training\n",
      "Took: 403.36401987075806 for predicting 810 training instances\n",
      "Took: 43.92808222770691 for predicting 90 test instances\n",
      "Took: 51.43049597740173 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.529875  0.505105      0.511895\n",
      "F1 Tr. only       0.000000            0.706145  0.706145      0.715572\n",
      "F1 Train          0.000000            0.597191  0.600049      0.992593\n",
      "Pred.Tra. Time  403.364020            0.052993  0.231227      0.112018\n",
      "Test             -1.488889            0.855556  0.851852      0.848148\n",
      "Testing Time     43.928082            0.000091  0.000274      0.105216\n",
      "Tr. Only         -1.416667            0.920000  0.920000      0.910000\n",
      "Tr.Test Time     51.430496            0.000094  0.000289      0.105522\n",
      "Train            -1.453909            0.883128  0.883539      0.997531\n",
      "Training Time   202.310637            0.000529  0.001431      0.102643\n",
      "took: 701.2204434871674 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t8\n",
      "Epoch 0: 0.37188010352574\n",
      "Epoch 25: 0.00043383372077670753\n",
      "Epoch 50: 0.00022362787180065598\n",
      "Epoch 75: 0.00015279677369086202\n",
      "Epoch 100: 0.0001167966992056264\n",
      "Epoch 125: 9.487454643888256e-05\n",
      "Epoch 150: 8.00696814235064e-05\n",
      "Took: 203.36435341835022 for training\n",
      "Took: 395.0942950248718 for predicting 810 training instances\n",
      "Took: 44.43714165687561 for predicting 90 test instances\n",
      "Took: 47.889453411102295 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.773226  0.773226      0.737905\n",
      "F1 Tr. only       0.000000            0.706145  0.706145      0.699060\n",
      "F1 Train          0.000000            0.579654  0.576527      0.992586\n",
      "Pred.Tra. Time  395.094295            0.052959  0.219454      0.111256\n",
      "Test             -1.311111            0.940741  0.940741      0.903704\n",
      "Testing Time     44.437142            0.000093  0.000284      0.105044\n",
      "Tr. Only         -1.636667            0.920000  0.920000      0.893333\n",
      "Tr.Test Time     47.889453            0.000093  0.000288      0.105583\n",
      "Train            -1.393004            0.875309  0.874486      0.996708\n",
      "Training Time   203.364353            0.000556  0.001425      0.104294\n",
      "took: 691.0021831989288 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t9\n",
      "Epoch 0: 0.32511152619668193\n",
      "Epoch 25: 0.0005061690688856296\n",
      "Epoch 50: 0.00026184629669994184\n",
      "Epoch 75: 0.0001789232506088941\n",
      "Epoch 100: 0.00013665018189190498\n",
      "Epoch 125: 0.00011087584851808597\n",
      "Epoch 150: 9.34629871916272e-05\n",
      "Took: 195.59370493888855 for training\n",
      "Took: 401.0931234359741 for predicting 810 training instances\n",
      "Took: 42.65196943283081 for predicting 90 test instances\n",
      "Took: 51.896848917007446 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.519165  0.519165      0.502956\n",
      "F1 Tr. only       0.000000            0.701124  0.706145      0.703801\n",
      "F1 Train          0.000000            0.606836  0.604056      0.993821\n",
      "Pred.Tra. Time  401.093123            0.056586  0.202346      0.126878\n",
      "Test             -1.803704            0.855556  0.855556      0.837037\n",
      "Testing Time     42.651969            0.000107  0.000288      0.104894\n",
      "Tr. Only         -1.743333            0.916667  0.920000      0.900000\n",
      "Tr.Test Time     51.896849            0.000111  0.000294      0.105638\n",
      "Train            -1.784362            0.884362  0.883951      0.997942\n",
      "Training Time   195.593705            0.000561  0.001451      0.102804\n",
      "took: 691.4502930641174 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "K: \t10\n",
      "Epoch 0: 0.354043422103197\n",
      "Epoch 25: 0.0004746879699535224\n",
      "Epoch 50: 0.00024342959618681414\n",
      "Epoch 75: 0.0001653860157174618\n",
      "Epoch 100: 0.00012577618635102933\n",
      "Epoch 125: 0.00010171934614553732\n",
      "Epoch 150: 8.551772389205395e-05\n",
      "Took: 196.13898015022278 for training\n",
      "Took: 395.69983410835266 for predicting 810 training instances\n",
      "Took: 42.055965185165405 for predicting 90 test instances\n",
      "Took: 49.52366042137146 for predicting 100 Turkish test instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.711111  0.711111      0.670287\n",
      "F1 Tr. only       0.000000            0.706145  0.706145      0.690952\n",
      "F1 Train          0.000000            0.585746  0.591223      0.995044\n",
      "Pred.Tra. Time  395.699834            0.042391  0.380917      0.110985\n",
      "Test             -1.359259            0.922222  0.922222      0.885185\n",
      "Testing Time     42.055965            0.000096  0.000281      0.105039\n",
      "Tr. Only         -1.716667            0.920000  0.920000      0.893333\n",
      "Tr.Test Time     49.523660            0.000095  0.000295      0.104863\n",
      "Train            -1.408642            0.876955  0.877778      0.998354\n",
      "Training Time   196.138980            0.000513  0.001434      0.104237\n",
      "took: 683.5974311828613 seconds\n",
      "\n",
      "**********\n",
      "\n",
      "Average scores for trial 0\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.590337  0.586436      0.590771\n",
      "F1 Tr. only       0.000000            0.703132  0.715043      0.688956\n",
      "F1 Train          0.000000            0.596330  0.600897      0.993320\n",
      "Pred.Tra. Time  394.298890            0.054156  0.329618      0.120595\n",
      "Test             -1.643704            0.879259  0.879259      0.862593\n",
      "Testing Time     43.132841            0.000101  0.000298      0.104587\n",
      "Tr. Only         -1.697000            0.918000  0.921667      0.894333\n",
      "Tr.Test Time     48.112591            0.000109  0.000297      0.104921\n",
      "Train            -1.645021            0.881276  0.881975      0.997407\n",
      "Training Time   195.936370            0.000579  0.001444      0.103598\n",
      "------------------------------\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Average of 1 trials\n",
      "                DeepSelect  LogisticRegression       MLP  RandomForest\n",
      "F1 Test           0.000000            0.590337  0.586436      0.590771\n",
      "F1 Tr. only       0.000000            0.703132  0.715043      0.688956\n",
      "F1 Train          0.000000            0.596330  0.600897      0.993320\n",
      "Pred.Tra. Time  394.298890            0.054156  0.329618      0.120595\n",
      "Test             -1.643704            0.879259  0.879259      0.862593\n",
      "Testing Time     43.132841            0.000101  0.000298      0.104587\n",
      "Tr. Only         -1.697000            0.918000  0.921667      0.894333\n",
      "Tr.Test Time     48.112591            0.000109  0.000297      0.104921\n",
      "Train            -1.645021            0.881276  0.881975      0.997407\n",
      "Training Time   195.936370            0.000579  0.001444      0.103598\n"
     ]
    }
   ],
   "source": [
    "scores_tables_nn_tri = eval_selectivewaves_nn(df_trilabels, tronly_test_raw_trilabels)\n",
    "pickle.dump(scores_tables_nn_tri, open(\"../results/incremental_tf_tables_tri.results\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En: 50\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.995486431682025\n",
      "epoch 10:\t21.809009366870324\n",
      "epoch 20:\t21.626891747279853\n",
      "epoch 30:\t21.45687769961407\n",
      "epoch 40:\t21.276837475380066\n",
      "epoch 50:\t21.068732802359193\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.2148457270374315\n",
      "Epoch 25: 0.002857720736190256\n",
      "Epoch 50: 0.0014685058717380647\n",
      "Epoch 75: 0.001002038571636553\n",
      "Epoch 100: 0.0007655120114173365\n",
      "Epoch 125: 0.0006216729380664926\n",
      "Epoch 150: 0.0005246478323644826\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 59.706504106521606\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t16.93656054312707\n",
      "epoch 10:\t16.81727397575503\n",
      "epoch 20:\t16.648620749082724\n",
      "epoch 30:\t16.48787541940564\n",
      "epoch 40:\t16.372530960081864\n",
      "epoch 50:\t16.266300605659143\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 6.013702467604218\n",
      "Epoch 25: 0.003675902982483701\n",
      "Epoch 50: 0.0017843498439228474\n",
      "Epoch 75: 0.001197547555786444\n",
      "Epoch 100: 0.0009077268399625365\n",
      "Epoch 125: 0.0007337544545971644\n",
      "Epoch 150: 0.0006172875099290072\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 86.75075960159302\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.189964001481314\n",
      "epoch 10:\t17.927175486574516\n",
      "epoch 20:\t17.75489693516216\n",
      "epoch 30:\t17.569664035505706\n",
      "epoch 40:\t17.441097923416166\n",
      "epoch 50:\t17.277809002120307\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.7363604842192875\n",
      "Epoch 25: 0.0022111539915983637\n",
      "Epoch 50: 0.0011213938582996014\n",
      "Epoch 75: 0.0007622498402796777\n",
      "Epoch 100: 0.0005810721975041635\n",
      "Epoch 125: 0.00047119912097131456\n",
      "Epoch 150: 0.00039720837636640654\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 113.63486528396606\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.099143555933352\n",
      "epoch 10:\t23.392221091593118\n",
      "epoch 20:\t22.974565388162024\n",
      "epoch 30:\t22.698072570909265\n",
      "epoch 40:\t22.481609909460527\n",
      "epoch 50:\t22.30511742186316\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.9310949180496946\n",
      "Epoch 25: 0.0028132113153885386\n",
      "Epoch 50: 0.0013763521747461838\n",
      "Epoch 75: 0.0009183967321042647\n",
      "Epoch 100: 0.0006914269521774128\n",
      "Epoch 125: 0.0005554102293266234\n",
      "Epoch 150: 0.0004646295594552287\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 126.51161456108093\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.07686358219605\n",
      "epoch 10:\t20.828582445802745\n",
      "epoch 20:\t20.685572368122042\n",
      "epoch 30:\t20.46992822131374\n",
      "epoch 40:\t20.27537135031837\n",
      "epoch 50:\t20.070621000030158\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.9068887025216754\n",
      "Epoch 25: 0.0013525207690249772\n",
      "Epoch 50: 0.0006787898693615944\n",
      "Epoch 75: 0.00045742042162692087\n",
      "Epoch 100: 0.0003462928917432464\n",
      "Epoch 125: 0.00027921823804842914\n",
      "Epoch 150: 0.00023425383235013442\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 145.76305103302002\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.28829562832369\n",
      "epoch 10:\t19.364107918399984\n",
      "epoch 20:\t19.037740636620548\n",
      "epoch 30:\t18.875017356920154\n",
      "epoch 40:\t18.790518684678844\n",
      "epoch 50:\t18.711375288287847\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.668148895542655\n",
      "Epoch 25: 0.002094864479461821\n",
      "Epoch 50: 0.0010381888158372315\n",
      "Epoch 75: 0.0006959650932953247\n",
      "Epoch 100: 0.0005255188272522363\n",
      "Epoch 125: 0.00042311619835603236\n",
      "Epoch 150: 0.00035465906783376167\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 162.3464183807373\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t16.54016296939017\n",
      "epoch 10:\t16.330757227822698\n",
      "epoch 20:\t16.169805021891325\n",
      "epoch 30:\t16.057654216243595\n",
      "epoch 40:\t15.950906656832842\n",
      "epoch 50:\t15.834237391208182\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.7333562175884296\n",
      "Epoch 25: 0.0014000147006391107\n",
      "Epoch 50: 0.0007096947014124504\n",
      "Epoch 75: 0.0004811515724954795\n",
      "Epoch 100: 0.0003659174837545806\n",
      "Epoch 125: 0.0002961330484548729\n",
      "Epoch 150: 0.0002492012203259547\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 172.7580349445343\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.43018432020671\n",
      "epoch 10:\t22.283030159226808\n",
      "epoch 20:\t22.086799064968975\n",
      "epoch 30:\t21.904905346515275\n",
      "epoch 40:\t21.73273330893335\n",
      "epoch 50:\t21.572682674062268\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.1517260113051855\n",
      "Epoch 25: 0.0010488117802339432\n",
      "Epoch 50: 0.000538198154081221\n",
      "Epoch 75: 0.00036678442552916853\n",
      "Epoch 100: 0.00027986042542338326\n",
      "Epoch 125: 0.0002270292378471896\n",
      "Epoch 150: 0.00019140911000296474\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 197.6751892566681\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.118110849638175\n",
      "epoch 10:\t19.619601355622123\n",
      "epoch 20:\t19.32026156758924\n",
      "epoch 30:\t19.02741183386671\n",
      "epoch 40:\t18.733507478292452\n",
      "epoch 50:\t18.485511998909995\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.1798025182481762\n",
      "Epoch 25: 0.0011923835978543261\n",
      "Epoch 50: 0.0005817713020586718\n",
      "Epoch 75: 0.00038757330450480147\n",
      "Epoch 100: 0.00029157689837349174\n",
      "Epoch 125: 0.00023416662536249771\n",
      "Epoch 150: 0.00019590897152381065\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 214.67156386375427\n",
      "--------------------------------------------------\n",
      "En: 50\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.228588312367222\n",
      "epoch 10:\t19.114356086288968\n",
      "epoch 20:\t18.972505197018183\n",
      "epoch 30:\t18.735883849247454\n",
      "epoch 40:\t18.4715613719034\n",
      "epoch 50:\t18.217583430256937\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.756422575457361\n",
      "Epoch 25: 0.000829506189045901\n",
      "Epoch 50: 0.00042915225528980094\n",
      "Epoch 75: 0.0002923802651650299\n",
      "Epoch 100: 0.00022277291646509588\n",
      "Epoch 125: 0.0001804406391376132\n",
      "Epoch 150: 0.00015191307439696149\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 238.76969933509827\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t15.756080732851283\n",
      "epoch 10:\t15.458915255322736\n",
      "epoch 20:\t15.23705229052654\n",
      "epoch 30:\t15.11372331731871\n",
      "epoch 40:\t15.016760746409282\n",
      "epoch 50:\t14.941128507302773\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.8162891676627624\n",
      "Epoch 25: 0.0022685779465551345\n",
      "Epoch 50: 0.001118053639791989\n",
      "Epoch 75: 0.000751818958331439\n",
      "Epoch 100: 0.0005696306853094159\n",
      "Epoch 125: 0.0004600400073968558\n",
      "Epoch 150: 0.0003866513749764116\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 101.9269871711731\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.873492504757376\n",
      "epoch 10:\t19.552780236335824\n",
      "epoch 20:\t19.117807573032497\n",
      "epoch 30:\t18.769562140765963\n",
      "epoch 40:\t18.51872701510374\n",
      "epoch 50:\t18.41561994482911\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.5633300536460917\n",
      "Epoch 25: 0.0013743906972788662\n",
      "Epoch 50: 0.0006899505099201835\n",
      "Epoch 75: 0.00047209633560467206\n",
      "Epoch 100: 0.00036296599263355096\n",
      "Epoch 125: 0.0002967699860016006\n",
      "Epoch 150: 0.00025208226640371673\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 117.39118504524231\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t16.70018230479383\n",
      "epoch 10:\t16.25233263117646\n",
      "epoch 20:\t16.078108060749344\n",
      "epoch 30:\t15.912003584956485\n",
      "epoch 40:\t15.748004213105553\n",
      "epoch 50:\t15.599192431099526\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.0175247193572845\n",
      "Epoch 25: 0.0017934642611758084\n",
      "Epoch 50: 0.0009051289652739895\n",
      "Epoch 75: 0.0006150666554512957\n",
      "Epoch 100: 0.00046867847252100734\n",
      "Epoch 125: 0.00037987180404544773\n",
      "Epoch 150: 0.00032004285422935005\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 143.34916758537292\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.88808358040605\n",
      "epoch 10:\t19.657148704299882\n",
      "epoch 20:\t19.54440605213537\n",
      "epoch 30:\t19.39385233640243\n",
      "epoch 40:\t19.26569638003375\n",
      "epoch 50:\t19.143366491932994\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.8840181974420445\n",
      "Epoch 25: 0.001970295224443292\n",
      "Epoch 50: 0.000953101131073726\n",
      "Epoch 75: 0.0006351931656711739\n",
      "Epoch 100: 0.0004784077300745738\n",
      "Epoch 125: 0.0003846589227873774\n",
      "Epoch 150: 0.0003221560392017973\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 165.3357219696045\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.799412403577936\n",
      "epoch 10:\t18.586704819148853\n",
      "epoch 20:\t18.39243922127449\n",
      "epoch 30:\t18.254006577190843\n",
      "epoch 40:\t18.13364093715036\n",
      "epoch 50:\t18.005379983473578\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.093923967117401\n",
      "Epoch 25: 0.0016315131826959827\n",
      "Epoch 50: 0.0008213721197687107\n",
      "Epoch 75: 0.000553149141061103\n",
      "Epoch 100: 0.0004185432375947566\n",
      "Epoch 125: 0.0003373816519471025\n",
      "Epoch 150: 0.00028299749594992815\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 184.45032024383545\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.20034101063229\n",
      "epoch 10:\t17.977644491564167\n",
      "epoch 20:\t17.935384147726534\n",
      "epoch 30:\t17.872207123492377\n",
      "epoch 40:\t17.765696456925117\n",
      "epoch 50:\t17.670573373129773\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.4399991334918809\n",
      "Epoch 25: 0.0008939700034317902\n",
      "Epoch 50: 0.0004564061221779776\n",
      "Epoch 75: 0.00030968880847256024\n",
      "Epoch 100: 0.00023552968778157974\n",
      "Epoch 125: 0.00019059023023026064\n",
      "Epoch 150: 0.00016036053338573745\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 199.3394501209259\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.880337188292902\n",
      "epoch 10:\t18.71510301973792\n",
      "epoch 20:\t18.687029337422217\n",
      "epoch 30:\t18.65395258764502\n",
      "epoch 40:\t18.506473033437945\n",
      "epoch 50:\t18.389749122725814\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.46074135343935785\n",
      "Epoch 25: 0.0007060088826321849\n",
      "Epoch 50: 0.0003777137736021455\n",
      "Epoch 75: 0.0002609335652187601\n",
      "Epoch 100: 0.00020038164066252164\n",
      "Epoch 125: 0.0001631395908785518\n",
      "Epoch 150: 0.00013784061685656542\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 214.2069034576416\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.138597779623296\n",
      "epoch 10:\t19.135713250763764\n",
      "epoch 20:\t18.872771563954323\n",
      "epoch 30:\t18.688741723288786\n",
      "epoch 40:\t18.503033014728388\n",
      "epoch 50:\t18.31257141855659\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.2629455857959415\n",
      "Epoch 25: 0.0012744447085169884\n",
      "Epoch 50: 0.0006592826850232129\n",
      "Epoch 75: 0.0004492400702547781\n",
      "Epoch 100: 0.000342300530517326\n",
      "Epoch 125: 0.00027722295801717274\n",
      "Epoch 150: 0.00023336467104095553\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 225.50767374038696\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.353861291486798\n",
      "epoch 10:\t18.775935254039656\n",
      "epoch 20:\t18.48315860867812\n",
      "epoch 30:\t18.16058393770997\n",
      "epoch 40:\t17.858364063015703\n",
      "epoch 50:\t17.53938652318855\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.5018814516842807\n",
      "Epoch 25: 0.0007356673999389639\n",
      "Epoch 50: 0.0003763822570394938\n",
      "Epoch 75: 0.0002569173337236733\n",
      "Epoch 100: 0.00019634774008738616\n",
      "Epoch 125: 0.00015949572264829562\n",
      "Epoch 150: 0.00013461288612649262\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 248.49011540412903\n",
      "--------------------------------------------------\n",
      "En: 100\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.95985328296848\n",
      "epoch 10:\t22.880131996065177\n",
      "epoch 20:\t22.34121056461483\n",
      "epoch 30:\t21.683600768630857\n",
      "epoch 40:\t21.12346710899034\n",
      "epoch 50:\t20.697846232975678\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.2157140206712336\n",
      "Epoch 25: 0.0008016790207638281\n",
      "Epoch 50: 0.000406209862691469\n",
      "Epoch 75: 0.0002743938772495653\n",
      "Epoch 100: 0.000208073542426348\n",
      "Epoch 125: 0.00016801479332571035\n",
      "Epoch 150: 0.0001411486434289202\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 263.5652129650116\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.715449266885155\n",
      "epoch 10:\t21.186580368407434\n",
      "epoch 20:\t20.741663078650568\n",
      "epoch 30:\t20.551130554368637\n",
      "epoch 40:\t20.39722839372674\n",
      "epoch 50:\t20.17477892990892\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.615052441967112\n",
      "Epoch 25: 0.0022232406961943765\n",
      "Epoch 50: 0.0011028503091270786\n",
      "Epoch 75: 0.0007487057857959276\n",
      "Epoch 100: 0.0005721157417862119\n",
      "Epoch 125: 0.0004653805359590766\n",
      "Epoch 150: 0.00039351654956566273\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 125.82777404785156\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.795807657930926\n",
      "epoch 10:\t20.415549539350664\n",
      "epoch 20:\t20.029992881715657\n",
      "epoch 30:\t19.75313146930398\n",
      "epoch 40:\t19.63584264689815\n",
      "epoch 50:\t19.48161415323717\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 3.519948087819237\n",
      "Epoch 25: 0.002722077766310102\n",
      "Epoch 50: 0.0013724101175524618\n",
      "Epoch 75: 0.0009272777635334498\n",
      "Epoch 100: 0.0007035601301469262\n",
      "Epoch 125: 0.0005683753651250913\n",
      "Epoch 150: 0.00047762314572831536\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 155.9616141319275\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.950479828100026\n",
      "epoch 10:\t18.84750890951568\n",
      "epoch 20:\t18.578164430246204\n",
      "epoch 30:\t18.416067890658585\n",
      "epoch 40:\t18.269976911239493\n",
      "epoch 50:\t18.12434967406995\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.411539242359302\n",
      "Epoch 25: 0.0019458852789263667\n",
      "Epoch 50: 0.000905377027251259\n",
      "Epoch 75: 0.0005997201604575114\n",
      "Epoch 100: 0.00045130066186347735\n",
      "Epoch 125: 0.00036307504115745394\n",
      "Epoch 150: 0.00030440943176986195\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 168.47822833061218\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.027597675933826\n",
      "epoch 10:\t17.6981768765794\n",
      "epoch 20:\t17.86848595721261\n",
      "epoch 30:\t17.745899225733343\n",
      "epoch 40:\t17.671444601147044\n",
      "epoch 50:\t17.631552385390815\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.407230269520111\n",
      "Epoch 25: 0.0016215945738538046\n",
      "Epoch 50: 0.000808341466713977\n",
      "Epoch 75: 0.0005444974387666163\n",
      "Epoch 100: 0.0004125798443044826\n",
      "Epoch 125: 0.00033307938502591037\n",
      "Epoch 150: 0.00027977846075639116\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 196.11262011528015\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t17.6532730522487\n",
      "epoch 10:\t17.384419905247768\n",
      "epoch 20:\t17.075703436288304\n",
      "epoch 30:\t16.69879132483391\n",
      "epoch 40:\t16.410171540482448\n",
      "epoch 50:\t16.161701376393548\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.5090587024132665\n",
      "Epoch 25: 0.0007900448406786609\n",
      "Epoch 50: 0.00040898166177933196\n",
      "Epoch 75: 0.00027787678134741004\n",
      "Epoch 100: 0.00021113164382232494\n",
      "Epoch 125: 0.0001705846151799863\n",
      "Epoch 150: 0.000143294087826819\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 213.5734302997589\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.751547056694587\n",
      "epoch 10:\t18.677800759630106\n",
      "epoch 20:\t18.521265553850736\n",
      "epoch 30:\t18.319974199824173\n",
      "epoch 40:\t18.12681710463772\n",
      "epoch 50:\t17.962971665225993\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.425829935658592\n",
      "Epoch 25: 0.0015864334134304359\n",
      "Epoch 50: 0.0007780268297906901\n",
      "Epoch 75: 0.0005237680924922508\n",
      "Epoch 100: 0.00039782777715872844\n",
      "Epoch 125: 0.00032215889423026624\n",
      "Epoch 150: 0.00027146106747958737\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 227.4394404888153\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.80664713846403\n",
      "epoch 10:\t20.370982499945374\n",
      "epoch 20:\t19.98536876101021\n",
      "epoch 30:\t19.567033311135543\n",
      "epoch 40:\t19.125465921199822\n",
      "epoch 50:\t18.73684762406981\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.3430145361879366\n",
      "Epoch 25: 0.0010023873122792719\n",
      "Epoch 50: 0.0005161802696137081\n",
      "Epoch 75: 0.0003520869965037031\n",
      "Epoch 100: 0.00026859863599999994\n",
      "Epoch 125: 0.00021775874115400427\n",
      "Epoch 150: 0.0001834455317691333\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 245.73215222358704\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.177242233538873\n",
      "epoch 10:\t20.044145956528865\n",
      "epoch 20:\t19.595210239436692\n",
      "epoch 30:\t19.10073890504355\n",
      "epoch 40:\t18.8699740141948\n",
      "epoch 50:\t18.714897325649833\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.8920366579344432\n",
      "Epoch 25: 0.0011976648877328351\n",
      "Epoch 50: 0.0006047363959982807\n",
      "Epoch 75: 0.0004096890175063397\n",
      "Epoch 100: 0.00031148915546882176\n",
      "Epoch 125: 0.00025204698998408653\n",
      "Epoch 150: 0.00021207035564163967\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 256.8566360473633\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t26.300500599517164\n",
      "epoch 10:\t25.595791605441292\n",
      "epoch 20:\t25.134957962939115\n",
      "epoch 30:\t24.865374967239244\n",
      "epoch 40:\t24.56982183146451\n",
      "epoch 50:\t24.221063771830973\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.0495135255750956\n",
      "Epoch 25: 0.0009492964361966778\n",
      "Epoch 50: 0.000481442851329972\n",
      "Epoch 75: 0.00032846083967733784\n",
      "Epoch 100: 0.0002512441811389317\n",
      "Epoch 125: 0.0002043402749178852\n",
      "Epoch 150: 0.00017268747628144317\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 276.45719623565674\n",
      "--------------------------------------------------\n",
      "En: 150\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.930641477821343\n",
      "epoch 10:\t22.266813745657213\n",
      "epoch 20:\t21.332671120286562\n",
      "epoch 30:\t20.88565502966813\n",
      "epoch 40:\t20.634847795147742\n",
      "epoch 50:\t20.356380175541958\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.9214233087040338\n",
      "Epoch 25: 0.001094637096889838\n",
      "Epoch 50: 0.0005500479933743142\n",
      "Epoch 75: 0.00037046284520068245\n",
      "Epoch 100: 0.0002803217044670832\n",
      "Epoch 125: 0.00022592586249239524\n",
      "Epoch 150: 0.00018946147869896052\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 289.4551315307617\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.67886914962118\n",
      "epoch 10:\t22.96024899805737\n",
      "epoch 20:\t22.9272255170989\n",
      "epoch 30:\t22.645017935718926\n",
      "epoch 40:\t22.36282377148056\n",
      "epoch 50:\t22.100649640836327\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.6285833277574662\n",
      "Epoch 25: 0.0017865697149905676\n",
      "Epoch 50: 0.0008818812068057014\n",
      "Epoch 75: 0.000598801556931979\n",
      "Epoch 100: 0.0004570227382345138\n",
      "Epoch 125: 0.0003710949531002446\n",
      "Epoch 150: 0.00031317563492810527\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 154.4181411266327\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.491619022328994\n",
      "epoch 10:\t18.156675516356383\n",
      "epoch 20:\t18.01885290482789\n",
      "epoch 30:\t17.93261341186552\n",
      "epoch 40:\t17.844493738559457\n",
      "epoch 50:\t17.683898886316896\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.563218083990965\n",
      "Epoch 25: 0.0010393330989038369\n",
      "Epoch 50: 0.000533780265491503\n",
      "Epoch 75: 0.0003630252525258218\n",
      "Epoch 100: 0.00027641550443350735\n",
      "Epoch 125: 0.00022383511069174388\n",
      "Epoch 150: 0.0001884159641540809\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 177.83717107772827\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.319049714813403\n",
      "epoch 10:\t21.250377482395567\n",
      "epoch 20:\t21.057319980014018\n",
      "epoch 30:\t20.896228143592378\n",
      "epoch 40:\t20.750800756614506\n",
      "epoch 50:\t20.687191021181288\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.9213776496791638\n",
      "Epoch 25: 0.0009892998745727245\n",
      "Epoch 50: 0.0005019870683017569\n",
      "Epoch 75: 0.0003422816717515431\n",
      "Epoch 100: 0.0002619322271318225\n",
      "Epoch 125: 0.00021323375442161563\n",
      "Epoch 150: 0.00018044731031792162\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 195.82722568511963\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.338785313103983\n",
      "epoch 10:\t17.909880454351022\n",
      "epoch 20:\t17.625723383374268\n",
      "epoch 30:\t17.462420789350357\n",
      "epoch 40:\t17.355943488775246\n",
      "epoch 50:\t17.199525803362345\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.726466435144751\n",
      "Epoch 25: 0.0017371283612770108\n",
      "Epoch 50: 0.0008491970005544482\n",
      "Epoch 75: 0.0005741679545107243\n",
      "Epoch 100: 0.0004380587898091272\n",
      "Epoch 125: 0.0003561421713879693\n",
      "Epoch 150: 0.000301131104058388\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 215.7332627773285\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.348254188000833\n",
      "epoch 10:\t21.463277013013112\n",
      "epoch 20:\t21.272972303453113\n",
      "epoch 30:\t21.049984809019097\n",
      "epoch 40:\t20.853973029369875\n",
      "epoch 50:\t20.69199721899615\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.4906555081369697\n",
      "Epoch 25: 0.0018584472017909093\n",
      "Epoch 50: 0.0007803143002962543\n",
      "Epoch 75: 0.0005051948629370884\n",
      "Epoch 100: 0.0003774373547783938\n",
      "Epoch 125: 0.0003029608432574804\n",
      "Epoch 150: 0.0002538932546842787\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 231.36121225357056\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.006538442918004\n",
      "epoch 10:\t23.68004826627131\n",
      "epoch 20:\t23.093827667380392\n",
      "epoch 30:\t22.7295450048652\n",
      "epoch 40:\t22.479839737665515\n",
      "epoch 50:\t22.283655704568435\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.6870656651903864\n",
      "Epoch 25: 0.0011589579144077595\n",
      "Epoch 50: 0.0005981437727237965\n",
      "Epoch 75: 0.0004086751193494432\n",
      "Epoch 100: 0.00031229960455922363\n",
      "Epoch 125: 0.0002536240236727978\n",
      "Epoch 150: 0.00021401666363203084\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 261.22406125068665\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.167549543782737\n",
      "epoch 10:\t19.93272869794049\n",
      "epoch 20:\t19.936579746629505\n",
      "epoch 30:\t19.732784120896508\n",
      "epoch 40:\t19.589484344108882\n",
      "epoch 50:\t19.444915275671217\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.6395715906832738\n",
      "Epoch 25: 0.0009285042056921711\n",
      "Epoch 50: 0.0004745114684376143\n",
      "Epoch 75: 0.00032260286647633286\n",
      "Epoch 100: 0.00024581690902717075\n",
      "Epoch 125: 0.00019925063622106738\n",
      "Epoch 150: 0.00016790225570607238\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 270.69765973091125\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.96241935558668\n",
      "epoch 10:\t19.80312573108534\n",
      "epoch 20:\t19.532003520605315\n",
      "epoch 30:\t19.266676087992604\n",
      "epoch 40:\t19.038147089662218\n",
      "epoch 50:\t18.82573708977132\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.4434578625105828\n",
      "Epoch 25: 0.000795068393735467\n",
      "Epoch 50: 0.00040999224919973954\n",
      "Epoch 75: 0.0002790345203676244\n",
      "Epoch 100: 0.00021239069492325988\n",
      "Epoch 125: 0.00017184528814258198\n",
      "Epoch 150: 0.00014451489461008075\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 278.333416223526\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.878298470790824\n",
      "epoch 10:\t20.596028194416125\n",
      "epoch 20:\t20.419948117885735\n",
      "epoch 30:\t20.253930863039407\n",
      "epoch 40:\t20.06942834109214\n",
      "epoch 50:\t19.892513056854074\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.41540285217474976\n",
      "Epoch 25: 0.0007006526280827937\n",
      "Epoch 50: 0.00035811835719132187\n",
      "Epoch 75: 0.00024270542065852092\n",
      "Epoch 100: 0.0001842554858095115\n",
      "Epoch 125: 0.00014880547001582098\n",
      "Epoch 150: 0.0001249633812571054\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 296.77882170677185\n",
      "--------------------------------------------------\n",
      "En: 200\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.317666602369314\n",
      "epoch 10:\t19.924078995717508\n",
      "epoch 20:\t19.722092839380178\n",
      "epoch 30:\t19.581051828494317\n",
      "epoch 40:\t19.470068367221472\n",
      "epoch 50:\t19.351258734898803\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.3954388748740334\n",
      "Epoch 25: 0.0007758906768719717\n",
      "Epoch 50: 0.00039542977882585243\n",
      "Epoch 75: 0.0002684305046779893\n",
      "Epoch 100: 0.00020422455008014615\n",
      "Epoch 125: 0.0001652756750391641\n",
      "Epoch 150: 0.00013906151652273973\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 317.62116980552673\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.453723754466996\n",
      "epoch 10:\t21.118385195165736\n",
      "epoch 20:\t20.95368124237903\n",
      "epoch 30:\t20.827142496722242\n",
      "epoch 40:\t20.70922766922041\n",
      "epoch 50:\t20.59961808352836\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.1070524542965297\n",
      "Epoch 25: 0.001314951987172243\n",
      "Epoch 50: 0.0006508698011657543\n",
      "Epoch 75: 0.00044049732202417884\n",
      "Epoch 100: 0.00033534868384713226\n",
      "Epoch 125: 0.0002717973963230285\n",
      "Epoch 150: 0.00022906861465578498\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 178.84746599197388\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.966922749682464\n",
      "epoch 10:\t21.81508573726856\n",
      "epoch 20:\t21.506640703520947\n",
      "epoch 30:\t21.183308816492353\n",
      "epoch 40:\t20.911955082741304\n",
      "epoch 50:\t20.697502455414583\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.2605320883410802\n",
      "Epoch 25: 0.0010159260091871726\n",
      "Epoch 50: 0.000496073159280458\n",
      "Epoch 75: 0.0003343488267920279\n",
      "Epoch 100: 0.00025412387719601416\n",
      "Epoch 125: 0.00020584441638151694\n",
      "Epoch 150: 0.00017347127237891954\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 204.71201300621033\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.084643114360514\n",
      "epoch 10:\t20.44796239286374\n",
      "epoch 20:\t20.166017492311255\n",
      "epoch 30:\t19.847703782859142\n",
      "epoch 40:\t19.53021733095352\n",
      "epoch 50:\t19.22623738601037\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.5538013216685121\n",
      "Epoch 25: 0.000940851304649432\n",
      "Epoch 50: 0.0004729290752348985\n",
      "Epoch 75: 0.00031993615739530604\n",
      "Epoch 100: 0.0002431242224259689\n",
      "Epoch 125: 0.00019669723234247503\n",
      "Epoch 150: 0.00016551015553309176\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 230.22813272476196\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.73893799827267\n",
      "epoch 10:\t20.238708642900146\n",
      "epoch 20:\t20.165399097456397\n",
      "epoch 30:\t20.047207747714747\n",
      "epoch 40:\t19.932569498269586\n",
      "epoch 50:\t19.815998019302075\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.5169978595006552\n",
      "Epoch 25: 0.0008847322740354973\n",
      "Epoch 50: 0.00045373087921497823\n",
      "Epoch 75: 0.000307776295786909\n",
      "Epoch 100: 0.00023382231449134468\n",
      "Epoch 125: 0.0001889705004776804\n",
      "Epoch 150: 0.00015880542644796183\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 251.34104871749878\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.761025045126313\n",
      "epoch 10:\t19.456285656801324\n",
      "epoch 20:\t19.11891759307782\n",
      "epoch 30:\t18.56887734021339\n",
      "epoch 40:\t18.02507834917694\n",
      "epoch 50:\t17.49897228461043\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.7491458053047291\n",
      "Epoch 25: 0.0009919709675917767\n",
      "Epoch 50: 0.0004907562032144281\n",
      "Epoch 75: 0.00033079841719064183\n",
      "Epoch 100: 0.000251087040168506\n",
      "Epoch 125: 0.00020306351954171002\n",
      "Epoch 150: 0.0001708454457585794\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 254.3437569141388\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.524198800286317\n",
      "epoch 10:\t20.22502558983886\n",
      "epoch 20:\t20.06154463613875\n",
      "epoch 30:\t19.888891514880328\n",
      "epoch 40:\t19.70039923249903\n",
      "epoch 50:\t19.529397276291764\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.40411698062061246\n",
      "Epoch 25: 0.0007605247883682168\n",
      "Epoch 50: 0.00038509217791601934\n",
      "Epoch 75: 0.00026170454934930143\n",
      "Epoch 100: 0.00019944168977347392\n",
      "Epoch 125: 0.0001616616154663865\n",
      "Epoch 150: 0.0001362028418005635\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 294.3428056240082\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.571152658100242\n",
      "epoch 10:\t22.53209373609964\n",
      "epoch 20:\t22.372237665453625\n",
      "epoch 30:\t22.314074629717254\n",
      "epoch 40:\t22.213928472121\n",
      "epoch 50:\t22.103439956792343\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.5490686592012524\n",
      "Epoch 25: 0.0008861562960195558\n",
      "Epoch 50: 0.0004535304209754194\n",
      "Epoch 75: 0.00030746676907690557\n",
      "Epoch 100: 0.00023352935533427587\n",
      "Epoch 125: 0.00018871745259163407\n",
      "Epoch 150: 0.0001585982392234033\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 304.71168208122253\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.538761189766785\n",
      "epoch 10:\t18.41971394348219\n",
      "epoch 20:\t18.142261695479274\n",
      "epoch 30:\t17.916732795232775\n",
      "epoch 40:\t17.74108267961829\n",
      "epoch 50:\t17.57939322747217\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.3284917088119376\n",
      "Epoch 25: 0.0006976997152511451\n",
      "Epoch 50: 0.0003663985020772655\n",
      "Epoch 75: 0.00025117514221016445\n",
      "Epoch 100: 0.0001920550630621009\n",
      "Epoch 125: 0.00015592067249515726\n",
      "Epoch 150: 0.00013148568312099467\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 316.769495010376\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.24300694472234\n",
      "epoch 10:\t20.01616305052707\n",
      "epoch 20:\t19.85144048247307\n",
      "epoch 30:\t19.760174563035562\n",
      "epoch 40:\t19.649950106546175\n",
      "epoch 50:\t19.529947064837167\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.43418784924706194\n",
      "Epoch 25: 0.0005656397514246179\n",
      "Epoch 50: 0.000299482388897366\n",
      "Epoch 75: 0.00020643055980002135\n",
      "Epoch 100: 0.00015846220019680415\n",
      "Epoch 125: 0.00012904217761969763\n",
      "Epoch 150: 0.00010908669745988652\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 320.1886782646179\n",
      "--------------------------------------------------\n",
      "En: 250\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.78737548042133\n",
      "epoch 10:\t19.91368338430777\n",
      "epoch 20:\t19.407863612741966\n",
      "epoch 30:\t19.113826990900787\n",
      "epoch 40:\t18.870115238745306\n",
      "epoch 50:\t18.691127852087032\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.4244505736851949\n",
      "Epoch 25: 0.0005752147130316897\n",
      "Epoch 50: 0.0002955104719884415\n",
      "Epoch 75: 0.0002004739420860565\n",
      "Epoch 100: 0.00015230587592900344\n",
      "Epoch 125: 0.0001231043823597352\n",
      "Epoch 150: 0.0001034726961634428\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 344.7388072013855\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.877501877708024\n",
      "epoch 10:\t19.681421735108973\n",
      "epoch 20:\t19.623229189998288\n",
      "epoch 30:\t19.388623646547398\n",
      "epoch 40:\t19.13488592650387\n",
      "epoch 50:\t18.868978303504765\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.3421416414203122\n",
      "Epoch 25: 0.0016634258143393013\n",
      "Epoch 50: 0.0007884605922968416\n",
      "Epoch 75: 0.0005238974345435481\n",
      "Epoch 100: 0.00039447531895107473\n",
      "Epoch 125: 0.00031732042590486824\n",
      "Epoch 150: 0.0002659348274699583\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 207.6849901676178\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.63911063875982\n",
      "epoch 10:\t21.391111905884856\n",
      "epoch 20:\t21.193403685041734\n",
      "epoch 30:\t20.96693714471819\n",
      "epoch 40:\t20.770546735613383\n",
      "epoch 50:\t20.60272224307916\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.9915133413481894\n",
      "Epoch 25: 0.0013089681085086855\n",
      "Epoch 50: 0.0006714315283327952\n",
      "Epoch 75: 0.0004576079504945079\n",
      "Epoch 100: 0.0003491848014448725\n",
      "Epoch 125: 0.0002832731680723031\n",
      "Epoch 150: 0.0002388384414648439\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 227.02105355262756\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.92550666958876\n",
      "epoch 10:\t18.682513865761226\n",
      "epoch 20:\t18.609680944076977\n",
      "epoch 30:\t18.52623454351249\n",
      "epoch 40:\t18.416205261479373\n",
      "epoch 50:\t18.312486240494923\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.988640673055211\n",
      "Epoch 25: 0.001033366248635811\n",
      "Epoch 50: 0.000528696757163516\n",
      "Epoch 75: 0.00036046407243942117\n",
      "Epoch 100: 0.0002752371609151369\n",
      "Epoch 125: 0.00022343470129800922\n",
      "Epoch 150: 0.000188482088525177\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 251.50884532928467\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.590623733032935\n",
      "epoch 10:\t19.258233457448398\n",
      "epoch 20:\t19.05156216162463\n",
      "epoch 30:\t18.834827200431686\n",
      "epoch 40:\t18.66581045301177\n",
      "epoch 50:\t18.453319692934286\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.188699512463506\n",
      "Epoch 25: 0.0012482534064992517\n",
      "Epoch 50: 0.0006134155247615996\n",
      "Epoch 75: 0.00041206573600210625\n",
      "Epoch 100: 0.00031203804337546554\n",
      "Epoch 125: 0.000251905128789694\n",
      "Epoch 150: 0.00021163717587749207\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 275.6127772331238\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t25.575613741471702\n",
      "epoch 10:\t24.654284274330465\n",
      "epoch 20:\t24.541216354523527\n",
      "epoch 30:\t24.380908877723044\n",
      "epoch 40:\t24.211384269843734\n",
      "epoch 50:\t24.043517108551697\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.7528917599997358\n",
      "Epoch 25: 0.0008187513865419192\n",
      "Epoch 50: 0.00041329336749015513\n",
      "Epoch 75: 0.00027874628145599443\n",
      "Epoch 100: 0.0002111286498439142\n",
      "Epoch 125: 0.0001703109222621606\n",
      "Epoch 150: 0.00014294292232759176\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 294.63042187690735\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.825008864159585\n",
      "epoch 10:\t21.195527425674204\n",
      "epoch 20:\t20.94216654307414\n",
      "epoch 30:\t20.756293699165585\n",
      "epoch 40:\t20.579185362102564\n",
      "epoch 50:\t20.388841453175953\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.0272395796696703\n",
      "Epoch 25: 0.0011903455662599493\n",
      "Epoch 50: 0.000580575338048877\n",
      "Epoch 75: 0.0003879457298458112\n",
      "Epoch 100: 0.00029278418862635594\n",
      "Epoch 125: 0.00023581502779998056\n",
      "Epoch 150: 0.0001978064752454882\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 305.32187700271606\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.771653312383048\n",
      "epoch 10:\t18.649945650340097\n",
      "epoch 20:\t18.540295257669385\n",
      "epoch 30:\t18.40523924087994\n",
      "epoch 40:\t18.28315252418324\n",
      "epoch 50:\t18.174381095034054\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.7505469080092302\n",
      "Epoch 25: 0.0007516547873734925\n",
      "Epoch 50: 0.00039083770675336026\n",
      "Epoch 75: 0.000267599110734502\n",
      "Epoch 100: 0.00020471256173252564\n",
      "Epoch 125: 0.0001663425812661599\n",
      "Epoch 150: 0.00014041178812642204\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 323.18109488487244\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.488106521864225\n",
      "epoch 10:\t22.37779015832533\n",
      "epoch 20:\t21.601719065580976\n",
      "epoch 30:\t21.397291769878233\n",
      "epoch 40:\t21.205617666115295\n",
      "epoch 50:\t21.02219240736215\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.8902073878982646\n",
      "Epoch 25: 0.0007497867132741475\n",
      "Epoch 50: 0.0003879016901325738\n",
      "Epoch 75: 0.00026357173931241244\n",
      "Epoch 100: 0.000200277555396316\n",
      "Epoch 125: 0.00016179887197568995\n",
      "Epoch 150: 0.00013590141936158911\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 338.724862575531\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.729967123650585\n",
      "epoch 10:\t19.10895539782278\n",
      "epoch 20:\t18.900043357132134\n",
      "epoch 30:\t18.86015854263247\n",
      "epoch 40:\t18.654699910879376\n",
      "epoch 50:\t18.50579111807601\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.5757770393066053\n",
      "Epoch 25: 0.0005505908687573098\n",
      "Epoch 50: 0.00028846191149240624\n",
      "Epoch 75: 0.00019861361866804137\n",
      "Epoch 100: 0.00015247944432066207\n",
      "Epoch 125: 0.00012417833190090646\n",
      "Epoch 150: 0.00010497175411561591\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 345.1399791240692\n",
      "--------------------------------------------------\n",
      "En: 300\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.34049041134794\n",
      "epoch 10:\t20.1789736669208\n",
      "epoch 20:\t20.22661856054755\n",
      "epoch 30:\t20.20557693800249\n",
      "epoch 40:\t20.192615221039265\n",
      "epoch 50:\t20.185008004826607\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.1777592450319974\n",
      "Epoch 25: 0.0010071731671301215\n",
      "Epoch 50: 0.0004909861123982548\n",
      "Epoch 75: 0.0003278384472326325\n",
      "Epoch 100: 0.00024724176796007264\n",
      "Epoch 125: 0.0001990039667661035\n",
      "Epoch 150: 0.00016681780650634843\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 374.02326703071594\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.937094501325863\n",
      "epoch 10:\t21.61850712666104\n",
      "epoch 20:\t21.237489947557734\n",
      "epoch 30:\t20.919649592054025\n",
      "epoch 40:\t20.681655518958838\n",
      "epoch 50:\t20.39587897755783\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.9742579666331762\n",
      "Epoch 25: 0.0008591964992853299\n",
      "Epoch 50: 0.00042011088966346916\n",
      "Epoch 75: 0.000282161894995097\n",
      "Epoch 100: 0.00021382910519367925\n",
      "Epoch 125: 0.0001727903135578875\n",
      "Epoch 150: 0.00014531757965156015\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 228.74335932731628\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.586189305398733\n",
      "epoch 10:\t21.52628076492083\n",
      "epoch 20:\t21.456007180537735\n",
      "epoch 30:\t21.245277254595138\n",
      "epoch 40:\t21.01929336903854\n",
      "epoch 50:\t20.785286760503407\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.1648828366476918\n",
      "Epoch 25: 0.0008539344423025415\n",
      "Epoch 50: 0.0004381052728581645\n",
      "Epoch 75: 0.00029769341921429937\n",
      "Epoch 100: 0.00022654676640258438\n",
      "Epoch 125: 0.00018339203559478815\n",
      "Epoch 150: 0.00015434544259351188\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 253.42606902122498\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.617111168952082\n",
      "epoch 10:\t20.83873899100132\n",
      "epoch 20:\t20.30671380775506\n",
      "epoch 30:\t19.585313650709402\n",
      "epoch 40:\t18.916704920543452\n",
      "epoch 50:\t18.46668435300629\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.7219111772094038\n",
      "Epoch 25: 0.0007149339570791793\n",
      "Epoch 50: 0.0003667295376843676\n",
      "Epoch 75: 0.000250053614186066\n",
      "Epoch 100: 0.0001908171527829195\n",
      "Epoch 125: 0.0001547838680848413\n",
      "Epoch 150: 0.00013047315184605438\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 279.1943407058716\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.416812288860587\n",
      "epoch 10:\t19.31791745698151\n",
      "epoch 20:\t19.166295056964604\n",
      "epoch 30:\t19.076648841861925\n",
      "epoch 40:\t19.016201130587863\n",
      "epoch 50:\t18.957978900290595\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.0308667681964878\n",
      "Epoch 25: 0.0010804428988067498\n",
      "Epoch 50: 0.0005033595702046205\n",
      "Epoch 75: 0.00033786435153855093\n",
      "Epoch 100: 0.00025695822140984966\n",
      "Epoch 125: 0.00020836905754996606\n",
      "Epoch 150: 0.00017575219375966719\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 294.66814279556274\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.293461601039805\n",
      "epoch 10:\t20.303714280795916\n",
      "epoch 20:\t20.33927029517042\n",
      "epoch 30:\t20.358561560531573\n",
      "epoch 40:\t20.335013894327858\n",
      "epoch 50:\t20.292575465678517\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.8393027965765478\n",
      "Epoch 25: 0.0012697571962249558\n",
      "Epoch 50: 0.0006421307988246513\n",
      "Epoch 75: 0.0004380824044045539\n",
      "Epoch 100: 0.0003350849266703645\n",
      "Epoch 125: 0.00027246473125364383\n",
      "Epoch 150: 0.00023017761406332615\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 321.57486629486084\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.66313234907037\n",
      "epoch 10:\t18.956120724551592\n",
      "epoch 20:\t18.95287182795093\n",
      "epoch 30:\t18.94179716433917\n",
      "epoch 40:\t18.914021286047433\n",
      "epoch 50:\t18.880608598872485\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.8898730858331226\n",
      "Epoch 25: 0.0012833363257304187\n",
      "Epoch 50: 0.0005876983984972805\n",
      "Epoch 75: 0.0003863818520663522\n",
      "Epoch 100: 0.00028923479841402264\n",
      "Epoch 125: 0.0002317249136161686\n",
      "Epoch 150: 0.00019359004321986158\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 324.9547643661499\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.585617216664414\n",
      "epoch 10:\t20.882200928138616\n",
      "epoch 20:\t20.651417188992415\n",
      "epoch 30:\t20.482093647830045\n",
      "epoch 40:\t20.33647205599969\n",
      "epoch 50:\t20.194440241360287\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.5610553435606754\n",
      "Epoch 25: 0.0005442663410559725\n",
      "Epoch 50: 0.00028368075866077046\n",
      "Epoch 75: 0.00019392584253938685\n",
      "Epoch 100: 0.0001480423483858629\n",
      "Epoch 125: 0.00012005761431896735\n",
      "Epoch 150: 0.00010115542949295429\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 356.4995799064636\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.383959155919168\n",
      "epoch 10:\t18.95635799012962\n",
      "epoch 20:\t18.71374198296631\n",
      "epoch 30:\t18.558012801101288\n",
      "epoch 40:\t18.428646616014735\n",
      "epoch 50:\t18.29184281203062\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.9300794121211106\n",
      "Epoch 25: 0.0005533189997567317\n",
      "Epoch 50: 0.00027578324043636443\n",
      "Epoch 75: 0.00018553925635271905\n",
      "Epoch 100: 0.00014051520800768713\n",
      "Epoch 125: 0.00011341776286356625\n",
      "Epoch 150: 9.528113427888284e-05\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 361.3704345226288\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.672412842900183\n",
      "epoch 10:\t21.2404152694168\n",
      "epoch 20:\t20.860528758786625\n",
      "epoch 30:\t20.433215388279024\n",
      "epoch 40:\t19.979782714608806\n",
      "epoch 50:\t19.585898918722922\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.9096646573422549\n",
      "Epoch 25: 0.0005890209984410893\n",
      "Epoch 50: 0.0002996570820966512\n",
      "Epoch 75: 0.0002036693085472853\n",
      "Epoch 100: 0.00015523822672405794\n",
      "Epoch 125: 0.0001258775131235248\n",
      "Epoch 150: 0.0001061099320069193\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 392.7497515678406\n",
      "--------------------------------------------------\n",
      "En: 350\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.320723468952195\n",
      "epoch 10:\t21.86813776008819\n",
      "epoch 20:\t21.54271661105584\n",
      "epoch 30:\t21.4199362229128\n",
      "epoch 40:\t21.287714319113405\n",
      "epoch 50:\t21.16085089470593\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.5968317603677442\n",
      "Epoch 25: 0.000538238292968856\n",
      "Epoch 50: 0.00026784668463672765\n",
      "Epoch 75: 0.00018133253593902054\n",
      "Epoch 100: 0.00013808685803921132\n",
      "Epoch 125: 0.00011196669812630944\n",
      "Epoch 150: 9.440156652357246e-05\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 388.2821481227875\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.59079495371879\n",
      "epoch 10:\t19.234261328701535\n",
      "epoch 20:\t18.80753439391968\n",
      "epoch 30:\t18.49097950367059\n",
      "epoch 40:\t18.28917248811043\n",
      "epoch 50:\t18.141532354236173\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.5284971251689554\n",
      "Epoch 25: 0.0010923954271044585\n",
      "Epoch 50: 0.00052104653436593\n",
      "Epoch 75: 0.0003478059883181314\n",
      "Epoch 100: 0.0002626344233187245\n",
      "Epoch 125: 0.00021165186298772328\n",
      "Epoch 150: 0.00017759573294969495\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 250.88857507705688\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.69584387142272\n",
      "epoch 10:\t19.245385984102743\n",
      "epoch 20:\t19.09001618993787\n",
      "epoch 30:\t19.01492492826377\n",
      "epoch 40:\t18.984222783907835\n",
      "epoch 50:\t18.969071044444267\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.7100081402260912\n",
      "Epoch 25: 0.001454603684534561\n",
      "Epoch 50: 0.0006091466020582933\n",
      "Epoch 75: 0.0003925980536365614\n",
      "Epoch 100: 0.0002913747827506086\n",
      "Epoch 125: 0.00023236927835365389\n",
      "Epoch 150: 0.00019361842062034877\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 284.6610896587372\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.577559401811996\n",
      "epoch 10:\t18.164547050577834\n",
      "epoch 20:\t18.15815741373091\n",
      "epoch 30:\t18.020937832531114\n",
      "epoch 40:\t17.75210806752529\n",
      "epoch 50:\t17.495004802212552\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.6972329683294902\n",
      "Epoch 25: 0.0009671317591572513\n",
      "Epoch 50: 0.0004912063926829875\n",
      "Epoch 75: 0.00033353552448431854\n",
      "Epoch 100: 0.0002537093044686582\n",
      "Epoch 125: 0.00020525782874152297\n",
      "Epoch 150: 0.00017262837986896566\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 298.6002802848816\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.13548164719274\n",
      "epoch 10:\t19.039074819184233\n",
      "epoch 20:\t18.869134763100558\n",
      "epoch 30:\t18.766609982077984\n",
      "epoch 40:\t18.703175089411236\n",
      "epoch 50:\t18.61552736720964\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.093111823786863\n",
      "Epoch 25: 0.0008322812589059124\n",
      "Epoch 50: 0.0004183075052001836\n",
      "Epoch 75: 0.0002821893657468369\n",
      "Epoch 100: 0.00021391273262525752\n",
      "Epoch 125: 0.00017271525922760234\n",
      "Epoch 150: 0.0001450871706990193\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 324.9941232204437\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.80764478593966\n",
      "epoch 10:\t20.61811095366731\n",
      "epoch 20:\t20.430853159396353\n",
      "epoch 30:\t20.264870922561258\n",
      "epoch 40:\t20.090501089547775\n",
      "epoch 50:\t19.919410193550362\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.5940409524813152\n",
      "Epoch 25: 0.0005936236929996852\n",
      "Epoch 50: 0.00030382631153313375\n",
      "Epoch 75: 0.00020661777660518983\n",
      "Epoch 100: 0.0001573299044648735\n",
      "Epoch 125: 0.0001273848462052977\n",
      "Epoch 150: 0.00010720680611295089\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 345.12460255622864\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.977509797067565\n",
      "epoch 10:\t18.699478446868852\n",
      "epoch 20:\t18.63775236570521\n",
      "epoch 30:\t18.530292499239202\n",
      "epoch 40:\t18.424156500577983\n",
      "epoch 50:\t18.327952723188254\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.3296788729451408\n",
      "Epoch 25: 0.0007934686106007671\n",
      "Epoch 50: 0.00040414287194883157\n",
      "Epoch 75: 0.0002748765863228586\n",
      "Epoch 100: 0.00020956907798983516\n",
      "Epoch 125: 0.0001699447680125532\n",
      "Epoch 150: 0.00014326639405037866\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 363.4637916088104\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.62187847685125\n",
      "epoch 10:\t19.820899383835208\n",
      "epoch 20:\t19.63004514462011\n",
      "epoch 30:\t19.449161179057878\n",
      "epoch 40:\t19.28798855863081\n",
      "epoch 50:\t19.081926615899082\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.35258514050982714\n",
      "Epoch 25: 0.0005062430128921387\n",
      "Epoch 50: 0.00026283128565752047\n",
      "Epoch 75: 0.0001796851283864368\n",
      "Epoch 100: 0.00013720559805191815\n",
      "Epoch 125: 0.0001112906173682237\n",
      "Epoch 150: 9.378053332087391e-05\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 376.2109363079071\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.68975510135037\n",
      "epoch 10:\t20.183242853418122\n",
      "epoch 20:\t19.99938467232956\n",
      "epoch 30:\t19.78930113551806\n",
      "epoch 40:\t19.55392254917742\n",
      "epoch 50:\t19.30193937424178\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.3401146410929363\n",
      "Epoch 25: 0.000844617284999632\n",
      "Epoch 50: 0.00041471257349188465\n",
      "Epoch 75: 0.0002778697941347059\n",
      "Epoch 100: 0.00020988320418025255\n",
      "Epoch 125: 0.00016905483516834371\n",
      "Epoch 150: 0.00014175806204307485\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 395.56547927856445\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t17.92115847840057\n",
      "epoch 10:\t17.781053029173687\n",
      "epoch 20:\t17.423349988472456\n",
      "epoch 30:\t17.19107722742919\n",
      "epoch 40:\t16.914854558068942\n",
      "epoch 50:\t16.64973319278416\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.6212796288385867\n",
      "Epoch 25: 0.0005663397028743738\n",
      "Epoch 50: 0.00029051940998159564\n",
      "Epoch 75: 0.0001975333779120952\n",
      "Epoch 100: 0.0001503513465169853\n",
      "Epoch 125: 0.00012168384899657413\n",
      "Epoch 150: 0.00010236085039501949\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 402.51341700553894\n",
      "--------------------------------------------------\n",
      "En: 400\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.788717222334338\n",
      "epoch 10:\t21.39658018974846\n",
      "epoch 20:\t21.090710016421585\n",
      "epoch 30:\t20.704223898733055\n",
      "epoch 40:\t20.233288187307664\n",
      "epoch 50:\t19.777736942761575\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.3212169349948584\n",
      "Epoch 25: 0.000503121584220736\n",
      "Epoch 50: 0.00026689195276041744\n",
      "Epoch 75: 0.00018398388361859475\n",
      "Epoch 100: 0.00014117004553922284\n",
      "Epoch 125: 0.00011489125075870632\n",
      "Epoch 150: 9.704967209520632e-05\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 421.63192105293274\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t23.508301179179266\n",
      "epoch 10:\t22.79226964816719\n",
      "epoch 20:\t22.261226774876405\n",
      "epoch 30:\t21.853901060754968\n",
      "epoch 40:\t21.55192784025945\n",
      "epoch 50:\t21.306169467846267\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.41171612060558743\n",
      "Epoch 25: 0.0005768308024267308\n",
      "Epoch 50: 0.0002958676395871166\n",
      "Epoch 75: 0.00020050650860421415\n",
      "Epoch 100: 0.00015218938194210547\n",
      "Epoch 125: 0.00012291702261433914\n",
      "Epoch 150: 0.00010323728271167018\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 277.40073895454407\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.917779236252155\n",
      "epoch 10:\t22.616458005038663\n",
      "epoch 20:\t22.329405206380716\n",
      "epoch 30:\t22.097045356031433\n",
      "epoch 40:\t21.87824137335212\n",
      "epoch 50:\t21.674724873603953\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.8831181841181978\n",
      "Epoch 25: 0.0007867112796745614\n",
      "Epoch 50: 0.0004004530565658947\n",
      "Epoch 75: 0.0002712884804305707\n",
      "Epoch 100: 0.00020598454468911785\n",
      "Epoch 125: 0.00016642364609892094\n",
      "Epoch 150: 0.00013982735381282423\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 300.0614619255066\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.92701313624325\n",
      "epoch 10:\t19.594994699076437\n",
      "epoch 20:\t19.592118977406766\n",
      "epoch 30:\t19.367173239346325\n",
      "epoch 40:\t19.169426067427242\n",
      "epoch 50:\t19.014240211435084\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 2.159502136626664\n",
      "Epoch 25: 0.0011082282083925907\n",
      "Epoch 50: 0.0005051221671819624\n",
      "Epoch 75: 0.0003318162258766546\n",
      "Epoch 100: 0.0002486850762967139\n",
      "Epoch 125: 0.00019963883272382327\n",
      "Epoch 150: 0.00016718812832783469\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 318.0315194129944\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.63331097018661\n",
      "epoch 10:\t20.49902408895231\n",
      "epoch 20:\t19.94813125018381\n",
      "epoch 30:\t19.45138805057282\n",
      "epoch 40:\t18.97098654053616\n",
      "epoch 50:\t18.53603406347436\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.520291083927332\n",
      "Epoch 25: 0.0005583374525677115\n",
      "Epoch 50: 0.0002914635043709279\n",
      "Epoch 75: 0.0001996041489403002\n",
      "Epoch 100: 0.00015252979191733514\n",
      "Epoch 125: 0.0001237577580072223\n",
      "Epoch 150: 0.00010430284704732756\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 344.48317289352417\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.984242217569825\n",
      "epoch 10:\t19.97203378793149\n",
      "epoch 20:\t19.938938528125387\n",
      "epoch 30:\t19.87135901616543\n",
      "epoch 40:\t19.766449924950297\n",
      "epoch 50:\t19.656404206868178\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.5964998070193542\n",
      "Epoch 25: 0.0007514081993129961\n",
      "Epoch 50: 0.00037093048454739104\n",
      "Epoch 75: 0.00024978661276293224\n",
      "Epoch 100: 0.00018937653339513906\n",
      "Epoch 125: 0.00015297731662242925\n",
      "Epoch 150: 0.00012857490644992053\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 363.47158122062683\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.34275769867278\n",
      "epoch 10:\t19.152336822453773\n",
      "epoch 20:\t18.727301457251144\n",
      "epoch 30:\t18.307662286215805\n",
      "epoch 40:\t17.955674203822998\n",
      "epoch 50:\t17.639224067871485\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.077254501000984\n",
      "Epoch 25: 0.000804340561073255\n",
      "Epoch 50: 0.0004159043075297884\n",
      "Epoch 75: 0.0002852547832445993\n",
      "Epoch 100: 0.00021856782180808818\n",
      "Epoch 125: 0.00017782471313218504\n",
      "Epoch 150: 0.00015023826043038737\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 371.2130584716797\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.01171913145645\n",
      "epoch 10:\t19.506844930538076\n",
      "epoch 20:\t19.399926830485878\n",
      "epoch 30:\t19.330891378251764\n",
      "epoch 40:\t19.254152625762952\n",
      "epoch 50:\t19.171793890878615\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.773139690674188\n",
      "Epoch 25: 0.0006694476950766463\n",
      "Epoch 50: 0.0003375169821744058\n",
      "Epoch 75: 0.00022880968888914252\n",
      "Epoch 100: 0.00017406178078973326\n",
      "Epoch 125: 0.00014091483929137648\n",
      "Epoch 150: 0.00011862452259480326\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 390.13446855545044\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.998886087429252\n",
      "epoch 10:\t19.66927865084315\n",
      "epoch 20:\t19.386768722078624\n",
      "epoch 30:\t19.153878820126764\n",
      "epoch 40:\t18.95534362204236\n",
      "epoch 50:\t18.791251702292982\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.9588644998664015\n",
      "Epoch 25: 0.0007675876978959712\n",
      "Epoch 50: 0.00039402686779097125\n",
      "Epoch 75: 0.0002686678937814469\n",
      "Epoch 100: 0.00020501335062776845\n",
      "Epoch 125: 0.0001662873471296216\n",
      "Epoch 150: 0.00014016781144895852\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 403.0559208393097\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.47867749176311\n",
      "epoch 10:\t20.06781494917824\n",
      "epoch 20:\t19.54978796205222\n",
      "epoch 30:\t19.205456103332462\n",
      "epoch 40:\t18.858269202620704\n",
      "epoch 50:\t18.501392091738264\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.4925891362245384\n",
      "Epoch 25: 0.0005936428931378743\n",
      "Epoch 50: 0.0003096729908492606\n",
      "Epoch 75: 0.00021212647618696503\n",
      "Epoch 100: 0.00016213867421631297\n",
      "Epoch 125: 0.00013158020863389863\n",
      "Epoch 150: 0.00011090297844433115\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 416.5778832435608\n",
      "--------------------------------------------------\n",
      "En: 450\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.653064932280966\n",
      "epoch 10:\t21.535089109082445\n",
      "epoch 20:\t21.240247886611396\n",
      "epoch 30:\t20.992276439763742\n",
      "epoch 40:\t20.749717701692138\n",
      "epoch 50:\t20.520287008560555\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.7642623049469266\n",
      "Epoch 25: 0.000614050869689088\n",
      "Epoch 50: 0.00031888768229277155\n",
      "Epoch 75: 0.0002176130168605121\n",
      "Epoch 100: 0.00016593395935215688\n",
      "Epoch 125: 0.00013445486189012586\n",
      "Epoch 150: 0.00011321136869564525\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 441.5951416492462\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 40\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t18.97462616686457\n",
      "epoch 10:\t18.787427531847435\n",
      "epoch 20:\t18.716431553237488\n",
      "epoch 30:\t18.590864897890757\n",
      "epoch 40:\t18.466036014840125\n",
      "epoch 50:\t18.35516346268019\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.9548767429897487\n",
      "Epoch 25: 0.0012437334210166232\n",
      "Epoch 50: 0.00047700967783970643\n",
      "Epoch 75: 0.00030440824088499965\n",
      "Epoch 100: 0.00022525655375026254\n",
      "Epoch 125: 0.0001794266756344914\n",
      "Epoch 150: 0.00014941003872158482\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 299.56812858581543\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 80\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.07435258920056\n",
      "epoch 10:\t21.363174400414227\n",
      "epoch 20:\t21.303736408157448\n",
      "epoch 30:\t21.190318032264212\n",
      "epoch 40:\t21.06767901828783\n",
      "epoch 50:\t20.799598495684112\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.6973638192825092\n",
      "Epoch 25: 0.0007081160764641937\n",
      "Epoch 50: 0.0003363872406482975\n",
      "Epoch 75: 0.00022326555468074778\n",
      "Epoch 100: 0.00016792113854119728\n",
      "Epoch 125: 0.0001349272498539096\n",
      "Epoch 150: 0.00011296341425971812\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 319.42956709861755\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 120\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t19.79085166140153\n",
      "epoch 10:\t19.831545881139306\n",
      "epoch 20:\t19.58345902238234\n",
      "epoch 30:\t19.39943134056826\n",
      "epoch 40:\t19.19215951145961\n",
      "epoch 50:\t19.02596107120848\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.5600120756729549\n",
      "Epoch 25: 0.0006393068024149876\n",
      "Epoch 50: 0.00032566062957302633\n",
      "Epoch 75: 0.0002215772000754111\n",
      "Epoch 100: 0.00016889335818168474\n",
      "Epoch 125: 0.00013688508822027752\n",
      "Epoch 150: 0.00011529577206575383\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 352.23665475845337\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 160\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t17.54771671969621\n",
      "epoch 10:\t17.558109832533038\n",
      "epoch 20:\t17.299426191779588\n",
      "epoch 30:\t17.045624562286328\n",
      "epoch 40:\t16.78852687831267\n",
      "epoch 50:\t16.51537848178511\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.8949028166529057\n",
      "Epoch 25: 0.0010461731624582904\n",
      "Epoch 50: 0.0005300702691063075\n",
      "Epoch 75: 0.00035900801447192606\n",
      "Epoch 100: 0.0002728831717697855\n",
      "Epoch 125: 0.0002207946321777165\n",
      "Epoch 150: 0.00018580594075476314\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 356.82896876335144\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 200\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.018409196591065\n",
      "epoch 10:\t21.59902594820964\n",
      "epoch 20:\t21.47643042111108\n",
      "epoch 30:\t21.299400114552768\n",
      "epoch 40:\t21.123124300834267\n",
      "epoch 50:\t20.952220396099897\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.3168627731494533\n",
      "Epoch 25: 0.0006371210521121741\n",
      "Epoch 50: 0.0003284025721492664\n",
      "Epoch 75: 0.00022411539976405136\n",
      "Epoch 100: 0.00017109815656681348\n",
      "Epoch 125: 0.0001388188770419723\n",
      "Epoch 150: 0.00011704141426518179\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 385.1057720184326\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 240\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t24.38002420936876\n",
      "epoch 10:\t24.25643195015265\n",
      "epoch 20:\t24.079575965769674\n",
      "epoch 30:\t23.843874027032314\n",
      "epoch 40:\t23.459771606494822\n",
      "epoch 50:\t22.752531436062544\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.43330766879907845\n",
      "Epoch 25: 0.0005055747338142597\n",
      "Epoch 50: 0.0002631171419092328\n",
      "Epoch 75: 0.00017965745178406755\n",
      "Epoch 100: 0.00013700722830954824\n",
      "Epoch 125: 0.00011101050649484874\n",
      "Epoch 150: 9.34561605932944e-05\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 396.69316816329956\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 280\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t20.36882039313268\n",
      "epoch 10:\t19.703221708984646\n",
      "epoch 20:\t19.5529583468676\n",
      "epoch 30:\t19.417598282576915\n",
      "epoch 40:\t19.28748829628178\n",
      "epoch 50:\t19.163227479213216\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.32461337343763835\n",
      "Epoch 25: 0.0005011869442204587\n",
      "Epoch 50: 0.00026288000301641855\n",
      "Epoch 75: 0.00018038920789284528\n",
      "Epoch 100: 0.00013801834538070397\n",
      "Epoch 125: 0.00011208601034839606\n",
      "Epoch 150: 9.452899085318496e-05\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 420.43932342529297\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 320\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.910487857455962\n",
      "epoch 10:\t21.762883343261738\n",
      "epoch 20:\t21.678958245514263\n",
      "epoch 30:\t21.507791618968643\n",
      "epoch 40:\t21.36934006544743\n",
      "epoch 50:\t21.245370325292857\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.6285440791720824\n",
      "Epoch 25: 0.0005033054952927715\n",
      "Epoch 50: 0.0002483822841671317\n",
      "Epoch 75: 0.00016698881235599537\n",
      "Epoch 100: 0.0001264427085619333\n",
      "Epoch 125: 0.00010204359233262594\n",
      "Epoch 150: 8.570157858707509e-05\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 434.0487177371979\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 360\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t22.9441377321463\n",
      "epoch 10:\t22.69992786963736\n",
      "epoch 20:\t22.322205284348485\n",
      "epoch 30:\t21.802259152183293\n",
      "epoch 40:\t21.370238770812595\n",
      "epoch 50:\t20.981162605855797\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 1.0481938470983285\n",
      "Epoch 25: 0.0005732007456607681\n",
      "Epoch 50: 0.0002950297346107822\n",
      "Epoch 75: 0.0002005211772631042\n",
      "Epoch 100: 0.00015245413280546126\n",
      "Epoch 125: 0.00012322665864412146\n",
      "Epoch 150: 0.00010354203335318056\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 454.1157395839691\n",
      "--------------------------------------------------\n",
      "En: 500\tTr: 400\n",
      "Using first variation (Regressor and Classifier with score vectors)\n",
      "epoch 0:\t21.42877272522985\n",
      "epoch 10:\t20.632025082193827\n",
      "epoch 20:\t20.429120579875605\n",
      "epoch 30:\t20.275507686569416\n",
      "epoch 40:\t20.08860205786903\n",
      "epoch 50:\t19.897858699669456\n",
      "Using second variation (average of outputs produced by each set of weight matrices)\n",
      "Epoch 0: 0.2529614382275251\n",
      "Epoch 25: 0.0004315335957474689\n",
      "Epoch 50: 0.00022717441941056096\n",
      "Epoch 75: 0.00015604327352080973\n",
      "Epoch 100: 0.00011951028004645536\n",
      "Epoch 125: 9.715653555539284e-05\n",
      "Epoch 150: 8.203221601399314e-05\n",
      "Using well-known algorithms: Logistic Regression, RandomForest and MLP\n",
      "Took: 469.8164360523224\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "robustness_tri = robustness_test(df_full_trilabels)\n",
    "pickle.dump(robustness_tri, open(\"../results/robustness_tri.results\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW TO CHEAT LIKE A PRO\n",
    "# \"\"\"\n",
    "# def test_selective(df_test, W1, W2, W3):\n",
    "#     reset_graph()\n",
    "#     x = tf.placeholder(tf.float32, [None, 300])\n",
    "#     y = tf.placeholder(tf.float32, [None, 10]) # 1-10 => 10 classes\n",
    "\n",
    "#     w1 = tf.placeholder(tf.float32, [300, 300])\n",
    "#     w2 = tf.placeholder(tf.float32, [300, 300])\n",
    "#     w3 = tf.placeholder(tf.float32, [300, 10])\n",
    "\n",
    "#     b1 = tf.Variable(tf.zeros([300]))\n",
    "#     b2 = tf.Variable(tf.zeros([300]))\n",
    "#     b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#     l2 = tf.nn.sigmoid(tf.matmul(x, w1) + b1)\n",
    "#     l3 = tf.nn.sigmoid(tf.matmul(l2, w2) + b2)\n",
    "#     pred = tf.nn.softmax(tf.matmul(l3, w3) + b3)\n",
    "    \n",
    "#     correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "#     instance_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#         # Testing the model\n",
    "#         LSMR_test = preprocess_data(df_test)\n",
    "#         X_test, y_test = get_test(LSMR_test)\n",
    "#         accuracy = 0.\n",
    "#         for i in range(len(X_test)):\n",
    "#             best_instance_accuracy = float(\"-inf\")\n",
    "#             for language, score, movie_id in W1:\n",
    "#                 w_1 = W1[(language, score, movie_id)]\n",
    "#                 w_2 = W2[(language, score)]\n",
    "#                 w_3 = W3[score]\n",
    "#                 a = instance_accuracy.eval({x: np.atleast_2d(X_test[i]), y: np.atleast_2d(y_test[i]),\n",
    "#                                    w1:w_1,\n",
    "#                                    w2:w_2,\n",
    "#                                    w3:w_3})\n",
    "#                 if a > best_instance_accuracy:\n",
    "#                     best_instance_accuracy = a\n",
    "#             accuracy += best_instance_accuracy\n",
    "\n",
    "#     return accuracy/len(X_test)\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-layer NN > needs at least 3 days for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu is a must\n",
    "def train_deep(df_train, epochs=100, learning_rate=0.1, random_state=42):\n",
    "    LSMR_train = preprocess_data(df_train)\n",
    "    np.random.seed(random_state)\n",
    "    data_dict, L1, L2, L3 = get_data_dict(LSMR_train, get_L2and3=True)\n",
    "    init_weights = lambda layer, i, o: {k:2*np.random.random((i, o))-1 for k in layer}\n",
    "    W1 = init_weights(L1, 300, 300)  # (languge, score, movie_id)\n",
    "    W2 = init_weights(L2, 300, 300)  # (languge, score):\n",
    "    W3 = init_weights(L3, 300, 10)  # score:\n",
    "    \n",
    "    \n",
    "    reset_graph()\n",
    "    x = tf.placeholder(tf.float32, [None, 300])\n",
    "    y = tf.placeholder(tf.float32, [None, 10]) # 1-10 => 10 classes\n",
    "\n",
    "    w1 = tf.Variable(tf.zeros([300, 300]))\n",
    "    w2 = tf.Variable(tf.zeros([300, 300]))\n",
    "    w3 = tf.Variable(tf.zeros([300, 10]))\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([300]))\n",
    "    b2 = tf.Variable(tf.zeros([300]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    l2 = tf.nn.sigmoid(tf.matmul(x, w1) + b1)\n",
    "    l3 = tf.nn.sigmoid(tf.matmul(l2, w2) + b2)\n",
    "    pred = tf.nn.softmax(tf.matmul(l3, w3) + b3)\n",
    "\n",
    "\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    training_curve = dict()\n",
    "    with tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):\n",
    "        with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for e in range(epochs+1):\n",
    "                start = time.time()\n",
    "                avg_cost = 0.\n",
    "                for _, row in LSMR_train.iterrows():\n",
    "                    score = row[\"Score\"]\n",
    "                    y_ = np.zeros(10)\n",
    "                    y_[score-1] = 1\n",
    "                    y_ = np.atleast_2d(y_)\n",
    "                    x_ = np.atleast_2d(row[\"rev_vec\"])\n",
    "                    w_1, w_2, w_3 , _, c = sess.run([w1, w2, w3, optimizer, cost], feed_dict={x: x_,y: y_})               \n",
    "                    avg_cost += c\n",
    "                avg_cost /= len(LSMR_train)\n",
    "                training_curve[e] = (avg_cost, time.time()-start)\n",
    "                if e%10==0:\n",
    "                    print(\"Epoch {}: {}\".format(e, avg_cost))\n",
    "\n",
    "    return w_1, w_2, w_3, training_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_deep(df_test, w_1, w_2, w_3):\n",
    "    reset_graph()\n",
    "    x = tf.placeholder(tf.float32, [None, 300])\n",
    "    y = tf.placeholder(tf.float32, [None, 10]) # 1-10 => 10 classes\n",
    "\n",
    "    w1 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w2 = tf.placeholder(tf.float32, [300, 300])\n",
    "    w3 = tf.placeholder(tf.float32, [300, 10])\n",
    "\n",
    "    b1 = tf.Variable(tf.zeros([300]))\n",
    "    b2 = tf.Variable(tf.zeros([300]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    l2 = tf.nn.sigmoid(tf.matmul(x, w1) + b1)\n",
    "    l3 = tf.nn.sigmoid(tf.matmul(l2, w2) + b2)\n",
    "    pred = tf.nn.softmax(tf.matmul(l3, w3) + b3)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    with tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):\n",
    "        with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # Testing the model\n",
    "            LSMR_test = preprocess_data(df_test)\n",
    "            X_test, y_test = get_test(LSMR_test)\n",
    "            return accuracy.eval({x: X_test,\n",
    "                                  y: y_test,\n",
    "                                  w1:w_1,w2:w_2,\n",
    "                                  w3:w_3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 1\n",
    "scores_incremental = dict()\n",
    "learning_curves = dict()\n",
    "for i in range(NUM_TRIALS):\n",
    "    scores_incremental[i] = dict()\n",
    "    learning_curves[i] = dict()\n",
    "    print(\"Trial:\\t{}\".format(i+1))\n",
    "    k = 0\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=i)\n",
    "    for train_index, test_index in skf.split(df[\"Review\"], df[\"Language\"]):\n",
    "        start = time.time()\n",
    "        w1, w2, w3, learning_curve = train_deep(df.loc[train_index], random_state=i, epochs=10000)\n",
    "        s = test_deep(df.loc[test_index], w1, w2, w3)\n",
    "        k += 1\n",
    "        print(\"K:\\t{}\\nScore:\\t{}\".format(k, s))\n",
    "        print(\"took:\", time.time()-start)\n",
    "        scores_incremental[i][k] = s\n",
    "        learning_curves[i][k] = learning_curve\n",
    "    print(\"*\"*10)\n",
    "    try:\n",
    "        print(\"Trial {} avg score:\\t {}\".format(i+1, np.mean(list(scores_incremental[i].values()))))\n",
    "    except:\n",
    "        continue\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
